====================Graph Node====================
Node: arg57_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg56_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg58_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg59_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg60_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg61_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg62_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg63_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg64_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg65_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg66_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg0_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg1_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg67_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg68_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg69_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg70_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg71_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg72_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg73_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg74_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg75_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg76_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg77_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg78_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg2_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg3_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg79_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg80_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg81_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg82_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg83_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg84_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg85_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg86_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg87_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg88_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg89_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg90_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg4_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg5_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg91_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg92_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg93_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg94_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg95_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg96_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg97_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg98_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg99_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg100_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg101_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg102_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg6_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg7_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg103_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg104_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg105_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg106_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg107_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg108_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg109_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg110_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg111_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg112_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg113_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg114_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg8_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg9_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg115_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg116_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg117_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg118_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg119_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg120_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg121_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg122_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg123_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg124_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg125_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg126_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg10_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg11_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg127_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg128_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg129_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg130_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg131_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg132_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg133_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg134_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg135_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg136_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg137_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg138_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg12_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg13_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg139_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg140_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg141_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg142_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg143_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg144_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg145_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg146_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg147_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg148_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg149_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg150_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg14_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg15_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg151_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg152_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg153_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg154_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg155_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg156_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg157_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg158_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg159_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg160_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg161_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg162_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg16_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg17_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg163_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg164_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg165_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg166_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg167_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg168_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg169_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg170_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg171_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg172_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg173_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg174_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg18_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg19_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg175_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg176_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg177_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg178_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg179_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg180_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg181_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg182_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg183_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg184_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg185_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg186_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg20_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg21_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg187_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg188_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg189_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg190_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg191_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg192_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg193_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg194_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg195_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg196_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg197_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg198_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg22_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg23_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg199_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg200_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg201_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg202_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg203_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg204_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg205_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg206_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg207_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg208_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg209_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg210_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg24_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg25_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg211_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg212_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg213_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg214_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg215_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg216_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg217_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg218_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg219_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg220_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg221_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg222_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg26_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg27_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg223_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg224_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg225_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg226_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg227_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg228_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg229_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg230_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg231_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg232_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg233_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg234_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg28_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg29_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg235_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg236_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg237_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg238_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg239_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg240_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg241_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg242_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg243_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg244_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg245_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg246_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg30_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg31_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg247_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg248_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg249_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg250_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg251_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg252_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg253_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg254_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg255_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg256_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg257_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg258_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg32_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg33_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg259_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg260_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg261_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg262_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg263_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg264_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg265_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg266_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg267_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg268_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg269_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg270_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg34_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg35_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg271_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg272_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg273_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg274_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg275_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg276_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg277_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg278_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg279_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg280_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg281_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg282_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg36_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg37_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg283_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg284_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg285_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg286_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg287_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg288_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg289_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg290_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg291_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg292_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg293_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg294_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg38_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg39_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg295_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg296_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg297_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg298_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg299_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg300_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg301_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg302_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg303_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg304_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg305_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg306_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg40_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg41_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg307_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg308_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg309_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg310_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg311_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg312_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg313_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg314_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg315_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg316_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg317_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg318_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg42_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg43_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg319_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg320_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg321_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg322_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg323_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg324_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg325_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg326_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg327_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg328_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg329_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg330_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg44_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg45_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg331_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg332_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg333_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg334_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg335_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg336_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg337_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg338_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg339_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg340_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg341_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg342_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg46_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg47_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg343_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg344_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg345_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg346_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg347_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg348_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg349_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg350_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg351_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg352_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg353_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg354_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg48_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg49_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg355_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg356_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg357_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg358_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg359_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg360_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg361_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg362_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg363_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg364_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg365_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg366_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg50_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg51_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg367_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg368_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg369_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg370_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg371_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg372_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg373_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg374_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg375_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg376_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg377_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg378_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg52_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg53_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg379_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg380_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg381_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg382_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg383_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg384_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg385_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg386_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg387_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg388_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg389_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg390_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg54_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg55_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg391_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg392_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg393_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg394_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg395_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg396_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: arg397_1
Type: OpType.PlaceholderType
Arguments: []
Parents: []
Children: []
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: embedding
Type: OpType.ReshapeType
Arguments: ['arg57_1', 'arg56_1']
Parents: ['arg57_1', 'arg56_1']
Children: ['pow_1', 'mul_2', 'add_4']
--------------------MLIR OPS--------------------
%0 = "tosa.cast"(%arg1) : (tensor<1x1xi64>) -> tensor<1x1xi32>
%1 = "tosa.reshape"(%arg0) <{new_shape = array<i64: 1, 151936, 1536>}> : (tensor<151936x1536xf32>) -> tensor<1x151936x1536xf32>
%2 = "tosa.gather"(%1, %0) : (tensor<1x151936x1536xf32>, tensor<1x1xi32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: unsqueeze
Type: OpType.ReshapeType
Arguments: ['arg58_1', 0]
Parents: ['arg58_1']
Children: ['slice_2']
--------------------MLIR OPS--------------------
%3 = "tosa.reshape"(%arg2) <{new_shape = array<i64: 1, 1>}> : (tensor<1xi64>) -> tensor<1x1xi64>

====================Graph Node====================
Node: iota
Type: OpType.PlaceholderType
Arguments: [1024]
Parents: []
Children: ['add']
--------------------MLIR OPS--------------------
%4 = "tosa.const"() <{value = dense<"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tensor<1024xi64>}> : () -> tensor<1024xi64>

====================Graph Node====================
Node: add
Type: OpType.BroadcastType
Arguments: ['iota', 0]
Parents: ['iota']
Children: ['le']
--------------------MLIR OPS--------------------
%5 = "tosa.const"() <{value = dense<0> : tensor<1024xi64>}> : () -> tensor<1024xi64>
%6 = "tosa.add"(%4, %5) : (tensor<1024xi64>, tensor<1024xi64>) -> tensor<1024xi64>

====================Graph Node====================
Node: view
Type: OpType.ReshapeType
Arguments: ['arg58_1', [1, 1]]
Parents: ['arg58_1']
Children: ['le']
--------------------MLIR OPS--------------------
%7 = "tosa.reshape"(%arg2) <{new_shape = array<i64: 1, 1>}> : (tensor<1xi64>) -> tensor<1x1xi64>

====================Graph Node====================
Node: le
Type: OpType.ElementwiseType
Arguments: ['add', 'view']
Parents: ['add', 'view']
Children: ['expand']
--------------------MLIR OPS--------------------
%8 = "tosa.const"() <{value = dense<0> : tensor<1x1024xi64>}> : () -> tensor<1x1024xi64>
%9 = "tosa.reshape"(%6) <{new_shape = array<i64: 1, 1024>}> : (tensor<1024xi64>) -> tensor<1x1024xi64>
%10 = "tosa.add"(%9, %8) : (tensor<1x1024xi64>, tensor<1x1024xi64>) -> tensor<1x1024xi64>
%11 = "tosa.const"() <{value = dense<0> : tensor<1x1024xi64>}> : () -> tensor<1x1024xi64>
%12 = "tosa.add"(%7, %11) : (tensor<1x1xi64>, tensor<1x1024xi64>) -> tensor<1x1024xi64>
%13 = "arith.cmpi"(%10, %12) <{predicate = 7 : i64}> : (tensor<1x1024xi64>, tensor<1x1024xi64>) -> tensor<1x1024xi1>

====================Graph Node====================
Node: expand
Type: OpType.ReshapeType
Arguments: ['le', [1, 1, 1024]]
Parents: ['le']
Children: ['expand_1']
--------------------MLIR OPS--------------------
%14 = "tosa.const"() <{value = dense<false> : tensor<1x1xi1>}> : () -> tensor<1x1xi1>
%15 = "tosa.add"(%13, %14) : (tensor<1x1024xi1>, tensor<1x1xi1>) -> tensor<1x1024xi1>

====================Graph Node====================
Node: expand_1
Type: OpType.ReshapeType
Arguments: ['expand', [1, 1, 1, 1024]]
Parents: ['expand']
Children: ['slice_24', 'slice_47', 'slice_70', 'slice_93', 'slice_116', 'slice_139', 'slice_162', 'slice_185', 'slice_208', 'slice_231', 'slice_254', 'slice_277', 'slice_300', 'slice_323', 'slice_346', 'slice_369', 'slice_392', 'slice_415', 'slice_438', 'slice_461', 'slice_484', 'slice_507', 'slice_530', 'slice_553', 'slice_576', 'slice_599', 'slice_622', 'slice_645']
--------------------MLIR OPS--------------------
%16 = "tosa.const"() <{value = dense<false> : tensor<1x1xi1>}> : () -> tensor<1x1xi1>
%17 = "tosa.add"(%15, %16) : (tensor<1x1024xi1>, tensor<1x1xi1>) -> tensor<1x1024xi1>

====================Graph Node====================
Node: unsqueeze_1
Type: OpType.ReshapeType
Arguments: ['arg59_1', 0]
Parents: ['arg59_1']
Children: ['slice_1']
--------------------MLIR OPS--------------------
%18 = "tosa.reshape"(%arg3) <{new_shape = array<i64: 1, 64>}> : (tensor<64xf32>) -> tensor<1x64xf32>

====================Graph Node====================
Node: slice_1
Type: OpType.ReshapeType
Arguments: ['unsqueeze_1', 1, 0, 9223372036854775807]
Parents: ['unsqueeze_1']
Children: ['unsqueeze_2']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_2
Type: OpType.ReshapeType
Arguments: ['slice_1', 2]
Parents: ['slice_1']
Children: ['expand_2']
--------------------MLIR OPS--------------------
%19 = "tosa.reshape"(%18) <{new_shape = array<i64: 1, 64, 1>}> : (tensor<1x64xf32>) -> tensor<1x64x1xf32>

====================Graph Node====================
Node: expand_2
Type: OpType.ReshapeType
Arguments: ['unsqueeze_2', [1, -1, 1]]
Parents: ['unsqueeze_2']
Children: ['expand_3']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_2
Type: OpType.ReshapeType
Arguments: ['unsqueeze', 0, 0, 9223372036854775807]
Parents: ['unsqueeze']
Children: ['unsqueeze_3']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_3
Type: OpType.ReshapeType
Arguments: ['slice_2', 1]
Parents: ['slice_2']
Children: ['slice_3']
--------------------MLIR OPS--------------------
%20 = "tosa.reshape"(%3) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1x1xi64>) -> tensor<1x1x1xi64>

====================Graph Node====================
Node: slice_3
Type: OpType.ReshapeType
Arguments: ['unsqueeze_3', 2, 0, 9223372036854775807]
Parents: ['unsqueeze_3']
Children: ['convert_element_type']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: convert_element_type
Type: OpType.ElementwiseType
Arguments: ['slice_3', <TensorDType.Float32: 'float32'>]
Parents: ['slice_3']
Children: ['expand_4']
--------------------MLIR OPS--------------------
%21 = "tosa.cast"(%20) : (tensor<1x1x1xi64>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: expand_3
Type: OpType.ReshapeType
Arguments: ['expand_2', [1, 64, 1]]
Parents: ['expand_2']
Children: ['view_1']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_1
Type: OpType.ReshapeType
Arguments: ['expand_3', [1, 64, 1]]
Parents: ['expand_3']
Children: ['bmm']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_4
Type: OpType.ReshapeType
Arguments: ['convert_element_type', [1, 1, 1]]
Parents: ['convert_element_type']
Children: ['view_2']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_2
Type: OpType.ReshapeType
Arguments: ['expand_4', [1, 1, 1]]
Parents: ['expand_4']
Children: ['bmm']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: bmm
Type: OpType.ReduceType
Arguments: ['view_1', 'view_2']
Parents: ['view_1', 'view_2']
Children: ['view_3']
--------------------MLIR OPS--------------------
%22 = "tosa.matmul"(%19, %21) : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32>

====================Graph Node====================
Node: view_3
Type: OpType.ReshapeType
Arguments: ['bmm', [1, 64, 1]]
Parents: ['bmm']
Children: ['permute']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute
Type: OpType.ReshapeType
Arguments: ['view_3', [0, 2, 1]]
Parents: ['view_3']
Children: ['unsqueeze_4']
--------------------MLIR OPS--------------------
%23 = "tosa.const"() <{value = dense<[0, 2, 1]> : tensor<3xi32>}> : () -> tensor<3xi32>
%24 = "tosa.transpose"(%22, %23) : (tensor<1x64x1xf32>, tensor<3xi32>) -> tensor<1x1x64xf32>

====================Graph Node====================
Node: unsqueeze_4
Type: OpType.ReshapeType
Arguments: ['permute', 2]
Parents: ['permute']
Children: ['expand_5']
--------------------MLIR OPS--------------------
%25 = "tosa.reshape"(%24) <{new_shape = array<i64: 1, 1, 1, 64>}> : (tensor<1x1x64xf32>) -> tensor<1x1x1x64xf32>

====================Graph Node====================
Node: expand_5
Type: OpType.ReshapeType
Arguments: ['unsqueeze_4', [1, 1, 2, 64]]
Parents: ['unsqueeze_4']
Children: ['clone']
--------------------MLIR OPS--------------------
%26 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x1x2x64xf32>}> : () -> tensor<1x1x2x64xf32>
%27 = "tosa.add"(%25, %26) : (tensor<1x1x1x64xf32>, tensor<1x1x2x64xf32>) -> tensor<1x1x2x64xf32>

====================Graph Node====================
Node: clone
Type: OpType.ReduceType
Arguments: ['expand_5']
Parents: ['expand_5']
Children: ['view_4']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_4
Type: OpType.ReshapeType
Arguments: ['clone', [1, 1, 128]]
Parents: ['clone']
Children: ['clone_1']
--------------------MLIR OPS--------------------
%28 = "tosa.reshape"(%27) <{new_shape = array<i64: 1, 1, 128>}> : (tensor<1x1x2x64xf32>) -> tensor<1x1x128xf32>

====================Graph Node====================
Node: clone_1
Type: OpType.ReduceType
Arguments: ['view_4']
Parents: ['view_4']
Children: ['cos', 'sin']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: cos
Type: OpType.ElementwiseType
Arguments: ['clone_1']
Parents: ['clone_1']
Children: ['mul']
--------------------MLIR OPS--------------------
%29 = "math.cos"(%28) <{fastmath = #arith.fastmath<none>}> : (tensor<1x1x128xf32>) -> tensor<1x1x128xf32>

====================Graph Node====================
Node: mul
Type: OpType.BroadcastType
Arguments: ['cos', 1.0]
Parents: ['cos']
Children: ['unsqueeze_5', 'unsqueeze_11', 'unsqueeze_17', 'unsqueeze_23', 'unsqueeze_29', 'unsqueeze_35', 'unsqueeze_41', 'unsqueeze_47', 'unsqueeze_53', 'unsqueeze_59', 'unsqueeze_65', 'unsqueeze_71', 'unsqueeze_77', 'unsqueeze_83', 'unsqueeze_89', 'unsqueeze_95', 'unsqueeze_101', 'unsqueeze_107', 'unsqueeze_113', 'unsqueeze_119', 'unsqueeze_125', 'unsqueeze_131', 'unsqueeze_137', 'unsqueeze_143', 'unsqueeze_149', 'unsqueeze_155', 'unsqueeze_161', 'unsqueeze_167']
--------------------MLIR OPS--------------------
%30 = "arith.constant"() <{value = dense<1.000000e+00> : tensor<1xf32>}> : () -> tensor<1xf32>
%31 = "tosa.reshape"(%30) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%32 = "tosa.mul"(%29, %31) : (tensor<1x1x128xf32>, tensor<1x1x1xf32>) -> tensor<1x1x128xf32>

====================Graph Node====================
Node: sin
Type: OpType.ElementwiseType
Arguments: ['clone_1']
Parents: ['clone_1']
Children: ['mul_1']
--------------------MLIR OPS--------------------
%33 = "math.sin"(%28) <{fastmath = #arith.fastmath<none>}> : (tensor<1x1x128xf32>) -> tensor<1x1x128xf32>

====================Graph Node====================
Node: mul_1
Type: OpType.BroadcastType
Arguments: ['sin', 1.0]
Parents: ['sin']
Children: ['unsqueeze_6', 'unsqueeze_12', 'unsqueeze_18', 'unsqueeze_24', 'unsqueeze_30', 'unsqueeze_36', 'unsqueeze_42', 'unsqueeze_48', 'unsqueeze_54', 'unsqueeze_60', 'unsqueeze_66', 'unsqueeze_72', 'unsqueeze_78', 'unsqueeze_84', 'unsqueeze_90', 'unsqueeze_96', 'unsqueeze_102', 'unsqueeze_108', 'unsqueeze_114', 'unsqueeze_120', 'unsqueeze_126', 'unsqueeze_132', 'unsqueeze_138', 'unsqueeze_144', 'unsqueeze_150', 'unsqueeze_156', 'unsqueeze_162', 'unsqueeze_168']
--------------------MLIR OPS--------------------
%34 = "arith.constant"() <{value = dense<1.000000e+00> : tensor<1xf32>}> : () -> tensor<1xf32>
%35 = "tosa.reshape"(%34) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%36 = "tosa.mul"(%33, %35) : (tensor<1x1x128xf32>, tensor<1x1x1xf32>) -> tensor<1x1x128xf32>

====================Graph Node====================
Node: pow_1
Type: OpType.BroadcastType
Arguments: ['embedding', 2]
Parents: ['embedding']
Children: ['mean']
--------------------MLIR OPS--------------------
%37 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%38 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%39 = "linalg.generic"(%2, %37) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %40 = "math.fpowi"(%arg398, %38) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%40) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean
Type: OpType.ReduceType
Arguments: ['pow_1', [-1], True]
Parents: ['pow_1']
Children: ['add_1']
--------------------MLIR OPS--------------------
%40 = "tosa.reduce_sum"(%39) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%41 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%42 = "tosa.reciprocal"(%41) : (tensor<1xf32>) -> tensor<1xf32>
%43 = "tosa.reshape"(%42) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%44 = "tosa.mul"(%43, %40) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_1
Type: OpType.BroadcastType
Arguments: ['mean', 1e-06]
Parents: ['mean']
Children: ['rsqrt']
--------------------MLIR OPS--------------------
%45 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%46 = "tosa.add"(%44, %45) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt
Type: OpType.ElementwiseType
Arguments: ['add_1']
Parents: ['add_1']
Children: ['mul_2']
--------------------MLIR OPS--------------------
%47 = "tosa.rsqrt"(%46) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_2
Type: OpType.BroadcastType
Arguments: ['embedding', 'rsqrt']
Parents: ['embedding', 'rsqrt']
Children: ['mul_3']
--------------------MLIR OPS--------------------
%48 = "tosa.mul"(%2, %47) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_3
Type: OpType.BroadcastType
Arguments: ['arg60_1', 'mul_2']
Parents: ['arg60_1', 'mul_2']
Children: ['view_5', 'view_8', 'view_11']
--------------------MLIR OPS--------------------
%49 = "tosa.reshape"(%arg4) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%50 = "tosa.mul"(%49, %48) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_5
Type: OpType.ReshapeType
Arguments: ['mul_3', [1, 1536]]
Parents: ['mul_3']
Children: ['addmm']
--------------------MLIR OPS--------------------
%51 = "tosa.reshape"(%50) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_1
Type: OpType.ReshapeType
Arguments: ['arg61_1', [1, 0]]
Parents: ['arg61_1']
Children: ['addmm']
--------------------MLIR OPS--------------------
%52 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%53 = "tosa.transpose"(%arg5, %52) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm
Type: OpType.ReduceType
Arguments: ['arg62_1', 'view_5', 'permute_1']
Parents: ['arg62_1', 'view_5', 'permute_1']
Children: ['view_6']
--------------------MLIR OPS--------------------
%54 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%55 = "linalg.matmul"(%51, %53, %54) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %58 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %59 = "arith.addf"(%arg400, %58) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%59) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%56 = "tosa.reshape"(%arg6) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%57 = "tosa.add"(%56, %55) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_6
Type: OpType.ReshapeType
Arguments: ['addmm', [1, 1, 1536]]
Parents: ['addmm']
Children: ['view_7']
--------------------MLIR OPS--------------------
%58 = "tosa.reshape"(%57) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_7
Type: OpType.ReshapeType
Arguments: ['view_6', [1, 1, -1, 128]]
Parents: ['view_6']
Children: ['permute_2']
--------------------MLIR OPS--------------------
%59 = "tosa.reshape"(%58) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_2
Type: OpType.ReshapeType
Arguments: ['view_7', [0, 2, 1, 3]]
Parents: ['view_7']
Children: ['mul_4', 'slice_4', 'slice_5']
--------------------MLIR OPS--------------------
%60 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%61 = "tosa.transpose"(%59, %60) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_8
Type: OpType.ReshapeType
Arguments: ['mul_3', [1, 1536]]
Parents: ['mul_3']
Children: ['addmm_1']
--------------------MLIR OPS--------------------
%62 = "tosa.reshape"(%50) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_3
Type: OpType.ReshapeType
Arguments: ['arg63_1', [1, 0]]
Parents: ['arg63_1']
Children: ['addmm_1']
--------------------MLIR OPS--------------------
%63 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%64 = "tosa.transpose"(%arg7, %63) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_1
Type: OpType.ReduceType
Arguments: ['arg64_1', 'view_8', 'permute_3']
Parents: ['arg64_1', 'view_8', 'permute_3']
Children: ['view_9']
--------------------MLIR OPS--------------------
%65 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%66 = "linalg.matmul"(%62, %64, %65) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %69 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %70 = "arith.addf"(%arg400, %69) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%70) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%67 = "tosa.reshape"(%arg8) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%68 = "tosa.add"(%67, %66) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_9
Type: OpType.ReshapeType
Arguments: ['addmm_1', [1, 1, 256]]
Parents: ['addmm_1']
Children: ['view_10']
--------------------MLIR OPS--------------------
%69 = "tosa.reshape"(%68) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_10
Type: OpType.ReshapeType
Arguments: ['view_9', [1, 1, -1, 128]]
Parents: ['view_9']
Children: ['permute_4']
--------------------MLIR OPS--------------------
%70 = "tosa.reshape"(%69) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_4
Type: OpType.ReshapeType
Arguments: ['view_10', [0, 2, 1, 3]]
Parents: ['view_10']
Children: ['mul_6', 'slice_6', 'slice_7']
--------------------MLIR OPS--------------------
%71 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%72 = "tosa.transpose"(%70, %71) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_11
Type: OpType.ReshapeType
Arguments: ['mul_3', [1, 1536]]
Parents: ['mul_3']
Children: ['addmm_2']
--------------------MLIR OPS--------------------
%73 = "tosa.reshape"(%50) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_5
Type: OpType.ReshapeType
Arguments: ['arg65_1', [1, 0]]
Parents: ['arg65_1']
Children: ['addmm_2']
--------------------MLIR OPS--------------------
%74 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%75 = "tosa.transpose"(%arg9, %74) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_2
Type: OpType.ReduceType
Arguments: ['arg66_1', 'view_11', 'permute_5']
Parents: ['arg66_1', 'view_11', 'permute_5']
Children: ['view_12']
--------------------MLIR OPS--------------------
%76 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%77 = "linalg.matmul"(%73, %75, %76) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %80 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %81 = "arith.addf"(%arg400, %80) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%81) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%78 = "tosa.reshape"(%arg10) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%79 = "tosa.add"(%78, %77) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_12
Type: OpType.ReshapeType
Arguments: ['addmm_2', [1, 1, 256]]
Parents: ['addmm_2']
Children: ['view_13']
--------------------MLIR OPS--------------------
%80 = "tosa.reshape"(%79) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_13
Type: OpType.ReshapeType
Arguments: ['view_12', [1, 1, -1, 128]]
Parents: ['view_12']
Children: ['permute_6']
--------------------MLIR OPS--------------------
%81 = "tosa.reshape"(%80) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_6
Type: OpType.ReshapeType
Arguments: ['view_13', [0, 2, 1, 3]]
Parents: ['view_13']
Children: ['index_put_1']
--------------------MLIR OPS--------------------
%82 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%83 = "tosa.transpose"(%81, %82) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_5
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_4', 'mul_6']
--------------------MLIR OPS--------------------
%84 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_6
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_5', 'mul_7']
--------------------MLIR OPS--------------------
%85 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_4
Type: OpType.BroadcastType
Arguments: ['permute_2', 'unsqueeze_5']
Parents: ['permute_2', 'unsqueeze_5']
Children: ['add_2']
--------------------MLIR OPS--------------------
%86 = "tosa.mul"(%61, %84) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_4
Type: OpType.ReshapeType
Arguments: ['permute_2', 3, 0, 64]
Parents: ['permute_2']
Children: ['cat']
--------------------MLIR OPS--------------------
%87 = "tensor.extract_slice"(%61) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_5
Type: OpType.ReshapeType
Arguments: ['permute_2', 3, 64, 9223372036854775807]
Parents: ['permute_2']
Children: ['neg']
--------------------MLIR OPS--------------------
%88 = "tensor.extract_slice"(%61) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg
Type: OpType.ElementwiseType
Arguments: ['slice_5']
Parents: ['slice_5']
Children: ['cat']
--------------------MLIR OPS--------------------
%89 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%90 = "linalg.negf"(%88, %89) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %91 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%91) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat
Type: OpType.ConcatType
Arguments: [[neg, slice_4], -1]
Parents: []
Children: ['mul_5']
--------------------MLIR OPS--------------------
%91 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%92 = "tensor.insert_slice"(%90, %91) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%93 = "tensor.insert_slice"(%87, %92) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_5
Type: OpType.BroadcastType
Arguments: ['cat', 'unsqueeze_6']
Parents: ['cat', 'unsqueeze_6']
Children: ['add_2']
--------------------MLIR OPS--------------------
%94 = "tosa.mul"(%93, %85) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_2
Type: OpType.BroadcastType
Arguments: ['mul_4', 'mul_5']
Parents: ['mul_4', 'mul_5']
Children: ['_scaled_dot_product_flash_attention_for_cpu']
--------------------MLIR OPS--------------------
%95 = "tosa.add"(%86, %94) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_6
Type: OpType.BroadcastType
Arguments: ['permute_4', 'unsqueeze_5']
Parents: ['permute_4', 'unsqueeze_5']
Children: ['add_3']
--------------------MLIR OPS--------------------
%96 = "tosa.mul"(%72, %84) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_6
Type: OpType.ReshapeType
Arguments: ['permute_4', 3, 0, 64]
Parents: ['permute_4']
Children: ['cat_1']
--------------------MLIR OPS--------------------
%97 = "tensor.extract_slice"(%72) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_7
Type: OpType.ReshapeType
Arguments: ['permute_4', 3, 64, 9223372036854775807]
Parents: ['permute_4']
Children: ['neg_1']
--------------------MLIR OPS--------------------
%98 = "tensor.extract_slice"(%72) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_1
Type: OpType.ElementwiseType
Arguments: ['slice_7']
Parents: ['slice_7']
Children: ['cat_1']
--------------------MLIR OPS--------------------
%99 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%100 = "linalg.negf"(%98, %99) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %101 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%101) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_1
Type: OpType.ConcatType
Arguments: [[neg_1, slice_6], -1]
Parents: []
Children: ['mul_7']
--------------------MLIR OPS--------------------
%101 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%102 = "tensor.insert_slice"(%100, %101) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%103 = "tensor.insert_slice"(%97, %102) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_7
Type: OpType.BroadcastType
Arguments: ['cat_1', 'unsqueeze_6']
Parents: ['cat_1', 'unsqueeze_6']
Children: ['add_3']
--------------------MLIR OPS--------------------
%104 = "tosa.mul"(%103, %85) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_3
Type: OpType.BroadcastType
Arguments: ['mul_6', 'mul_7']
Parents: ['mul_6', 'mul_7']
Children: ['index_put']
--------------------MLIR OPS--------------------
%105 = "tosa.add"(%96, %104) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put
Type: OpType.ElementwiseType
Arguments: ['arg0_1', [None, None, arg58_1], 'add_3']
Parents: ['arg0_1', 'add_3']
Children: ['slice_12', 'output']
--------------------MLIR OPS--------------------
%106 = "bufferization.to_memref"(%arg11) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%107 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%108 = "bufferization.to_memref"(%105) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%109 = "arith.constant"() <{value = 0 : index}> : () -> index
%110 = "arith.constant"() <{value = 1 : index}> : () -> index
%111 = "arith.constant"() <{value = 1 : index}> : () -> index
%112 = "arith.constant"() <{value = 2 : index}> : () -> index
%113 = "arith.constant"() <{value = 1 : index}> : () -> index
%114 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%109, %111, %110) ({
^bb0(%arg398: index):
  "scf.for"(%109, %112, %110) ({
  ^bb0(%arg399: index):
    "scf.for"(%109, %113, %110) ({
    ^bb0(%arg400: index):
      %116 = "memref.load"(%107, %arg400) : (memref<1xi64>, index) -> i64
      %117 = "arith.index_cast"(%116) : (i64) -> index
      "scf.for"(%109, %114, %110) ({
      ^bb0(%arg401: index):
        %118 = "memref.load"(%108, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%118, %106, %arg398, %arg399, %117, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%115 = "bufferization.to_tensor"(%106) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_1
Type: OpType.ElementwiseType
Arguments: ['arg1_1', [None, None, arg58_1], 'permute_6']
Parents: ['arg1_1', 'permute_6']
Children: ['slice_20', 'output']
--------------------MLIR OPS--------------------
%116 = "bufferization.to_memref"(%arg12) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%117 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%118 = "bufferization.to_memref"(%83) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%119 = "arith.constant"() <{value = 0 : index}> : () -> index
%120 = "arith.constant"() <{value = 1 : index}> : () -> index
%121 = "arith.constant"() <{value = 1 : index}> : () -> index
%122 = "arith.constant"() <{value = 2 : index}> : () -> index
%123 = "arith.constant"() <{value = 1 : index}> : () -> index
%124 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%119, %121, %120) ({
^bb0(%arg398: index):
  "scf.for"(%119, %122, %120) ({
  ^bb0(%arg399: index):
    "scf.for"(%119, %123, %120) ({
    ^bb0(%arg400: index):
      %126 = "memref.load"(%117, %arg400) : (memref<1xi64>, index) -> i64
      %127 = "arith.index_cast"(%126) : (i64) -> index
      "scf.for"(%119, %124, %120) ({
      ^bb0(%arg401: index):
        %128 = "memref.load"(%118, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%128, %116, %arg398, %arg399, %127, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%125 = "bufferization.to_tensor"(%116) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_12
Type: OpType.ReshapeType
Arguments: ['index_put', 0, 0, 9223372036854775807]
Parents: ['index_put']
Children: ['slice_13']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_13
Type: OpType.ReshapeType
Arguments: ['slice_12', 1, 0, 9223372036854775807]
Parents: ['slice_12']
Children: ['unsqueeze_8']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_8
Type: OpType.ReshapeType
Arguments: ['slice_13', 2]
Parents: ['slice_13']
Children: ['slice_14']
--------------------MLIR OPS--------------------
%126 = "tosa.reshape"(%115) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_14
Type: OpType.ReshapeType
Arguments: ['unsqueeze_8', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_8']
Children: ['slice_15']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_15
Type: OpType.ReshapeType
Arguments: ['slice_14', 4, 0, 9223372036854775807]
Parents: ['slice_14']
Children: ['expand_7']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_7
Type: OpType.ReshapeType
Arguments: ['slice_15', [1, 2, 6, 1024, 128]]
Parents: ['slice_15']
Children: ['clone_2']
--------------------MLIR OPS--------------------
%127 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%128 = "tosa.add"(%126, %127) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_2
Type: OpType.ReduceType
Arguments: ['expand_7']
Parents: ['expand_7']
Children: ['view_14']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_14
Type: OpType.ReshapeType
Arguments: ['clone_2', [1, 12, 1024, 128]]
Parents: ['clone_2']
Children: ['_scaled_dot_product_flash_attention_for_cpu']
--------------------MLIR OPS--------------------
%129 = "tosa.reshape"(%128) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_20
Type: OpType.ReshapeType
Arguments: ['index_put_1', 0, 0, 9223372036854775807]
Parents: ['index_put_1']
Children: ['slice_21']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_21
Type: OpType.ReshapeType
Arguments: ['slice_20', 1, 0, 9223372036854775807]
Parents: ['slice_20']
Children: ['unsqueeze_10']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_10
Type: OpType.ReshapeType
Arguments: ['slice_21', 2]
Parents: ['slice_21']
Children: ['slice_22']
--------------------MLIR OPS--------------------
%130 = "tosa.reshape"(%125) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_22
Type: OpType.ReshapeType
Arguments: ['unsqueeze_10', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_10']
Children: ['slice_23']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_23
Type: OpType.ReshapeType
Arguments: ['slice_22', 4, 0, 9223372036854775807]
Parents: ['slice_22']
Children: ['expand_9']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_9
Type: OpType.ReshapeType
Arguments: ['slice_23', [1, 2, 6, 1024, 128]]
Parents: ['slice_23']
Children: ['clone_3']
--------------------MLIR OPS--------------------
%131 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%132 = "tosa.add"(%130, %131) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_3
Type: OpType.ReduceType
Arguments: ['expand_9']
Parents: ['expand_9']
Children: ['view_15']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_15
Type: OpType.ReshapeType
Arguments: ['clone_3', [1, 12, 1024, 128]]
Parents: ['clone_3']
Children: ['_scaled_dot_product_flash_attention_for_cpu']
--------------------MLIR OPS--------------------
%133 = "tosa.reshape"(%132) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_24
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_25']
--------------------MLIR OPS--------------------
%134 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_25
Type: OpType.ReshapeType
Arguments: ['slice_24', 1, 0, 9223372036854775807]
Parents: ['slice_24']
Children: ['slice_26']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_26
Type: OpType.ReshapeType
Arguments: ['slice_25', 2, 0, 9223372036854775807]
Parents: ['slice_25']
Children: ['where']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where']
--------------------MLIR OPS--------------------
%135 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_1
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where']
--------------------MLIR OPS--------------------
%136 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where
Type: OpType.ElementwiseType
Arguments: ['slice_26', 'scalar_tensor_1', 'scalar_tensor']
Parents: ['slice_26', 'scalar_tensor_1', 'scalar_tensor']
Children: ['_scaled_dot_product_flash_attention_for_cpu']
--------------------MLIR OPS--------------------
%137 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%138 = "tensor.splat"(%136) : (f32) -> tensor<1x1x1x1024xf32>
%139 = "tensor.splat"(%135) : (f32) -> tensor<1x1x1x1024xf32>
%140 = "linalg.generic"(%134, %138, %139, %137) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %141 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%141) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu
Type: OpType.ElementwiseType
Arguments: ['add_2', 'view_14', 'view_15']
Parents: ['add_2', 'view_14', 'view_15']
Children: ['getitem']
--------------------MLIR OPS--------------------
%141 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%142 = "tensor.splat"(%141) : (f32) -> tensor<1x1024xf32>
%143 = "tosa.reshape"(%140) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%144 = "tosa.add"(%142, %143) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%145 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%146 = "tosa.transpose"(%129, %145) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%147 = "tosa.reshape"(%95) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%148 = "tosa.reshape"(%146) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%149 = "tosa.matmul"(%147, %148) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%150 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%151 = "tensor.splat"(%150) : (f32) -> tensor<12x1x1024xf32>
%152 = "tosa.mul"(%149, %151) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%153 = "tosa.reshape"(%144) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%154 = "tosa.add"(%152, %153) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%155 = "tosa.reduce_max"(%154) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%156 = "tosa.sub"(%154, %155) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%157 = "math.exp"(%156) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%158 = "tosa.reduce_sum"(%157) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%159 = "tosa.log"(%158) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%160 = "tosa.add"(%155, %159) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%161 = "tosa.sub"(%154, %160) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%162 = "math.exp"(%161) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%163 = "tosa.reshape"(%160) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%164 = "tosa.reshape"(%133) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%165 = "tosa.matmul"(%162, %164) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%166 = "tosa.reshape"(%165) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu']
Children: ['permute_7']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_7
Type: OpType.ReshapeType
Arguments: ['getitem', [0, 2, 1, 3]]
Parents: ['getitem']
Children: ['view_16']
--------------------MLIR OPS--------------------
%167 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%168 = "tosa.transpose"(%166, %167) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_16
Type: OpType.ReshapeType
Arguments: ['permute_7', [1, 1, -1]]
Parents: ['permute_7']
Children: ['view_17']
--------------------MLIR OPS--------------------
%169 = "tosa.reshape"(%168) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_8
Type: OpType.ReshapeType
Arguments: ['arg67_1', [1, 0]]
Parents: ['arg67_1']
Children: ['mm']
--------------------MLIR OPS--------------------
%170 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%171 = "tosa.transpose"(%arg13, %170) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_17
Type: OpType.ReshapeType
Arguments: ['view_16', [1, 1536]]
Parents: ['view_16']
Children: ['mm']
--------------------MLIR OPS--------------------
%172 = "tosa.reshape"(%169) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm
Type: OpType.ReduceType
Arguments: ['view_17', 'permute_8']
Parents: ['view_17', 'permute_8']
Children: ['view_18']
--------------------MLIR OPS--------------------
%173 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%174 = "linalg.matmul"(%172, %171, %173) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %175 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %176 = "arith.addf"(%arg400, %175) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%176) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_18
Type: OpType.ReshapeType
Arguments: ['mm', [1, 1, 1536]]
Parents: ['mm']
Children: ['add_4']
--------------------MLIR OPS--------------------
%175 = "tosa.reshape"(%174) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_4
Type: OpType.BroadcastType
Arguments: ['embedding', 'view_18']
Parents: ['embedding', 'view_18']
Children: ['pow_2', 'mul_8', 'add_6']
--------------------MLIR OPS--------------------
%176 = "tosa.add"(%2, %175) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_2
Type: OpType.BroadcastType
Arguments: ['add_4', 2]
Parents: ['add_4']
Children: ['mean_1']
--------------------MLIR OPS--------------------
%177 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%178 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%179 = "linalg.generic"(%176, %177) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %180 = "math.fpowi"(%arg398, %178) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%180) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_1
Type: OpType.ReduceType
Arguments: ['pow_2', [-1], True]
Parents: ['pow_2']
Children: ['add_5']
--------------------MLIR OPS--------------------
%180 = "tosa.reduce_sum"(%179) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%181 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%182 = "tosa.reciprocal"(%181) : (tensor<1xf32>) -> tensor<1xf32>
%183 = "tosa.reshape"(%182) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%184 = "tosa.mul"(%183, %180) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_5
Type: OpType.BroadcastType
Arguments: ['mean_1', 1e-06]
Parents: ['mean_1']
Children: ['rsqrt_1']
--------------------MLIR OPS--------------------
%185 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%186 = "tosa.add"(%184, %185) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_1
Type: OpType.ElementwiseType
Arguments: ['add_5']
Parents: ['add_5']
Children: ['mul_8']
--------------------MLIR OPS--------------------
%187 = "tosa.rsqrt"(%186) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_8
Type: OpType.BroadcastType
Arguments: ['add_4', 'rsqrt_1']
Parents: ['add_4', 'rsqrt_1']
Children: ['mul_9']
--------------------MLIR OPS--------------------
%188 = "tosa.mul"(%176, %187) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_9
Type: OpType.BroadcastType
Arguments: ['arg68_1', 'mul_8']
Parents: ['arg68_1', 'mul_8']
Children: ['view_19', 'view_21']
--------------------MLIR OPS--------------------
%189 = "tosa.reshape"(%arg14) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%190 = "tosa.mul"(%189, %188) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_9
Type: OpType.ReshapeType
Arguments: ['arg69_1', [1, 0]]
Parents: ['arg69_1']
Children: ['mm_1']
--------------------MLIR OPS--------------------
%191 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%192 = "tosa.transpose"(%arg15, %191) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_19
Type: OpType.ReshapeType
Arguments: ['mul_9', [1, 1536]]
Parents: ['mul_9']
Children: ['mm_1']
--------------------MLIR OPS--------------------
%193 = "tosa.reshape"(%190) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_1
Type: OpType.ReduceType
Arguments: ['view_19', 'permute_9']
Parents: ['view_19', 'permute_9']
Children: ['view_20']
--------------------MLIR OPS--------------------
%194 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%195 = "linalg.matmul"(%193, %192, %194) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %196 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %197 = "arith.addf"(%arg400, %196) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%197) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_20
Type: OpType.ReshapeType
Arguments: ['mm_1', [1, 1, 8960]]
Parents: ['mm_1']
Children: ['sigmoid', 'mul_10']
--------------------MLIR OPS--------------------
%196 = "tosa.reshape"(%195) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid
Type: OpType.ElementwiseType
Arguments: ['view_20']
Parents: ['view_20']
Children: ['mul_10']
--------------------MLIR OPS--------------------
%197 = "tosa.sigmoid"(%196) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_10
Type: OpType.BroadcastType
Arguments: ['view_20', 'sigmoid']
Parents: ['view_20', 'sigmoid']
Children: ['mul_11']
--------------------MLIR OPS--------------------
%198 = "tosa.mul"(%196, %197) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_10
Type: OpType.ReshapeType
Arguments: ['arg70_1', [1, 0]]
Parents: ['arg70_1']
Children: ['mm_2']
--------------------MLIR OPS--------------------
%199 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%200 = "tosa.transpose"(%arg16, %199) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_21
Type: OpType.ReshapeType
Arguments: ['mul_9', [1, 1536]]
Parents: ['mul_9']
Children: ['mm_2']
--------------------MLIR OPS--------------------
%201 = "tosa.reshape"(%190) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_2
Type: OpType.ReduceType
Arguments: ['view_21', 'permute_10']
Parents: ['view_21', 'permute_10']
Children: ['view_22']
--------------------MLIR OPS--------------------
%202 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%203 = "linalg.matmul"(%201, %200, %202) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %204 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %205 = "arith.addf"(%arg400, %204) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%205) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_22
Type: OpType.ReshapeType
Arguments: ['mm_2', [1, 1, 8960]]
Parents: ['mm_2']
Children: ['mul_11']
--------------------MLIR OPS--------------------
%204 = "tosa.reshape"(%203) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_11
Type: OpType.BroadcastType
Arguments: ['mul_10', 'view_22']
Parents: ['mul_10', 'view_22']
Children: ['view_23']
--------------------MLIR OPS--------------------
%205 = "tosa.mul"(%198, %204) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_11
Type: OpType.ReshapeType
Arguments: ['arg71_1', [1, 0]]
Parents: ['arg71_1']
Children: ['mm_3']
--------------------MLIR OPS--------------------
%206 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%207 = "tosa.transpose"(%arg17, %206) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_23
Type: OpType.ReshapeType
Arguments: ['mul_11', [1, 8960]]
Parents: ['mul_11']
Children: ['mm_3']
--------------------MLIR OPS--------------------
%208 = "tosa.reshape"(%205) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_3
Type: OpType.ReduceType
Arguments: ['view_23', 'permute_11']
Parents: ['view_23', 'permute_11']
Children: ['view_24']
--------------------MLIR OPS--------------------
%209 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%210 = "linalg.matmul"(%208, %207, %209) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %211 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %212 = "arith.addf"(%arg400, %211) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%212) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_24
Type: OpType.ReshapeType
Arguments: ['mm_3', [1, 1, 1536]]
Parents: ['mm_3']
Children: ['add_6']
--------------------MLIR OPS--------------------
%211 = "tosa.reshape"(%210) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_6
Type: OpType.BroadcastType
Arguments: ['add_4', 'view_24']
Parents: ['add_4', 'view_24']
Children: ['pow_3', 'mul_12', 'add_10']
--------------------MLIR OPS--------------------
%212 = "tosa.add"(%176, %211) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_3
Type: OpType.BroadcastType
Arguments: ['add_6', 2]
Parents: ['add_6']
Children: ['mean_2']
--------------------MLIR OPS--------------------
%213 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%214 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%215 = "linalg.generic"(%212, %213) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %216 = "math.fpowi"(%arg398, %214) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%216) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_2
Type: OpType.ReduceType
Arguments: ['pow_3', [-1], True]
Parents: ['pow_3']
Children: ['add_7']
--------------------MLIR OPS--------------------
%216 = "tosa.reduce_sum"(%215) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%217 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%218 = "tosa.reciprocal"(%217) : (tensor<1xf32>) -> tensor<1xf32>
%219 = "tosa.reshape"(%218) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%220 = "tosa.mul"(%219, %216) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_7
Type: OpType.BroadcastType
Arguments: ['mean_2', 1e-06]
Parents: ['mean_2']
Children: ['rsqrt_2']
--------------------MLIR OPS--------------------
%221 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%222 = "tosa.add"(%220, %221) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_2
Type: OpType.ElementwiseType
Arguments: ['add_7']
Parents: ['add_7']
Children: ['mul_12']
--------------------MLIR OPS--------------------
%223 = "tosa.rsqrt"(%222) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_12
Type: OpType.BroadcastType
Arguments: ['add_6', 'rsqrt_2']
Parents: ['add_6', 'rsqrt_2']
Children: ['mul_13']
--------------------MLIR OPS--------------------
%224 = "tosa.mul"(%212, %223) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_13
Type: OpType.BroadcastType
Arguments: ['arg72_1', 'mul_12']
Parents: ['arg72_1', 'mul_12']
Children: ['view_25', 'view_28', 'view_31']
--------------------MLIR OPS--------------------
%225 = "tosa.reshape"(%arg18) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%226 = "tosa.mul"(%225, %224) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_25
Type: OpType.ReshapeType
Arguments: ['mul_13', [1, 1536]]
Parents: ['mul_13']
Children: ['addmm_3']
--------------------MLIR OPS--------------------
%227 = "tosa.reshape"(%226) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_12
Type: OpType.ReshapeType
Arguments: ['arg73_1', [1, 0]]
Parents: ['arg73_1']
Children: ['addmm_3']
--------------------MLIR OPS--------------------
%228 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%229 = "tosa.transpose"(%arg19, %228) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_3
Type: OpType.ReduceType
Arguments: ['arg74_1', 'view_25', 'permute_12']
Parents: ['arg74_1', 'view_25', 'permute_12']
Children: ['view_26']
--------------------MLIR OPS--------------------
%230 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%231 = "linalg.matmul"(%227, %229, %230) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %234 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %235 = "arith.addf"(%arg400, %234) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%235) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%232 = "tosa.reshape"(%arg20) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%233 = "tosa.add"(%232, %231) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_26
Type: OpType.ReshapeType
Arguments: ['addmm_3', [1, 1, 1536]]
Parents: ['addmm_3']
Children: ['view_27']
--------------------MLIR OPS--------------------
%234 = "tosa.reshape"(%233) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_27
Type: OpType.ReshapeType
Arguments: ['view_26', [1, 1, -1, 128]]
Parents: ['view_26']
Children: ['permute_13']
--------------------MLIR OPS--------------------
%235 = "tosa.reshape"(%234) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_13
Type: OpType.ReshapeType
Arguments: ['view_27', [0, 2, 1, 3]]
Parents: ['view_27']
Children: ['mul_14', 'slice_27', 'slice_28']
--------------------MLIR OPS--------------------
%236 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%237 = "tosa.transpose"(%235, %236) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_28
Type: OpType.ReshapeType
Arguments: ['mul_13', [1, 1536]]
Parents: ['mul_13']
Children: ['addmm_4']
--------------------MLIR OPS--------------------
%238 = "tosa.reshape"(%226) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_14
Type: OpType.ReshapeType
Arguments: ['arg75_1', [1, 0]]
Parents: ['arg75_1']
Children: ['addmm_4']
--------------------MLIR OPS--------------------
%239 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%240 = "tosa.transpose"(%arg21, %239) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_4
Type: OpType.ReduceType
Arguments: ['arg76_1', 'view_28', 'permute_14']
Parents: ['arg76_1', 'view_28', 'permute_14']
Children: ['view_29']
--------------------MLIR OPS--------------------
%241 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%242 = "linalg.matmul"(%238, %240, %241) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %245 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %246 = "arith.addf"(%arg400, %245) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%246) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%243 = "tosa.reshape"(%arg22) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%244 = "tosa.add"(%243, %242) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_29
Type: OpType.ReshapeType
Arguments: ['addmm_4', [1, 1, 256]]
Parents: ['addmm_4']
Children: ['view_30']
--------------------MLIR OPS--------------------
%245 = "tosa.reshape"(%244) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_30
Type: OpType.ReshapeType
Arguments: ['view_29', [1, 1, -1, 128]]
Parents: ['view_29']
Children: ['permute_15']
--------------------MLIR OPS--------------------
%246 = "tosa.reshape"(%245) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_15
Type: OpType.ReshapeType
Arguments: ['view_30', [0, 2, 1, 3]]
Parents: ['view_30']
Children: ['mul_16', 'slice_29', 'slice_30']
--------------------MLIR OPS--------------------
%247 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%248 = "tosa.transpose"(%246, %247) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_31
Type: OpType.ReshapeType
Arguments: ['mul_13', [1, 1536]]
Parents: ['mul_13']
Children: ['addmm_5']
--------------------MLIR OPS--------------------
%249 = "tosa.reshape"(%226) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_16
Type: OpType.ReshapeType
Arguments: ['arg77_1', [1, 0]]
Parents: ['arg77_1']
Children: ['addmm_5']
--------------------MLIR OPS--------------------
%250 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%251 = "tosa.transpose"(%arg23, %250) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_5
Type: OpType.ReduceType
Arguments: ['arg78_1', 'view_31', 'permute_16']
Parents: ['arg78_1', 'view_31', 'permute_16']
Children: ['view_32']
--------------------MLIR OPS--------------------
%252 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%253 = "linalg.matmul"(%249, %251, %252) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %256 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %257 = "arith.addf"(%arg400, %256) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%257) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%254 = "tosa.reshape"(%arg24) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%255 = "tosa.add"(%254, %253) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_32
Type: OpType.ReshapeType
Arguments: ['addmm_5', [1, 1, 256]]
Parents: ['addmm_5']
Children: ['view_33']
--------------------MLIR OPS--------------------
%256 = "tosa.reshape"(%255) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_33
Type: OpType.ReshapeType
Arguments: ['view_32', [1, 1, -1, 128]]
Parents: ['view_32']
Children: ['permute_17']
--------------------MLIR OPS--------------------
%257 = "tosa.reshape"(%256) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_17
Type: OpType.ReshapeType
Arguments: ['view_33', [0, 2, 1, 3]]
Parents: ['view_33']
Children: ['index_put_3']
--------------------MLIR OPS--------------------
%258 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%259 = "tosa.transpose"(%257, %258) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_11
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_14', 'mul_16']
--------------------MLIR OPS--------------------
%260 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_12
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_15', 'mul_17']
--------------------MLIR OPS--------------------
%261 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_14
Type: OpType.BroadcastType
Arguments: ['permute_13', 'unsqueeze_11']
Parents: ['permute_13', 'unsqueeze_11']
Children: ['add_8']
--------------------MLIR OPS--------------------
%262 = "tosa.mul"(%237, %260) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_27
Type: OpType.ReshapeType
Arguments: ['permute_13', 3, 0, 64]
Parents: ['permute_13']
Children: ['cat_2']
--------------------MLIR OPS--------------------
%263 = "tensor.extract_slice"(%237) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_28
Type: OpType.ReshapeType
Arguments: ['permute_13', 3, 64, 9223372036854775807]
Parents: ['permute_13']
Children: ['neg_2']
--------------------MLIR OPS--------------------
%264 = "tensor.extract_slice"(%237) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_2
Type: OpType.ElementwiseType
Arguments: ['slice_28']
Parents: ['slice_28']
Children: ['cat_2']
--------------------MLIR OPS--------------------
%265 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%266 = "linalg.negf"(%264, %265) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %267 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%267) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_2
Type: OpType.ConcatType
Arguments: [[neg_2, slice_27], -1]
Parents: []
Children: ['mul_15']
--------------------MLIR OPS--------------------
%267 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%268 = "tensor.insert_slice"(%266, %267) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%269 = "tensor.insert_slice"(%263, %268) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_15
Type: OpType.BroadcastType
Arguments: ['cat_2', 'unsqueeze_12']
Parents: ['cat_2', 'unsqueeze_12']
Children: ['add_8']
--------------------MLIR OPS--------------------
%270 = "tosa.mul"(%269, %261) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_8
Type: OpType.BroadcastType
Arguments: ['mul_14', 'mul_15']
Parents: ['mul_14', 'mul_15']
Children: ['_scaled_dot_product_flash_attention_for_cpu_1']
--------------------MLIR OPS--------------------
%271 = "tosa.add"(%262, %270) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_16
Type: OpType.BroadcastType
Arguments: ['permute_15', 'unsqueeze_11']
Parents: ['permute_15', 'unsqueeze_11']
Children: ['add_9']
--------------------MLIR OPS--------------------
%272 = "tosa.mul"(%248, %260) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_29
Type: OpType.ReshapeType
Arguments: ['permute_15', 3, 0, 64]
Parents: ['permute_15']
Children: ['cat_3']
--------------------MLIR OPS--------------------
%273 = "tensor.extract_slice"(%248) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_30
Type: OpType.ReshapeType
Arguments: ['permute_15', 3, 64, 9223372036854775807]
Parents: ['permute_15']
Children: ['neg_3']
--------------------MLIR OPS--------------------
%274 = "tensor.extract_slice"(%248) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_3
Type: OpType.ElementwiseType
Arguments: ['slice_30']
Parents: ['slice_30']
Children: ['cat_3']
--------------------MLIR OPS--------------------
%275 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%276 = "linalg.negf"(%274, %275) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %277 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%277) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_3
Type: OpType.ConcatType
Arguments: [[neg_3, slice_29], -1]
Parents: []
Children: ['mul_17']
--------------------MLIR OPS--------------------
%277 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%278 = "tensor.insert_slice"(%276, %277) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%279 = "tensor.insert_slice"(%273, %278) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_17
Type: OpType.BroadcastType
Arguments: ['cat_3', 'unsqueeze_12']
Parents: ['cat_3', 'unsqueeze_12']
Children: ['add_9']
--------------------MLIR OPS--------------------
%280 = "tosa.mul"(%279, %261) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_9
Type: OpType.BroadcastType
Arguments: ['mul_16', 'mul_17']
Parents: ['mul_16', 'mul_17']
Children: ['index_put_2']
--------------------MLIR OPS--------------------
%281 = "tosa.add"(%272, %280) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_2
Type: OpType.ElementwiseType
Arguments: ['arg2_1', [None, None, arg58_1], 'add_9']
Parents: ['arg2_1', 'add_9']
Children: ['slice_35', 'output']
--------------------MLIR OPS--------------------
%282 = "bufferization.to_memref"(%arg25) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%283 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%284 = "bufferization.to_memref"(%281) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%285 = "arith.constant"() <{value = 0 : index}> : () -> index
%286 = "arith.constant"() <{value = 1 : index}> : () -> index
%287 = "arith.constant"() <{value = 1 : index}> : () -> index
%288 = "arith.constant"() <{value = 2 : index}> : () -> index
%289 = "arith.constant"() <{value = 1 : index}> : () -> index
%290 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%285, %287, %286) ({
^bb0(%arg398: index):
  "scf.for"(%285, %288, %286) ({
  ^bb0(%arg399: index):
    "scf.for"(%285, %289, %286) ({
    ^bb0(%arg400: index):
      %292 = "memref.load"(%283, %arg400) : (memref<1xi64>, index) -> i64
      %293 = "arith.index_cast"(%292) : (i64) -> index
      "scf.for"(%285, %290, %286) ({
      ^bb0(%arg401: index):
        %294 = "memref.load"(%284, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%294, %282, %arg398, %arg399, %293, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%291 = "bufferization.to_tensor"(%282) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_3
Type: OpType.ElementwiseType
Arguments: ['arg3_1', [None, None, arg58_1], 'permute_17']
Parents: ['arg3_1', 'permute_17']
Children: ['slice_43', 'output']
--------------------MLIR OPS--------------------
%292 = "bufferization.to_memref"(%arg26) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%293 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%294 = "bufferization.to_memref"(%259) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%295 = "arith.constant"() <{value = 0 : index}> : () -> index
%296 = "arith.constant"() <{value = 1 : index}> : () -> index
%297 = "arith.constant"() <{value = 1 : index}> : () -> index
%298 = "arith.constant"() <{value = 2 : index}> : () -> index
%299 = "arith.constant"() <{value = 1 : index}> : () -> index
%300 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%295, %297, %296) ({
^bb0(%arg398: index):
  "scf.for"(%295, %298, %296) ({
  ^bb0(%arg399: index):
    "scf.for"(%295, %299, %296) ({
    ^bb0(%arg400: index):
      %302 = "memref.load"(%293, %arg400) : (memref<1xi64>, index) -> i64
      %303 = "arith.index_cast"(%302) : (i64) -> index
      "scf.for"(%295, %300, %296) ({
      ^bb0(%arg401: index):
        %304 = "memref.load"(%294, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%304, %292, %arg398, %arg399, %303, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%301 = "bufferization.to_tensor"(%292) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_35
Type: OpType.ReshapeType
Arguments: ['index_put_2', 0, 0, 9223372036854775807]
Parents: ['index_put_2']
Children: ['slice_36']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_36
Type: OpType.ReshapeType
Arguments: ['slice_35', 1, 0, 9223372036854775807]
Parents: ['slice_35']
Children: ['unsqueeze_14']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_14
Type: OpType.ReshapeType
Arguments: ['slice_36', 2]
Parents: ['slice_36']
Children: ['slice_37']
--------------------MLIR OPS--------------------
%302 = "tosa.reshape"(%291) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_37
Type: OpType.ReshapeType
Arguments: ['unsqueeze_14', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_14']
Children: ['slice_38']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_38
Type: OpType.ReshapeType
Arguments: ['slice_37', 4, 0, 9223372036854775807]
Parents: ['slice_37']
Children: ['expand_11']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_11
Type: OpType.ReshapeType
Arguments: ['slice_38', [1, 2, 6, 1024, 128]]
Parents: ['slice_38']
Children: ['clone_4']
--------------------MLIR OPS--------------------
%303 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%304 = "tosa.add"(%302, %303) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_4
Type: OpType.ReduceType
Arguments: ['expand_11']
Parents: ['expand_11']
Children: ['view_34']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_34
Type: OpType.ReshapeType
Arguments: ['clone_4', [1, 12, 1024, 128]]
Parents: ['clone_4']
Children: ['_scaled_dot_product_flash_attention_for_cpu_1']
--------------------MLIR OPS--------------------
%305 = "tosa.reshape"(%304) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_43
Type: OpType.ReshapeType
Arguments: ['index_put_3', 0, 0, 9223372036854775807]
Parents: ['index_put_3']
Children: ['slice_44']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_44
Type: OpType.ReshapeType
Arguments: ['slice_43', 1, 0, 9223372036854775807]
Parents: ['slice_43']
Children: ['unsqueeze_16']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_16
Type: OpType.ReshapeType
Arguments: ['slice_44', 2]
Parents: ['slice_44']
Children: ['slice_45']
--------------------MLIR OPS--------------------
%306 = "tosa.reshape"(%301) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_45
Type: OpType.ReshapeType
Arguments: ['unsqueeze_16', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_16']
Children: ['slice_46']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_46
Type: OpType.ReshapeType
Arguments: ['slice_45', 4, 0, 9223372036854775807]
Parents: ['slice_45']
Children: ['expand_13']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_13
Type: OpType.ReshapeType
Arguments: ['slice_46', [1, 2, 6, 1024, 128]]
Parents: ['slice_46']
Children: ['clone_5']
--------------------MLIR OPS--------------------
%307 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%308 = "tosa.add"(%306, %307) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_5
Type: OpType.ReduceType
Arguments: ['expand_13']
Parents: ['expand_13']
Children: ['view_35']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_35
Type: OpType.ReshapeType
Arguments: ['clone_5', [1, 12, 1024, 128]]
Parents: ['clone_5']
Children: ['_scaled_dot_product_flash_attention_for_cpu_1']
--------------------MLIR OPS--------------------
%309 = "tosa.reshape"(%308) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_47
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_48']
--------------------MLIR OPS--------------------
%310 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_48
Type: OpType.ReshapeType
Arguments: ['slice_47', 1, 0, 9223372036854775807]
Parents: ['slice_47']
Children: ['slice_49']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_49
Type: OpType.ReshapeType
Arguments: ['slice_48', 2, 0, 9223372036854775807]
Parents: ['slice_48']
Children: ['where_1']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_2
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_1']
--------------------MLIR OPS--------------------
%311 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_3
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_1']
--------------------MLIR OPS--------------------
%312 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_1
Type: OpType.ElementwiseType
Arguments: ['slice_49', 'scalar_tensor_3', 'scalar_tensor_2']
Parents: ['slice_49', 'scalar_tensor_3', 'scalar_tensor_2']
Children: ['_scaled_dot_product_flash_attention_for_cpu_1']
--------------------MLIR OPS--------------------
%313 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%314 = "tensor.splat"(%312) : (f32) -> tensor<1x1x1x1024xf32>
%315 = "tensor.splat"(%311) : (f32) -> tensor<1x1x1x1024xf32>
%316 = "linalg.generic"(%310, %314, %315, %313) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %317 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%317) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_1
Type: OpType.ElementwiseType
Arguments: ['add_8', 'view_34', 'view_35']
Parents: ['add_8', 'view_34', 'view_35']
Children: ['getitem_2']
--------------------MLIR OPS--------------------
%317 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%318 = "tensor.splat"(%317) : (f32) -> tensor<1x1024xf32>
%319 = "tosa.reshape"(%316) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%320 = "tosa.add"(%318, %319) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%321 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%322 = "tosa.transpose"(%305, %321) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%323 = "tosa.reshape"(%271) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%324 = "tosa.reshape"(%322) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%325 = "tosa.matmul"(%323, %324) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%326 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%327 = "tensor.splat"(%326) : (f32) -> tensor<12x1x1024xf32>
%328 = "tosa.mul"(%325, %327) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%329 = "tosa.reshape"(%320) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%330 = "tosa.add"(%328, %329) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%331 = "tosa.reduce_max"(%330) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%332 = "tosa.sub"(%330, %331) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%333 = "math.exp"(%332) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%334 = "tosa.reduce_sum"(%333) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%335 = "tosa.log"(%334) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%336 = "tosa.add"(%331, %335) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%337 = "tosa.sub"(%330, %336) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%338 = "math.exp"(%337) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%339 = "tosa.reshape"(%336) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%340 = "tosa.reshape"(%309) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%341 = "tosa.matmul"(%338, %340) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%342 = "tosa.reshape"(%341) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_2
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_1', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_1']
Children: ['permute_18']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_18
Type: OpType.ReshapeType
Arguments: ['getitem_2', [0, 2, 1, 3]]
Parents: ['getitem_2']
Children: ['view_36']
--------------------MLIR OPS--------------------
%343 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%344 = "tosa.transpose"(%342, %343) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_36
Type: OpType.ReshapeType
Arguments: ['permute_18', [1, 1, -1]]
Parents: ['permute_18']
Children: ['view_37']
--------------------MLIR OPS--------------------
%345 = "tosa.reshape"(%344) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_19
Type: OpType.ReshapeType
Arguments: ['arg79_1', [1, 0]]
Parents: ['arg79_1']
Children: ['mm_4']
--------------------MLIR OPS--------------------
%346 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%347 = "tosa.transpose"(%arg27, %346) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_37
Type: OpType.ReshapeType
Arguments: ['view_36', [1, 1536]]
Parents: ['view_36']
Children: ['mm_4']
--------------------MLIR OPS--------------------
%348 = "tosa.reshape"(%345) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_4
Type: OpType.ReduceType
Arguments: ['view_37', 'permute_19']
Parents: ['view_37', 'permute_19']
Children: ['view_38']
--------------------MLIR OPS--------------------
%349 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%350 = "linalg.matmul"(%348, %347, %349) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %351 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %352 = "arith.addf"(%arg400, %351) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%352) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_38
Type: OpType.ReshapeType
Arguments: ['mm_4', [1, 1, 1536]]
Parents: ['mm_4']
Children: ['add_10']
--------------------MLIR OPS--------------------
%351 = "tosa.reshape"(%350) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_10
Type: OpType.BroadcastType
Arguments: ['add_6', 'view_38']
Parents: ['add_6', 'view_38']
Children: ['pow_4', 'mul_18', 'add_12']
--------------------MLIR OPS--------------------
%352 = "tosa.add"(%212, %351) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_4
Type: OpType.BroadcastType
Arguments: ['add_10', 2]
Parents: ['add_10']
Children: ['mean_3']
--------------------MLIR OPS--------------------
%353 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%354 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%355 = "linalg.generic"(%352, %353) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %356 = "math.fpowi"(%arg398, %354) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%356) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_3
Type: OpType.ReduceType
Arguments: ['pow_4', [-1], True]
Parents: ['pow_4']
Children: ['add_11']
--------------------MLIR OPS--------------------
%356 = "tosa.reduce_sum"(%355) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%357 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%358 = "tosa.reciprocal"(%357) : (tensor<1xf32>) -> tensor<1xf32>
%359 = "tosa.reshape"(%358) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%360 = "tosa.mul"(%359, %356) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_11
Type: OpType.BroadcastType
Arguments: ['mean_3', 1e-06]
Parents: ['mean_3']
Children: ['rsqrt_3']
--------------------MLIR OPS--------------------
%361 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%362 = "tosa.add"(%360, %361) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_3
Type: OpType.ElementwiseType
Arguments: ['add_11']
Parents: ['add_11']
Children: ['mul_18']
--------------------MLIR OPS--------------------
%363 = "tosa.rsqrt"(%362) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_18
Type: OpType.BroadcastType
Arguments: ['add_10', 'rsqrt_3']
Parents: ['add_10', 'rsqrt_3']
Children: ['mul_19']
--------------------MLIR OPS--------------------
%364 = "tosa.mul"(%352, %363) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_19
Type: OpType.BroadcastType
Arguments: ['arg80_1', 'mul_18']
Parents: ['arg80_1', 'mul_18']
Children: ['view_39', 'view_41']
--------------------MLIR OPS--------------------
%365 = "tosa.reshape"(%arg28) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%366 = "tosa.mul"(%365, %364) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_20
Type: OpType.ReshapeType
Arguments: ['arg81_1', [1, 0]]
Parents: ['arg81_1']
Children: ['mm_5']
--------------------MLIR OPS--------------------
%367 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%368 = "tosa.transpose"(%arg29, %367) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_39
Type: OpType.ReshapeType
Arguments: ['mul_19', [1, 1536]]
Parents: ['mul_19']
Children: ['mm_5']
--------------------MLIR OPS--------------------
%369 = "tosa.reshape"(%366) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_5
Type: OpType.ReduceType
Arguments: ['view_39', 'permute_20']
Parents: ['view_39', 'permute_20']
Children: ['view_40']
--------------------MLIR OPS--------------------
%370 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%371 = "linalg.matmul"(%369, %368, %370) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %372 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %373 = "arith.addf"(%arg400, %372) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%373) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_40
Type: OpType.ReshapeType
Arguments: ['mm_5', [1, 1, 8960]]
Parents: ['mm_5']
Children: ['sigmoid_1', 'mul_20']
--------------------MLIR OPS--------------------
%372 = "tosa.reshape"(%371) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_1
Type: OpType.ElementwiseType
Arguments: ['view_40']
Parents: ['view_40']
Children: ['mul_20']
--------------------MLIR OPS--------------------
%373 = "tosa.sigmoid"(%372) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_20
Type: OpType.BroadcastType
Arguments: ['view_40', 'sigmoid_1']
Parents: ['view_40', 'sigmoid_1']
Children: ['mul_21']
--------------------MLIR OPS--------------------
%374 = "tosa.mul"(%372, %373) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_21
Type: OpType.ReshapeType
Arguments: ['arg82_1', [1, 0]]
Parents: ['arg82_1']
Children: ['mm_6']
--------------------MLIR OPS--------------------
%375 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%376 = "tosa.transpose"(%arg30, %375) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_41
Type: OpType.ReshapeType
Arguments: ['mul_19', [1, 1536]]
Parents: ['mul_19']
Children: ['mm_6']
--------------------MLIR OPS--------------------
%377 = "tosa.reshape"(%366) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_6
Type: OpType.ReduceType
Arguments: ['view_41', 'permute_21']
Parents: ['view_41', 'permute_21']
Children: ['view_42']
--------------------MLIR OPS--------------------
%378 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%379 = "linalg.matmul"(%377, %376, %378) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %380 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %381 = "arith.addf"(%arg400, %380) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%381) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_42
Type: OpType.ReshapeType
Arguments: ['mm_6', [1, 1, 8960]]
Parents: ['mm_6']
Children: ['mul_21']
--------------------MLIR OPS--------------------
%380 = "tosa.reshape"(%379) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_21
Type: OpType.BroadcastType
Arguments: ['mul_20', 'view_42']
Parents: ['mul_20', 'view_42']
Children: ['view_43']
--------------------MLIR OPS--------------------
%381 = "tosa.mul"(%374, %380) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_22
Type: OpType.ReshapeType
Arguments: ['arg83_1', [1, 0]]
Parents: ['arg83_1']
Children: ['mm_7']
--------------------MLIR OPS--------------------
%382 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%383 = "tosa.transpose"(%arg31, %382) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_43
Type: OpType.ReshapeType
Arguments: ['mul_21', [1, 8960]]
Parents: ['mul_21']
Children: ['mm_7']
--------------------MLIR OPS--------------------
%384 = "tosa.reshape"(%381) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_7
Type: OpType.ReduceType
Arguments: ['view_43', 'permute_22']
Parents: ['view_43', 'permute_22']
Children: ['view_44']
--------------------MLIR OPS--------------------
%385 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%386 = "linalg.matmul"(%384, %383, %385) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %387 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %388 = "arith.addf"(%arg400, %387) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%388) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_44
Type: OpType.ReshapeType
Arguments: ['mm_7', [1, 1, 1536]]
Parents: ['mm_7']
Children: ['add_12']
--------------------MLIR OPS--------------------
%387 = "tosa.reshape"(%386) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_12
Type: OpType.BroadcastType
Arguments: ['add_10', 'view_44']
Parents: ['add_10', 'view_44']
Children: ['pow_5', 'mul_22', 'add_16']
--------------------MLIR OPS--------------------
%388 = "tosa.add"(%352, %387) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_5
Type: OpType.BroadcastType
Arguments: ['add_12', 2]
Parents: ['add_12']
Children: ['mean_4']
--------------------MLIR OPS--------------------
%389 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%390 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%391 = "linalg.generic"(%388, %389) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %392 = "math.fpowi"(%arg398, %390) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%392) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_4
Type: OpType.ReduceType
Arguments: ['pow_5', [-1], True]
Parents: ['pow_5']
Children: ['add_13']
--------------------MLIR OPS--------------------
%392 = "tosa.reduce_sum"(%391) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%393 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%394 = "tosa.reciprocal"(%393) : (tensor<1xf32>) -> tensor<1xf32>
%395 = "tosa.reshape"(%394) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%396 = "tosa.mul"(%395, %392) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_13
Type: OpType.BroadcastType
Arguments: ['mean_4', 1e-06]
Parents: ['mean_4']
Children: ['rsqrt_4']
--------------------MLIR OPS--------------------
%397 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%398 = "tosa.add"(%396, %397) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_4
Type: OpType.ElementwiseType
Arguments: ['add_13']
Parents: ['add_13']
Children: ['mul_22']
--------------------MLIR OPS--------------------
%399 = "tosa.rsqrt"(%398) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_22
Type: OpType.BroadcastType
Arguments: ['add_12', 'rsqrt_4']
Parents: ['add_12', 'rsqrt_4']
Children: ['mul_23']
--------------------MLIR OPS--------------------
%400 = "tosa.mul"(%388, %399) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_23
Type: OpType.BroadcastType
Arguments: ['arg84_1', 'mul_22']
Parents: ['arg84_1', 'mul_22']
Children: ['view_45', 'view_48', 'view_51']
--------------------MLIR OPS--------------------
%401 = "tosa.reshape"(%arg32) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%402 = "tosa.mul"(%401, %400) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_45
Type: OpType.ReshapeType
Arguments: ['mul_23', [1, 1536]]
Parents: ['mul_23']
Children: ['addmm_6']
--------------------MLIR OPS--------------------
%403 = "tosa.reshape"(%402) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_23
Type: OpType.ReshapeType
Arguments: ['arg85_1', [1, 0]]
Parents: ['arg85_1']
Children: ['addmm_6']
--------------------MLIR OPS--------------------
%404 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%405 = "tosa.transpose"(%arg33, %404) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_6
Type: OpType.ReduceType
Arguments: ['arg86_1', 'view_45', 'permute_23']
Parents: ['arg86_1', 'view_45', 'permute_23']
Children: ['view_46']
--------------------MLIR OPS--------------------
%406 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%407 = "linalg.matmul"(%403, %405, %406) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %410 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %411 = "arith.addf"(%arg400, %410) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%411) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%408 = "tosa.reshape"(%arg34) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%409 = "tosa.add"(%408, %407) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_46
Type: OpType.ReshapeType
Arguments: ['addmm_6', [1, 1, 1536]]
Parents: ['addmm_6']
Children: ['view_47']
--------------------MLIR OPS--------------------
%410 = "tosa.reshape"(%409) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_47
Type: OpType.ReshapeType
Arguments: ['view_46', [1, 1, -1, 128]]
Parents: ['view_46']
Children: ['permute_24']
--------------------MLIR OPS--------------------
%411 = "tosa.reshape"(%410) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_24
Type: OpType.ReshapeType
Arguments: ['view_47', [0, 2, 1, 3]]
Parents: ['view_47']
Children: ['mul_24', 'slice_50', 'slice_51']
--------------------MLIR OPS--------------------
%412 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%413 = "tosa.transpose"(%411, %412) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_48
Type: OpType.ReshapeType
Arguments: ['mul_23', [1, 1536]]
Parents: ['mul_23']
Children: ['addmm_7']
--------------------MLIR OPS--------------------
%414 = "tosa.reshape"(%402) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_25
Type: OpType.ReshapeType
Arguments: ['arg87_1', [1, 0]]
Parents: ['arg87_1']
Children: ['addmm_7']
--------------------MLIR OPS--------------------
%415 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%416 = "tosa.transpose"(%arg35, %415) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_7
Type: OpType.ReduceType
Arguments: ['arg88_1', 'view_48', 'permute_25']
Parents: ['arg88_1', 'view_48', 'permute_25']
Children: ['view_49']
--------------------MLIR OPS--------------------
%417 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%418 = "linalg.matmul"(%414, %416, %417) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %421 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %422 = "arith.addf"(%arg400, %421) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%422) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%419 = "tosa.reshape"(%arg36) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%420 = "tosa.add"(%419, %418) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_49
Type: OpType.ReshapeType
Arguments: ['addmm_7', [1, 1, 256]]
Parents: ['addmm_7']
Children: ['view_50']
--------------------MLIR OPS--------------------
%421 = "tosa.reshape"(%420) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_50
Type: OpType.ReshapeType
Arguments: ['view_49', [1, 1, -1, 128]]
Parents: ['view_49']
Children: ['permute_26']
--------------------MLIR OPS--------------------
%422 = "tosa.reshape"(%421) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_26
Type: OpType.ReshapeType
Arguments: ['view_50', [0, 2, 1, 3]]
Parents: ['view_50']
Children: ['mul_26', 'slice_52', 'slice_53']
--------------------MLIR OPS--------------------
%423 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%424 = "tosa.transpose"(%422, %423) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_51
Type: OpType.ReshapeType
Arguments: ['mul_23', [1, 1536]]
Parents: ['mul_23']
Children: ['addmm_8']
--------------------MLIR OPS--------------------
%425 = "tosa.reshape"(%402) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_27
Type: OpType.ReshapeType
Arguments: ['arg89_1', [1, 0]]
Parents: ['arg89_1']
Children: ['addmm_8']
--------------------MLIR OPS--------------------
%426 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%427 = "tosa.transpose"(%arg37, %426) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_8
Type: OpType.ReduceType
Arguments: ['arg90_1', 'view_51', 'permute_27']
Parents: ['arg90_1', 'view_51', 'permute_27']
Children: ['view_52']
--------------------MLIR OPS--------------------
%428 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%429 = "linalg.matmul"(%425, %427, %428) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %432 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %433 = "arith.addf"(%arg400, %432) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%433) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%430 = "tosa.reshape"(%arg38) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%431 = "tosa.add"(%430, %429) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_52
Type: OpType.ReshapeType
Arguments: ['addmm_8', [1, 1, 256]]
Parents: ['addmm_8']
Children: ['view_53']
--------------------MLIR OPS--------------------
%432 = "tosa.reshape"(%431) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_53
Type: OpType.ReshapeType
Arguments: ['view_52', [1, 1, -1, 128]]
Parents: ['view_52']
Children: ['permute_28']
--------------------MLIR OPS--------------------
%433 = "tosa.reshape"(%432) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_28
Type: OpType.ReshapeType
Arguments: ['view_53', [0, 2, 1, 3]]
Parents: ['view_53']
Children: ['index_put_5']
--------------------MLIR OPS--------------------
%434 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%435 = "tosa.transpose"(%433, %434) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_17
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_24', 'mul_26']
--------------------MLIR OPS--------------------
%436 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_18
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_25', 'mul_27']
--------------------MLIR OPS--------------------
%437 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_24
Type: OpType.BroadcastType
Arguments: ['permute_24', 'unsqueeze_17']
Parents: ['permute_24', 'unsqueeze_17']
Children: ['add_14']
--------------------MLIR OPS--------------------
%438 = "tosa.mul"(%413, %436) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_50
Type: OpType.ReshapeType
Arguments: ['permute_24', 3, 0, 64]
Parents: ['permute_24']
Children: ['cat_4']
--------------------MLIR OPS--------------------
%439 = "tensor.extract_slice"(%413) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_51
Type: OpType.ReshapeType
Arguments: ['permute_24', 3, 64, 9223372036854775807]
Parents: ['permute_24']
Children: ['neg_4']
--------------------MLIR OPS--------------------
%440 = "tensor.extract_slice"(%413) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_4
Type: OpType.ElementwiseType
Arguments: ['slice_51']
Parents: ['slice_51']
Children: ['cat_4']
--------------------MLIR OPS--------------------
%441 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%442 = "linalg.negf"(%440, %441) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %443 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%443) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_4
Type: OpType.ConcatType
Arguments: [[neg_4, slice_50], -1]
Parents: []
Children: ['mul_25']
--------------------MLIR OPS--------------------
%443 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%444 = "tensor.insert_slice"(%442, %443) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%445 = "tensor.insert_slice"(%439, %444) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_25
Type: OpType.BroadcastType
Arguments: ['cat_4', 'unsqueeze_18']
Parents: ['cat_4', 'unsqueeze_18']
Children: ['add_14']
--------------------MLIR OPS--------------------
%446 = "tosa.mul"(%445, %437) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_14
Type: OpType.BroadcastType
Arguments: ['mul_24', 'mul_25']
Parents: ['mul_24', 'mul_25']
Children: ['_scaled_dot_product_flash_attention_for_cpu_2']
--------------------MLIR OPS--------------------
%447 = "tosa.add"(%438, %446) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_26
Type: OpType.BroadcastType
Arguments: ['permute_26', 'unsqueeze_17']
Parents: ['permute_26', 'unsqueeze_17']
Children: ['add_15']
--------------------MLIR OPS--------------------
%448 = "tosa.mul"(%424, %436) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_52
Type: OpType.ReshapeType
Arguments: ['permute_26', 3, 0, 64]
Parents: ['permute_26']
Children: ['cat_5']
--------------------MLIR OPS--------------------
%449 = "tensor.extract_slice"(%424) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_53
Type: OpType.ReshapeType
Arguments: ['permute_26', 3, 64, 9223372036854775807]
Parents: ['permute_26']
Children: ['neg_5']
--------------------MLIR OPS--------------------
%450 = "tensor.extract_slice"(%424) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_5
Type: OpType.ElementwiseType
Arguments: ['slice_53']
Parents: ['slice_53']
Children: ['cat_5']
--------------------MLIR OPS--------------------
%451 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%452 = "linalg.negf"(%450, %451) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %453 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%453) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_5
Type: OpType.ConcatType
Arguments: [[neg_5, slice_52], -1]
Parents: []
Children: ['mul_27']
--------------------MLIR OPS--------------------
%453 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%454 = "tensor.insert_slice"(%452, %453) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%455 = "tensor.insert_slice"(%449, %454) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_27
Type: OpType.BroadcastType
Arguments: ['cat_5', 'unsqueeze_18']
Parents: ['cat_5', 'unsqueeze_18']
Children: ['add_15']
--------------------MLIR OPS--------------------
%456 = "tosa.mul"(%455, %437) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_15
Type: OpType.BroadcastType
Arguments: ['mul_26', 'mul_27']
Parents: ['mul_26', 'mul_27']
Children: ['index_put_4']
--------------------MLIR OPS--------------------
%457 = "tosa.add"(%448, %456) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_4
Type: OpType.ElementwiseType
Arguments: ['arg4_1', [None, None, arg58_1], 'add_15']
Parents: ['arg4_1', 'add_15']
Children: ['slice_58', 'output']
--------------------MLIR OPS--------------------
%458 = "bufferization.to_memref"(%arg39) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%459 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%460 = "bufferization.to_memref"(%457) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%461 = "arith.constant"() <{value = 0 : index}> : () -> index
%462 = "arith.constant"() <{value = 1 : index}> : () -> index
%463 = "arith.constant"() <{value = 1 : index}> : () -> index
%464 = "arith.constant"() <{value = 2 : index}> : () -> index
%465 = "arith.constant"() <{value = 1 : index}> : () -> index
%466 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%461, %463, %462) ({
^bb0(%arg398: index):
  "scf.for"(%461, %464, %462) ({
  ^bb0(%arg399: index):
    "scf.for"(%461, %465, %462) ({
    ^bb0(%arg400: index):
      %468 = "memref.load"(%459, %arg400) : (memref<1xi64>, index) -> i64
      %469 = "arith.index_cast"(%468) : (i64) -> index
      "scf.for"(%461, %466, %462) ({
      ^bb0(%arg401: index):
        %470 = "memref.load"(%460, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%470, %458, %arg398, %arg399, %469, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%467 = "bufferization.to_tensor"(%458) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_5
Type: OpType.ElementwiseType
Arguments: ['arg5_1', [None, None, arg58_1], 'permute_28']
Parents: ['arg5_1', 'permute_28']
Children: ['slice_66', 'output']
--------------------MLIR OPS--------------------
%468 = "bufferization.to_memref"(%arg40) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%469 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%470 = "bufferization.to_memref"(%435) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%471 = "arith.constant"() <{value = 0 : index}> : () -> index
%472 = "arith.constant"() <{value = 1 : index}> : () -> index
%473 = "arith.constant"() <{value = 1 : index}> : () -> index
%474 = "arith.constant"() <{value = 2 : index}> : () -> index
%475 = "arith.constant"() <{value = 1 : index}> : () -> index
%476 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%471, %473, %472) ({
^bb0(%arg398: index):
  "scf.for"(%471, %474, %472) ({
  ^bb0(%arg399: index):
    "scf.for"(%471, %475, %472) ({
    ^bb0(%arg400: index):
      %478 = "memref.load"(%469, %arg400) : (memref<1xi64>, index) -> i64
      %479 = "arith.index_cast"(%478) : (i64) -> index
      "scf.for"(%471, %476, %472) ({
      ^bb0(%arg401: index):
        %480 = "memref.load"(%470, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%480, %468, %arg398, %arg399, %479, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%477 = "bufferization.to_tensor"(%468) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_58
Type: OpType.ReshapeType
Arguments: ['index_put_4', 0, 0, 9223372036854775807]
Parents: ['index_put_4']
Children: ['slice_59']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_59
Type: OpType.ReshapeType
Arguments: ['slice_58', 1, 0, 9223372036854775807]
Parents: ['slice_58']
Children: ['unsqueeze_20']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_20
Type: OpType.ReshapeType
Arguments: ['slice_59', 2]
Parents: ['slice_59']
Children: ['slice_60']
--------------------MLIR OPS--------------------
%478 = "tosa.reshape"(%467) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_60
Type: OpType.ReshapeType
Arguments: ['unsqueeze_20', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_20']
Children: ['slice_61']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_61
Type: OpType.ReshapeType
Arguments: ['slice_60', 4, 0, 9223372036854775807]
Parents: ['slice_60']
Children: ['expand_15']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_15
Type: OpType.ReshapeType
Arguments: ['slice_61', [1, 2, 6, 1024, 128]]
Parents: ['slice_61']
Children: ['clone_6']
--------------------MLIR OPS--------------------
%479 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%480 = "tosa.add"(%478, %479) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_6
Type: OpType.ReduceType
Arguments: ['expand_15']
Parents: ['expand_15']
Children: ['view_54']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_54
Type: OpType.ReshapeType
Arguments: ['clone_6', [1, 12, 1024, 128]]
Parents: ['clone_6']
Children: ['_scaled_dot_product_flash_attention_for_cpu_2']
--------------------MLIR OPS--------------------
%481 = "tosa.reshape"(%480) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_66
Type: OpType.ReshapeType
Arguments: ['index_put_5', 0, 0, 9223372036854775807]
Parents: ['index_put_5']
Children: ['slice_67']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_67
Type: OpType.ReshapeType
Arguments: ['slice_66', 1, 0, 9223372036854775807]
Parents: ['slice_66']
Children: ['unsqueeze_22']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_22
Type: OpType.ReshapeType
Arguments: ['slice_67', 2]
Parents: ['slice_67']
Children: ['slice_68']
--------------------MLIR OPS--------------------
%482 = "tosa.reshape"(%477) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_68
Type: OpType.ReshapeType
Arguments: ['unsqueeze_22', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_22']
Children: ['slice_69']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_69
Type: OpType.ReshapeType
Arguments: ['slice_68', 4, 0, 9223372036854775807]
Parents: ['slice_68']
Children: ['expand_17']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_17
Type: OpType.ReshapeType
Arguments: ['slice_69', [1, 2, 6, 1024, 128]]
Parents: ['slice_69']
Children: ['clone_7']
--------------------MLIR OPS--------------------
%483 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%484 = "tosa.add"(%482, %483) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_7
Type: OpType.ReduceType
Arguments: ['expand_17']
Parents: ['expand_17']
Children: ['view_55']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_55
Type: OpType.ReshapeType
Arguments: ['clone_7', [1, 12, 1024, 128]]
Parents: ['clone_7']
Children: ['_scaled_dot_product_flash_attention_for_cpu_2']
--------------------MLIR OPS--------------------
%485 = "tosa.reshape"(%484) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_70
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_71']
--------------------MLIR OPS--------------------
%486 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_71
Type: OpType.ReshapeType
Arguments: ['slice_70', 1, 0, 9223372036854775807]
Parents: ['slice_70']
Children: ['slice_72']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_72
Type: OpType.ReshapeType
Arguments: ['slice_71', 2, 0, 9223372036854775807]
Parents: ['slice_71']
Children: ['where_2']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_4
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_2']
--------------------MLIR OPS--------------------
%487 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_5
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_2']
--------------------MLIR OPS--------------------
%488 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_2
Type: OpType.ElementwiseType
Arguments: ['slice_72', 'scalar_tensor_5', 'scalar_tensor_4']
Parents: ['slice_72', 'scalar_tensor_5', 'scalar_tensor_4']
Children: ['_scaled_dot_product_flash_attention_for_cpu_2']
--------------------MLIR OPS--------------------
%489 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%490 = "tensor.splat"(%488) : (f32) -> tensor<1x1x1x1024xf32>
%491 = "tensor.splat"(%487) : (f32) -> tensor<1x1x1x1024xf32>
%492 = "linalg.generic"(%486, %490, %491, %489) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %493 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%493) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_2
Type: OpType.ElementwiseType
Arguments: ['add_14', 'view_54', 'view_55']
Parents: ['add_14', 'view_54', 'view_55']
Children: ['getitem_4']
--------------------MLIR OPS--------------------
%493 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%494 = "tensor.splat"(%493) : (f32) -> tensor<1x1024xf32>
%495 = "tosa.reshape"(%492) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%496 = "tosa.add"(%494, %495) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%497 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%498 = "tosa.transpose"(%481, %497) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%499 = "tosa.reshape"(%447) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%500 = "tosa.reshape"(%498) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%501 = "tosa.matmul"(%499, %500) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%502 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%503 = "tensor.splat"(%502) : (f32) -> tensor<12x1x1024xf32>
%504 = "tosa.mul"(%501, %503) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%505 = "tosa.reshape"(%496) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%506 = "tosa.add"(%504, %505) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%507 = "tosa.reduce_max"(%506) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%508 = "tosa.sub"(%506, %507) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%509 = "math.exp"(%508) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%510 = "tosa.reduce_sum"(%509) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%511 = "tosa.log"(%510) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%512 = "tosa.add"(%507, %511) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%513 = "tosa.sub"(%506, %512) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%514 = "math.exp"(%513) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%515 = "tosa.reshape"(%512) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%516 = "tosa.reshape"(%485) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%517 = "tosa.matmul"(%514, %516) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%518 = "tosa.reshape"(%517) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_4
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_2', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_2']
Children: ['permute_29']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_29
Type: OpType.ReshapeType
Arguments: ['getitem_4', [0, 2, 1, 3]]
Parents: ['getitem_4']
Children: ['view_56']
--------------------MLIR OPS--------------------
%519 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%520 = "tosa.transpose"(%518, %519) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_56
Type: OpType.ReshapeType
Arguments: ['permute_29', [1, 1, -1]]
Parents: ['permute_29']
Children: ['view_57']
--------------------MLIR OPS--------------------
%521 = "tosa.reshape"(%520) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_30
Type: OpType.ReshapeType
Arguments: ['arg91_1', [1, 0]]
Parents: ['arg91_1']
Children: ['mm_8']
--------------------MLIR OPS--------------------
%522 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%523 = "tosa.transpose"(%arg41, %522) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_57
Type: OpType.ReshapeType
Arguments: ['view_56', [1, 1536]]
Parents: ['view_56']
Children: ['mm_8']
--------------------MLIR OPS--------------------
%524 = "tosa.reshape"(%521) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_8
Type: OpType.ReduceType
Arguments: ['view_57', 'permute_30']
Parents: ['view_57', 'permute_30']
Children: ['view_58']
--------------------MLIR OPS--------------------
%525 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%526 = "linalg.matmul"(%524, %523, %525) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %527 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %528 = "arith.addf"(%arg400, %527) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%528) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_58
Type: OpType.ReshapeType
Arguments: ['mm_8', [1, 1, 1536]]
Parents: ['mm_8']
Children: ['add_16']
--------------------MLIR OPS--------------------
%527 = "tosa.reshape"(%526) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_16
Type: OpType.BroadcastType
Arguments: ['add_12', 'view_58']
Parents: ['add_12', 'view_58']
Children: ['pow_6', 'mul_28', 'add_18']
--------------------MLIR OPS--------------------
%528 = "tosa.add"(%388, %527) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_6
Type: OpType.BroadcastType
Arguments: ['add_16', 2]
Parents: ['add_16']
Children: ['mean_5']
--------------------MLIR OPS--------------------
%529 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%530 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%531 = "linalg.generic"(%528, %529) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %532 = "math.fpowi"(%arg398, %530) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%532) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_5
Type: OpType.ReduceType
Arguments: ['pow_6', [-1], True]
Parents: ['pow_6']
Children: ['add_17']
--------------------MLIR OPS--------------------
%532 = "tosa.reduce_sum"(%531) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%533 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%534 = "tosa.reciprocal"(%533) : (tensor<1xf32>) -> tensor<1xf32>
%535 = "tosa.reshape"(%534) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%536 = "tosa.mul"(%535, %532) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_17
Type: OpType.BroadcastType
Arguments: ['mean_5', 1e-06]
Parents: ['mean_5']
Children: ['rsqrt_5']
--------------------MLIR OPS--------------------
%537 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%538 = "tosa.add"(%536, %537) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_5
Type: OpType.ElementwiseType
Arguments: ['add_17']
Parents: ['add_17']
Children: ['mul_28']
--------------------MLIR OPS--------------------
%539 = "tosa.rsqrt"(%538) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_28
Type: OpType.BroadcastType
Arguments: ['add_16', 'rsqrt_5']
Parents: ['add_16', 'rsqrt_5']
Children: ['mul_29']
--------------------MLIR OPS--------------------
%540 = "tosa.mul"(%528, %539) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_29
Type: OpType.BroadcastType
Arguments: ['arg92_1', 'mul_28']
Parents: ['arg92_1', 'mul_28']
Children: ['view_59', 'view_61']
--------------------MLIR OPS--------------------
%541 = "tosa.reshape"(%arg42) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%542 = "tosa.mul"(%541, %540) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_31
Type: OpType.ReshapeType
Arguments: ['arg93_1', [1, 0]]
Parents: ['arg93_1']
Children: ['mm_9']
--------------------MLIR OPS--------------------
%543 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%544 = "tosa.transpose"(%arg43, %543) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_59
Type: OpType.ReshapeType
Arguments: ['mul_29', [1, 1536]]
Parents: ['mul_29']
Children: ['mm_9']
--------------------MLIR OPS--------------------
%545 = "tosa.reshape"(%542) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_9
Type: OpType.ReduceType
Arguments: ['view_59', 'permute_31']
Parents: ['view_59', 'permute_31']
Children: ['view_60']
--------------------MLIR OPS--------------------
%546 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%547 = "linalg.matmul"(%545, %544, %546) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %548 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %549 = "arith.addf"(%arg400, %548) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%549) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_60
Type: OpType.ReshapeType
Arguments: ['mm_9', [1, 1, 8960]]
Parents: ['mm_9']
Children: ['sigmoid_2', 'mul_30']
--------------------MLIR OPS--------------------
%548 = "tosa.reshape"(%547) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_2
Type: OpType.ElementwiseType
Arguments: ['view_60']
Parents: ['view_60']
Children: ['mul_30']
--------------------MLIR OPS--------------------
%549 = "tosa.sigmoid"(%548) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_30
Type: OpType.BroadcastType
Arguments: ['view_60', 'sigmoid_2']
Parents: ['view_60', 'sigmoid_2']
Children: ['mul_31']
--------------------MLIR OPS--------------------
%550 = "tosa.mul"(%548, %549) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_32
Type: OpType.ReshapeType
Arguments: ['arg94_1', [1, 0]]
Parents: ['arg94_1']
Children: ['mm_10']
--------------------MLIR OPS--------------------
%551 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%552 = "tosa.transpose"(%arg44, %551) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_61
Type: OpType.ReshapeType
Arguments: ['mul_29', [1, 1536]]
Parents: ['mul_29']
Children: ['mm_10']
--------------------MLIR OPS--------------------
%553 = "tosa.reshape"(%542) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_10
Type: OpType.ReduceType
Arguments: ['view_61', 'permute_32']
Parents: ['view_61', 'permute_32']
Children: ['view_62']
--------------------MLIR OPS--------------------
%554 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%555 = "linalg.matmul"(%553, %552, %554) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %556 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %557 = "arith.addf"(%arg400, %556) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%557) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_62
Type: OpType.ReshapeType
Arguments: ['mm_10', [1, 1, 8960]]
Parents: ['mm_10']
Children: ['mul_31']
--------------------MLIR OPS--------------------
%556 = "tosa.reshape"(%555) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_31
Type: OpType.BroadcastType
Arguments: ['mul_30', 'view_62']
Parents: ['mul_30', 'view_62']
Children: ['view_63']
--------------------MLIR OPS--------------------
%557 = "tosa.mul"(%550, %556) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_33
Type: OpType.ReshapeType
Arguments: ['arg95_1', [1, 0]]
Parents: ['arg95_1']
Children: ['mm_11']
--------------------MLIR OPS--------------------
%558 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%559 = "tosa.transpose"(%arg45, %558) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_63
Type: OpType.ReshapeType
Arguments: ['mul_31', [1, 8960]]
Parents: ['mul_31']
Children: ['mm_11']
--------------------MLIR OPS--------------------
%560 = "tosa.reshape"(%557) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_11
Type: OpType.ReduceType
Arguments: ['view_63', 'permute_33']
Parents: ['view_63', 'permute_33']
Children: ['view_64']
--------------------MLIR OPS--------------------
%561 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%562 = "linalg.matmul"(%560, %559, %561) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %563 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %564 = "arith.addf"(%arg400, %563) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%564) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_64
Type: OpType.ReshapeType
Arguments: ['mm_11', [1, 1, 1536]]
Parents: ['mm_11']
Children: ['add_18']
--------------------MLIR OPS--------------------
%563 = "tosa.reshape"(%562) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_18
Type: OpType.BroadcastType
Arguments: ['add_16', 'view_64']
Parents: ['add_16', 'view_64']
Children: ['pow_7', 'mul_32', 'add_22']
--------------------MLIR OPS--------------------
%564 = "tosa.add"(%528, %563) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_7
Type: OpType.BroadcastType
Arguments: ['add_18', 2]
Parents: ['add_18']
Children: ['mean_6']
--------------------MLIR OPS--------------------
%565 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%566 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%567 = "linalg.generic"(%564, %565) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %568 = "math.fpowi"(%arg398, %566) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%568) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_6
Type: OpType.ReduceType
Arguments: ['pow_7', [-1], True]
Parents: ['pow_7']
Children: ['add_19']
--------------------MLIR OPS--------------------
%568 = "tosa.reduce_sum"(%567) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%569 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%570 = "tosa.reciprocal"(%569) : (tensor<1xf32>) -> tensor<1xf32>
%571 = "tosa.reshape"(%570) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%572 = "tosa.mul"(%571, %568) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_19
Type: OpType.BroadcastType
Arguments: ['mean_6', 1e-06]
Parents: ['mean_6']
Children: ['rsqrt_6']
--------------------MLIR OPS--------------------
%573 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%574 = "tosa.add"(%572, %573) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_6
Type: OpType.ElementwiseType
Arguments: ['add_19']
Parents: ['add_19']
Children: ['mul_32']
--------------------MLIR OPS--------------------
%575 = "tosa.rsqrt"(%574) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_32
Type: OpType.BroadcastType
Arguments: ['add_18', 'rsqrt_6']
Parents: ['add_18', 'rsqrt_6']
Children: ['mul_33']
--------------------MLIR OPS--------------------
%576 = "tosa.mul"(%564, %575) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_33
Type: OpType.BroadcastType
Arguments: ['arg96_1', 'mul_32']
Parents: ['arg96_1', 'mul_32']
Children: ['view_65', 'view_68', 'view_71']
--------------------MLIR OPS--------------------
%577 = "tosa.reshape"(%arg46) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%578 = "tosa.mul"(%577, %576) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_65
Type: OpType.ReshapeType
Arguments: ['mul_33', [1, 1536]]
Parents: ['mul_33']
Children: ['addmm_9']
--------------------MLIR OPS--------------------
%579 = "tosa.reshape"(%578) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_34
Type: OpType.ReshapeType
Arguments: ['arg97_1', [1, 0]]
Parents: ['arg97_1']
Children: ['addmm_9']
--------------------MLIR OPS--------------------
%580 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%581 = "tosa.transpose"(%arg47, %580) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_9
Type: OpType.ReduceType
Arguments: ['arg98_1', 'view_65', 'permute_34']
Parents: ['arg98_1', 'view_65', 'permute_34']
Children: ['view_66']
--------------------MLIR OPS--------------------
%582 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%583 = "linalg.matmul"(%579, %581, %582) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %586 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %587 = "arith.addf"(%arg400, %586) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%587) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%584 = "tosa.reshape"(%arg48) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%585 = "tosa.add"(%584, %583) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_66
Type: OpType.ReshapeType
Arguments: ['addmm_9', [1, 1, 1536]]
Parents: ['addmm_9']
Children: ['view_67']
--------------------MLIR OPS--------------------
%586 = "tosa.reshape"(%585) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_67
Type: OpType.ReshapeType
Arguments: ['view_66', [1, 1, -1, 128]]
Parents: ['view_66']
Children: ['permute_35']
--------------------MLIR OPS--------------------
%587 = "tosa.reshape"(%586) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_35
Type: OpType.ReshapeType
Arguments: ['view_67', [0, 2, 1, 3]]
Parents: ['view_67']
Children: ['mul_34', 'slice_73', 'slice_74']
--------------------MLIR OPS--------------------
%588 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%589 = "tosa.transpose"(%587, %588) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_68
Type: OpType.ReshapeType
Arguments: ['mul_33', [1, 1536]]
Parents: ['mul_33']
Children: ['addmm_10']
--------------------MLIR OPS--------------------
%590 = "tosa.reshape"(%578) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_36
Type: OpType.ReshapeType
Arguments: ['arg99_1', [1, 0]]
Parents: ['arg99_1']
Children: ['addmm_10']
--------------------MLIR OPS--------------------
%591 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%592 = "tosa.transpose"(%arg49, %591) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_10
Type: OpType.ReduceType
Arguments: ['arg100_1', 'view_68', 'permute_36']
Parents: ['arg100_1', 'view_68', 'permute_36']
Children: ['view_69']
--------------------MLIR OPS--------------------
%593 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%594 = "linalg.matmul"(%590, %592, %593) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %597 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %598 = "arith.addf"(%arg400, %597) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%598) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%595 = "tosa.reshape"(%arg50) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%596 = "tosa.add"(%595, %594) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_69
Type: OpType.ReshapeType
Arguments: ['addmm_10', [1, 1, 256]]
Parents: ['addmm_10']
Children: ['view_70']
--------------------MLIR OPS--------------------
%597 = "tosa.reshape"(%596) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_70
Type: OpType.ReshapeType
Arguments: ['view_69', [1, 1, -1, 128]]
Parents: ['view_69']
Children: ['permute_37']
--------------------MLIR OPS--------------------
%598 = "tosa.reshape"(%597) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_37
Type: OpType.ReshapeType
Arguments: ['view_70', [0, 2, 1, 3]]
Parents: ['view_70']
Children: ['mul_36', 'slice_75', 'slice_76']
--------------------MLIR OPS--------------------
%599 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%600 = "tosa.transpose"(%598, %599) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_71
Type: OpType.ReshapeType
Arguments: ['mul_33', [1, 1536]]
Parents: ['mul_33']
Children: ['addmm_11']
--------------------MLIR OPS--------------------
%601 = "tosa.reshape"(%578) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_38
Type: OpType.ReshapeType
Arguments: ['arg101_1', [1, 0]]
Parents: ['arg101_1']
Children: ['addmm_11']
--------------------MLIR OPS--------------------
%602 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%603 = "tosa.transpose"(%arg51, %602) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_11
Type: OpType.ReduceType
Arguments: ['arg102_1', 'view_71', 'permute_38']
Parents: ['arg102_1', 'view_71', 'permute_38']
Children: ['view_72']
--------------------MLIR OPS--------------------
%604 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%605 = "linalg.matmul"(%601, %603, %604) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %608 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %609 = "arith.addf"(%arg400, %608) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%609) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%606 = "tosa.reshape"(%arg52) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%607 = "tosa.add"(%606, %605) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_72
Type: OpType.ReshapeType
Arguments: ['addmm_11', [1, 1, 256]]
Parents: ['addmm_11']
Children: ['view_73']
--------------------MLIR OPS--------------------
%608 = "tosa.reshape"(%607) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_73
Type: OpType.ReshapeType
Arguments: ['view_72', [1, 1, -1, 128]]
Parents: ['view_72']
Children: ['permute_39']
--------------------MLIR OPS--------------------
%609 = "tosa.reshape"(%608) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_39
Type: OpType.ReshapeType
Arguments: ['view_73', [0, 2, 1, 3]]
Parents: ['view_73']
Children: ['index_put_7']
--------------------MLIR OPS--------------------
%610 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%611 = "tosa.transpose"(%609, %610) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_23
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_34', 'mul_36']
--------------------MLIR OPS--------------------
%612 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_24
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_35', 'mul_37']
--------------------MLIR OPS--------------------
%613 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_34
Type: OpType.BroadcastType
Arguments: ['permute_35', 'unsqueeze_23']
Parents: ['permute_35', 'unsqueeze_23']
Children: ['add_20']
--------------------MLIR OPS--------------------
%614 = "tosa.mul"(%589, %612) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_73
Type: OpType.ReshapeType
Arguments: ['permute_35', 3, 0, 64]
Parents: ['permute_35']
Children: ['cat_6']
--------------------MLIR OPS--------------------
%615 = "tensor.extract_slice"(%589) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_74
Type: OpType.ReshapeType
Arguments: ['permute_35', 3, 64, 9223372036854775807]
Parents: ['permute_35']
Children: ['neg_6']
--------------------MLIR OPS--------------------
%616 = "tensor.extract_slice"(%589) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_6
Type: OpType.ElementwiseType
Arguments: ['slice_74']
Parents: ['slice_74']
Children: ['cat_6']
--------------------MLIR OPS--------------------
%617 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%618 = "linalg.negf"(%616, %617) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %619 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%619) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_6
Type: OpType.ConcatType
Arguments: [[neg_6, slice_73], -1]
Parents: []
Children: ['mul_35']
--------------------MLIR OPS--------------------
%619 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%620 = "tensor.insert_slice"(%618, %619) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%621 = "tensor.insert_slice"(%615, %620) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_35
Type: OpType.BroadcastType
Arguments: ['cat_6', 'unsqueeze_24']
Parents: ['cat_6', 'unsqueeze_24']
Children: ['add_20']
--------------------MLIR OPS--------------------
%622 = "tosa.mul"(%621, %613) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_20
Type: OpType.BroadcastType
Arguments: ['mul_34', 'mul_35']
Parents: ['mul_34', 'mul_35']
Children: ['_scaled_dot_product_flash_attention_for_cpu_3']
--------------------MLIR OPS--------------------
%623 = "tosa.add"(%614, %622) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_36
Type: OpType.BroadcastType
Arguments: ['permute_37', 'unsqueeze_23']
Parents: ['permute_37', 'unsqueeze_23']
Children: ['add_21']
--------------------MLIR OPS--------------------
%624 = "tosa.mul"(%600, %612) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_75
Type: OpType.ReshapeType
Arguments: ['permute_37', 3, 0, 64]
Parents: ['permute_37']
Children: ['cat_7']
--------------------MLIR OPS--------------------
%625 = "tensor.extract_slice"(%600) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_76
Type: OpType.ReshapeType
Arguments: ['permute_37', 3, 64, 9223372036854775807]
Parents: ['permute_37']
Children: ['neg_7']
--------------------MLIR OPS--------------------
%626 = "tensor.extract_slice"(%600) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_7
Type: OpType.ElementwiseType
Arguments: ['slice_76']
Parents: ['slice_76']
Children: ['cat_7']
--------------------MLIR OPS--------------------
%627 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%628 = "linalg.negf"(%626, %627) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %629 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%629) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_7
Type: OpType.ConcatType
Arguments: [[neg_7, slice_75], -1]
Parents: []
Children: ['mul_37']
--------------------MLIR OPS--------------------
%629 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%630 = "tensor.insert_slice"(%628, %629) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%631 = "tensor.insert_slice"(%625, %630) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_37
Type: OpType.BroadcastType
Arguments: ['cat_7', 'unsqueeze_24']
Parents: ['cat_7', 'unsqueeze_24']
Children: ['add_21']
--------------------MLIR OPS--------------------
%632 = "tosa.mul"(%631, %613) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_21
Type: OpType.BroadcastType
Arguments: ['mul_36', 'mul_37']
Parents: ['mul_36', 'mul_37']
Children: ['index_put_6']
--------------------MLIR OPS--------------------
%633 = "tosa.add"(%624, %632) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_6
Type: OpType.ElementwiseType
Arguments: ['arg6_1', [None, None, arg58_1], 'add_21']
Parents: ['arg6_1', 'add_21']
Children: ['slice_81', 'output']
--------------------MLIR OPS--------------------
%634 = "bufferization.to_memref"(%arg53) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%635 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%636 = "bufferization.to_memref"(%633) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%637 = "arith.constant"() <{value = 0 : index}> : () -> index
%638 = "arith.constant"() <{value = 1 : index}> : () -> index
%639 = "arith.constant"() <{value = 1 : index}> : () -> index
%640 = "arith.constant"() <{value = 2 : index}> : () -> index
%641 = "arith.constant"() <{value = 1 : index}> : () -> index
%642 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%637, %639, %638) ({
^bb0(%arg398: index):
  "scf.for"(%637, %640, %638) ({
  ^bb0(%arg399: index):
    "scf.for"(%637, %641, %638) ({
    ^bb0(%arg400: index):
      %644 = "memref.load"(%635, %arg400) : (memref<1xi64>, index) -> i64
      %645 = "arith.index_cast"(%644) : (i64) -> index
      "scf.for"(%637, %642, %638) ({
      ^bb0(%arg401: index):
        %646 = "memref.load"(%636, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%646, %634, %arg398, %arg399, %645, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%643 = "bufferization.to_tensor"(%634) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_7
Type: OpType.ElementwiseType
Arguments: ['arg7_1', [None, None, arg58_1], 'permute_39']
Parents: ['arg7_1', 'permute_39']
Children: ['slice_89', 'output']
--------------------MLIR OPS--------------------
%644 = "bufferization.to_memref"(%arg54) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%645 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%646 = "bufferization.to_memref"(%611) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%647 = "arith.constant"() <{value = 0 : index}> : () -> index
%648 = "arith.constant"() <{value = 1 : index}> : () -> index
%649 = "arith.constant"() <{value = 1 : index}> : () -> index
%650 = "arith.constant"() <{value = 2 : index}> : () -> index
%651 = "arith.constant"() <{value = 1 : index}> : () -> index
%652 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%647, %649, %648) ({
^bb0(%arg398: index):
  "scf.for"(%647, %650, %648) ({
  ^bb0(%arg399: index):
    "scf.for"(%647, %651, %648) ({
    ^bb0(%arg400: index):
      %654 = "memref.load"(%645, %arg400) : (memref<1xi64>, index) -> i64
      %655 = "arith.index_cast"(%654) : (i64) -> index
      "scf.for"(%647, %652, %648) ({
      ^bb0(%arg401: index):
        %656 = "memref.load"(%646, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%656, %644, %arg398, %arg399, %655, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%653 = "bufferization.to_tensor"(%644) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_81
Type: OpType.ReshapeType
Arguments: ['index_put_6', 0, 0, 9223372036854775807]
Parents: ['index_put_6']
Children: ['slice_82']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_82
Type: OpType.ReshapeType
Arguments: ['slice_81', 1, 0, 9223372036854775807]
Parents: ['slice_81']
Children: ['unsqueeze_26']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_26
Type: OpType.ReshapeType
Arguments: ['slice_82', 2]
Parents: ['slice_82']
Children: ['slice_83']
--------------------MLIR OPS--------------------
%654 = "tosa.reshape"(%643) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_83
Type: OpType.ReshapeType
Arguments: ['unsqueeze_26', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_26']
Children: ['slice_84']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_84
Type: OpType.ReshapeType
Arguments: ['slice_83', 4, 0, 9223372036854775807]
Parents: ['slice_83']
Children: ['expand_19']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_19
Type: OpType.ReshapeType
Arguments: ['slice_84', [1, 2, 6, 1024, 128]]
Parents: ['slice_84']
Children: ['clone_8']
--------------------MLIR OPS--------------------
%655 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%656 = "tosa.add"(%654, %655) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_8
Type: OpType.ReduceType
Arguments: ['expand_19']
Parents: ['expand_19']
Children: ['view_74']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_74
Type: OpType.ReshapeType
Arguments: ['clone_8', [1, 12, 1024, 128]]
Parents: ['clone_8']
Children: ['_scaled_dot_product_flash_attention_for_cpu_3']
--------------------MLIR OPS--------------------
%657 = "tosa.reshape"(%656) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_89
Type: OpType.ReshapeType
Arguments: ['index_put_7', 0, 0, 9223372036854775807]
Parents: ['index_put_7']
Children: ['slice_90']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_90
Type: OpType.ReshapeType
Arguments: ['slice_89', 1, 0, 9223372036854775807]
Parents: ['slice_89']
Children: ['unsqueeze_28']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_28
Type: OpType.ReshapeType
Arguments: ['slice_90', 2]
Parents: ['slice_90']
Children: ['slice_91']
--------------------MLIR OPS--------------------
%658 = "tosa.reshape"(%653) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_91
Type: OpType.ReshapeType
Arguments: ['unsqueeze_28', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_28']
Children: ['slice_92']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_92
Type: OpType.ReshapeType
Arguments: ['slice_91', 4, 0, 9223372036854775807]
Parents: ['slice_91']
Children: ['expand_21']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_21
Type: OpType.ReshapeType
Arguments: ['slice_92', [1, 2, 6, 1024, 128]]
Parents: ['slice_92']
Children: ['clone_9']
--------------------MLIR OPS--------------------
%659 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%660 = "tosa.add"(%658, %659) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_9
Type: OpType.ReduceType
Arguments: ['expand_21']
Parents: ['expand_21']
Children: ['view_75']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_75
Type: OpType.ReshapeType
Arguments: ['clone_9', [1, 12, 1024, 128]]
Parents: ['clone_9']
Children: ['_scaled_dot_product_flash_attention_for_cpu_3']
--------------------MLIR OPS--------------------
%661 = "tosa.reshape"(%660) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_93
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_94']
--------------------MLIR OPS--------------------
%662 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_94
Type: OpType.ReshapeType
Arguments: ['slice_93', 1, 0, 9223372036854775807]
Parents: ['slice_93']
Children: ['slice_95']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_95
Type: OpType.ReshapeType
Arguments: ['slice_94', 2, 0, 9223372036854775807]
Parents: ['slice_94']
Children: ['where_3']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_6
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_3']
--------------------MLIR OPS--------------------
%663 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_7
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_3']
--------------------MLIR OPS--------------------
%664 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_3
Type: OpType.ElementwiseType
Arguments: ['slice_95', 'scalar_tensor_7', 'scalar_tensor_6']
Parents: ['slice_95', 'scalar_tensor_7', 'scalar_tensor_6']
Children: ['_scaled_dot_product_flash_attention_for_cpu_3']
--------------------MLIR OPS--------------------
%665 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%666 = "tensor.splat"(%664) : (f32) -> tensor<1x1x1x1024xf32>
%667 = "tensor.splat"(%663) : (f32) -> tensor<1x1x1x1024xf32>
%668 = "linalg.generic"(%662, %666, %667, %665) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %669 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%669) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_3
Type: OpType.ElementwiseType
Arguments: ['add_20', 'view_74', 'view_75']
Parents: ['add_20', 'view_74', 'view_75']
Children: ['getitem_6']
--------------------MLIR OPS--------------------
%669 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%670 = "tensor.splat"(%669) : (f32) -> tensor<1x1024xf32>
%671 = "tosa.reshape"(%668) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%672 = "tosa.add"(%670, %671) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%673 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%674 = "tosa.transpose"(%657, %673) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%675 = "tosa.reshape"(%623) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%676 = "tosa.reshape"(%674) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%677 = "tosa.matmul"(%675, %676) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%678 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%679 = "tensor.splat"(%678) : (f32) -> tensor<12x1x1024xf32>
%680 = "tosa.mul"(%677, %679) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%681 = "tosa.reshape"(%672) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%682 = "tosa.add"(%680, %681) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%683 = "tosa.reduce_max"(%682) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%684 = "tosa.sub"(%682, %683) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%685 = "math.exp"(%684) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%686 = "tosa.reduce_sum"(%685) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%687 = "tosa.log"(%686) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%688 = "tosa.add"(%683, %687) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%689 = "tosa.sub"(%682, %688) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%690 = "math.exp"(%689) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%691 = "tosa.reshape"(%688) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%692 = "tosa.reshape"(%661) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%693 = "tosa.matmul"(%690, %692) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%694 = "tosa.reshape"(%693) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_6
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_3', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_3']
Children: ['permute_40']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_40
Type: OpType.ReshapeType
Arguments: ['getitem_6', [0, 2, 1, 3]]
Parents: ['getitem_6']
Children: ['view_76']
--------------------MLIR OPS--------------------
%695 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%696 = "tosa.transpose"(%694, %695) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_76
Type: OpType.ReshapeType
Arguments: ['permute_40', [1, 1, -1]]
Parents: ['permute_40']
Children: ['view_77']
--------------------MLIR OPS--------------------
%697 = "tosa.reshape"(%696) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_41
Type: OpType.ReshapeType
Arguments: ['arg103_1', [1, 0]]
Parents: ['arg103_1']
Children: ['mm_12']
--------------------MLIR OPS--------------------
%698 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%699 = "tosa.transpose"(%arg55, %698) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_77
Type: OpType.ReshapeType
Arguments: ['view_76', [1, 1536]]
Parents: ['view_76']
Children: ['mm_12']
--------------------MLIR OPS--------------------
%700 = "tosa.reshape"(%697) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_12
Type: OpType.ReduceType
Arguments: ['view_77', 'permute_41']
Parents: ['view_77', 'permute_41']
Children: ['view_78']
--------------------MLIR OPS--------------------
%701 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%702 = "linalg.matmul"(%700, %699, %701) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %703 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %704 = "arith.addf"(%arg400, %703) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%704) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_78
Type: OpType.ReshapeType
Arguments: ['mm_12', [1, 1, 1536]]
Parents: ['mm_12']
Children: ['add_22']
--------------------MLIR OPS--------------------
%703 = "tosa.reshape"(%702) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_22
Type: OpType.BroadcastType
Arguments: ['add_18', 'view_78']
Parents: ['add_18', 'view_78']
Children: ['pow_8', 'mul_38', 'add_24']
--------------------MLIR OPS--------------------
%704 = "tosa.add"(%564, %703) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_8
Type: OpType.BroadcastType
Arguments: ['add_22', 2]
Parents: ['add_22']
Children: ['mean_7']
--------------------MLIR OPS--------------------
%705 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%706 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%707 = "linalg.generic"(%704, %705) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %708 = "math.fpowi"(%arg398, %706) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%708) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_7
Type: OpType.ReduceType
Arguments: ['pow_8', [-1], True]
Parents: ['pow_8']
Children: ['add_23']
--------------------MLIR OPS--------------------
%708 = "tosa.reduce_sum"(%707) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%709 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%710 = "tosa.reciprocal"(%709) : (tensor<1xf32>) -> tensor<1xf32>
%711 = "tosa.reshape"(%710) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%712 = "tosa.mul"(%711, %708) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_23
Type: OpType.BroadcastType
Arguments: ['mean_7', 1e-06]
Parents: ['mean_7']
Children: ['rsqrt_7']
--------------------MLIR OPS--------------------
%713 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%714 = "tosa.add"(%712, %713) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_7
Type: OpType.ElementwiseType
Arguments: ['add_23']
Parents: ['add_23']
Children: ['mul_38']
--------------------MLIR OPS--------------------
%715 = "tosa.rsqrt"(%714) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_38
Type: OpType.BroadcastType
Arguments: ['add_22', 'rsqrt_7']
Parents: ['add_22', 'rsqrt_7']
Children: ['mul_39']
--------------------MLIR OPS--------------------
%716 = "tosa.mul"(%704, %715) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_39
Type: OpType.BroadcastType
Arguments: ['arg104_1', 'mul_38']
Parents: ['arg104_1', 'mul_38']
Children: ['view_79', 'view_81']
--------------------MLIR OPS--------------------
%717 = "tosa.reshape"(%arg56) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%718 = "tosa.mul"(%717, %716) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_42
Type: OpType.ReshapeType
Arguments: ['arg105_1', [1, 0]]
Parents: ['arg105_1']
Children: ['mm_13']
--------------------MLIR OPS--------------------
%719 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%720 = "tosa.transpose"(%arg57, %719) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_79
Type: OpType.ReshapeType
Arguments: ['mul_39', [1, 1536]]
Parents: ['mul_39']
Children: ['mm_13']
--------------------MLIR OPS--------------------
%721 = "tosa.reshape"(%718) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_13
Type: OpType.ReduceType
Arguments: ['view_79', 'permute_42']
Parents: ['view_79', 'permute_42']
Children: ['view_80']
--------------------MLIR OPS--------------------
%722 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%723 = "linalg.matmul"(%721, %720, %722) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %724 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %725 = "arith.addf"(%arg400, %724) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%725) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_80
Type: OpType.ReshapeType
Arguments: ['mm_13', [1, 1, 8960]]
Parents: ['mm_13']
Children: ['sigmoid_3', 'mul_40']
--------------------MLIR OPS--------------------
%724 = "tosa.reshape"(%723) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_3
Type: OpType.ElementwiseType
Arguments: ['view_80']
Parents: ['view_80']
Children: ['mul_40']
--------------------MLIR OPS--------------------
%725 = "tosa.sigmoid"(%724) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_40
Type: OpType.BroadcastType
Arguments: ['view_80', 'sigmoid_3']
Parents: ['view_80', 'sigmoid_3']
Children: ['mul_41']
--------------------MLIR OPS--------------------
%726 = "tosa.mul"(%724, %725) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_43
Type: OpType.ReshapeType
Arguments: ['arg106_1', [1, 0]]
Parents: ['arg106_1']
Children: ['mm_14']
--------------------MLIR OPS--------------------
%727 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%728 = "tosa.transpose"(%arg58, %727) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_81
Type: OpType.ReshapeType
Arguments: ['mul_39', [1, 1536]]
Parents: ['mul_39']
Children: ['mm_14']
--------------------MLIR OPS--------------------
%729 = "tosa.reshape"(%718) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_14
Type: OpType.ReduceType
Arguments: ['view_81', 'permute_43']
Parents: ['view_81', 'permute_43']
Children: ['view_82']
--------------------MLIR OPS--------------------
%730 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%731 = "linalg.matmul"(%729, %728, %730) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %732 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %733 = "arith.addf"(%arg400, %732) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%733) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_82
Type: OpType.ReshapeType
Arguments: ['mm_14', [1, 1, 8960]]
Parents: ['mm_14']
Children: ['mul_41']
--------------------MLIR OPS--------------------
%732 = "tosa.reshape"(%731) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_41
Type: OpType.BroadcastType
Arguments: ['mul_40', 'view_82']
Parents: ['mul_40', 'view_82']
Children: ['view_83']
--------------------MLIR OPS--------------------
%733 = "tosa.mul"(%726, %732) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_44
Type: OpType.ReshapeType
Arguments: ['arg107_1', [1, 0]]
Parents: ['arg107_1']
Children: ['mm_15']
--------------------MLIR OPS--------------------
%734 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%735 = "tosa.transpose"(%arg59, %734) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_83
Type: OpType.ReshapeType
Arguments: ['mul_41', [1, 8960]]
Parents: ['mul_41']
Children: ['mm_15']
--------------------MLIR OPS--------------------
%736 = "tosa.reshape"(%733) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_15
Type: OpType.ReduceType
Arguments: ['view_83', 'permute_44']
Parents: ['view_83', 'permute_44']
Children: ['view_84']
--------------------MLIR OPS--------------------
%737 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%738 = "linalg.matmul"(%736, %735, %737) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %739 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %740 = "arith.addf"(%arg400, %739) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%740) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_84
Type: OpType.ReshapeType
Arguments: ['mm_15', [1, 1, 1536]]
Parents: ['mm_15']
Children: ['add_24']
--------------------MLIR OPS--------------------
%739 = "tosa.reshape"(%738) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_24
Type: OpType.BroadcastType
Arguments: ['add_22', 'view_84']
Parents: ['add_22', 'view_84']
Children: ['pow_9', 'mul_42', 'add_28']
--------------------MLIR OPS--------------------
%740 = "tosa.add"(%704, %739) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_9
Type: OpType.BroadcastType
Arguments: ['add_24', 2]
Parents: ['add_24']
Children: ['mean_8']
--------------------MLIR OPS--------------------
%741 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%742 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%743 = "linalg.generic"(%740, %741) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %744 = "math.fpowi"(%arg398, %742) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%744) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_8
Type: OpType.ReduceType
Arguments: ['pow_9', [-1], True]
Parents: ['pow_9']
Children: ['add_25']
--------------------MLIR OPS--------------------
%744 = "tosa.reduce_sum"(%743) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%745 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%746 = "tosa.reciprocal"(%745) : (tensor<1xf32>) -> tensor<1xf32>
%747 = "tosa.reshape"(%746) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%748 = "tosa.mul"(%747, %744) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_25
Type: OpType.BroadcastType
Arguments: ['mean_8', 1e-06]
Parents: ['mean_8']
Children: ['rsqrt_8']
--------------------MLIR OPS--------------------
%749 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%750 = "tosa.add"(%748, %749) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_8
Type: OpType.ElementwiseType
Arguments: ['add_25']
Parents: ['add_25']
Children: ['mul_42']
--------------------MLIR OPS--------------------
%751 = "tosa.rsqrt"(%750) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_42
Type: OpType.BroadcastType
Arguments: ['add_24', 'rsqrt_8']
Parents: ['add_24', 'rsqrt_8']
Children: ['mul_43']
--------------------MLIR OPS--------------------
%752 = "tosa.mul"(%740, %751) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_43
Type: OpType.BroadcastType
Arguments: ['arg108_1', 'mul_42']
Parents: ['arg108_1', 'mul_42']
Children: ['view_85', 'view_88', 'view_91']
--------------------MLIR OPS--------------------
%753 = "tosa.reshape"(%arg60) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%754 = "tosa.mul"(%753, %752) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_85
Type: OpType.ReshapeType
Arguments: ['mul_43', [1, 1536]]
Parents: ['mul_43']
Children: ['addmm_12']
--------------------MLIR OPS--------------------
%755 = "tosa.reshape"(%754) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_45
Type: OpType.ReshapeType
Arguments: ['arg109_1', [1, 0]]
Parents: ['arg109_1']
Children: ['addmm_12']
--------------------MLIR OPS--------------------
%756 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%757 = "tosa.transpose"(%arg61, %756) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_12
Type: OpType.ReduceType
Arguments: ['arg110_1', 'view_85', 'permute_45']
Parents: ['arg110_1', 'view_85', 'permute_45']
Children: ['view_86']
--------------------MLIR OPS--------------------
%758 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%759 = "linalg.matmul"(%755, %757, %758) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %762 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %763 = "arith.addf"(%arg400, %762) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%763) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%760 = "tosa.reshape"(%arg62) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%761 = "tosa.add"(%760, %759) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_86
Type: OpType.ReshapeType
Arguments: ['addmm_12', [1, 1, 1536]]
Parents: ['addmm_12']
Children: ['view_87']
--------------------MLIR OPS--------------------
%762 = "tosa.reshape"(%761) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_87
Type: OpType.ReshapeType
Arguments: ['view_86', [1, 1, -1, 128]]
Parents: ['view_86']
Children: ['permute_46']
--------------------MLIR OPS--------------------
%763 = "tosa.reshape"(%762) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_46
Type: OpType.ReshapeType
Arguments: ['view_87', [0, 2, 1, 3]]
Parents: ['view_87']
Children: ['mul_44', 'slice_96', 'slice_97']
--------------------MLIR OPS--------------------
%764 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%765 = "tosa.transpose"(%763, %764) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_88
Type: OpType.ReshapeType
Arguments: ['mul_43', [1, 1536]]
Parents: ['mul_43']
Children: ['addmm_13']
--------------------MLIR OPS--------------------
%766 = "tosa.reshape"(%754) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_47
Type: OpType.ReshapeType
Arguments: ['arg111_1', [1, 0]]
Parents: ['arg111_1']
Children: ['addmm_13']
--------------------MLIR OPS--------------------
%767 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%768 = "tosa.transpose"(%arg63, %767) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_13
Type: OpType.ReduceType
Arguments: ['arg112_1', 'view_88', 'permute_47']
Parents: ['arg112_1', 'view_88', 'permute_47']
Children: ['view_89']
--------------------MLIR OPS--------------------
%769 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%770 = "linalg.matmul"(%766, %768, %769) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %773 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %774 = "arith.addf"(%arg400, %773) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%774) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%771 = "tosa.reshape"(%arg64) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%772 = "tosa.add"(%771, %770) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_89
Type: OpType.ReshapeType
Arguments: ['addmm_13', [1, 1, 256]]
Parents: ['addmm_13']
Children: ['view_90']
--------------------MLIR OPS--------------------
%773 = "tosa.reshape"(%772) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_90
Type: OpType.ReshapeType
Arguments: ['view_89', [1, 1, -1, 128]]
Parents: ['view_89']
Children: ['permute_48']
--------------------MLIR OPS--------------------
%774 = "tosa.reshape"(%773) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_48
Type: OpType.ReshapeType
Arguments: ['view_90', [0, 2, 1, 3]]
Parents: ['view_90']
Children: ['mul_46', 'slice_98', 'slice_99']
--------------------MLIR OPS--------------------
%775 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%776 = "tosa.transpose"(%774, %775) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_91
Type: OpType.ReshapeType
Arguments: ['mul_43', [1, 1536]]
Parents: ['mul_43']
Children: ['addmm_14']
--------------------MLIR OPS--------------------
%777 = "tosa.reshape"(%754) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_49
Type: OpType.ReshapeType
Arguments: ['arg113_1', [1, 0]]
Parents: ['arg113_1']
Children: ['addmm_14']
--------------------MLIR OPS--------------------
%778 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%779 = "tosa.transpose"(%arg65, %778) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_14
Type: OpType.ReduceType
Arguments: ['arg114_1', 'view_91', 'permute_49']
Parents: ['arg114_1', 'view_91', 'permute_49']
Children: ['view_92']
--------------------MLIR OPS--------------------
%780 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%781 = "linalg.matmul"(%777, %779, %780) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %784 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %785 = "arith.addf"(%arg400, %784) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%785) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%782 = "tosa.reshape"(%arg66) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%783 = "tosa.add"(%782, %781) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_92
Type: OpType.ReshapeType
Arguments: ['addmm_14', [1, 1, 256]]
Parents: ['addmm_14']
Children: ['view_93']
--------------------MLIR OPS--------------------
%784 = "tosa.reshape"(%783) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_93
Type: OpType.ReshapeType
Arguments: ['view_92', [1, 1, -1, 128]]
Parents: ['view_92']
Children: ['permute_50']
--------------------MLIR OPS--------------------
%785 = "tosa.reshape"(%784) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_50
Type: OpType.ReshapeType
Arguments: ['view_93', [0, 2, 1, 3]]
Parents: ['view_93']
Children: ['index_put_9']
--------------------MLIR OPS--------------------
%786 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%787 = "tosa.transpose"(%785, %786) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_29
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_44', 'mul_46']
--------------------MLIR OPS--------------------
%788 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_30
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_45', 'mul_47']
--------------------MLIR OPS--------------------
%789 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_44
Type: OpType.BroadcastType
Arguments: ['permute_46', 'unsqueeze_29']
Parents: ['permute_46', 'unsqueeze_29']
Children: ['add_26']
--------------------MLIR OPS--------------------
%790 = "tosa.mul"(%765, %788) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_96
Type: OpType.ReshapeType
Arguments: ['permute_46', 3, 0, 64]
Parents: ['permute_46']
Children: ['cat_8']
--------------------MLIR OPS--------------------
%791 = "tensor.extract_slice"(%765) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_97
Type: OpType.ReshapeType
Arguments: ['permute_46', 3, 64, 9223372036854775807]
Parents: ['permute_46']
Children: ['neg_8']
--------------------MLIR OPS--------------------
%792 = "tensor.extract_slice"(%765) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_8
Type: OpType.ElementwiseType
Arguments: ['slice_97']
Parents: ['slice_97']
Children: ['cat_8']
--------------------MLIR OPS--------------------
%793 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%794 = "linalg.negf"(%792, %793) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %795 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%795) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_8
Type: OpType.ConcatType
Arguments: [[neg_8, slice_96], -1]
Parents: []
Children: ['mul_45']
--------------------MLIR OPS--------------------
%795 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%796 = "tensor.insert_slice"(%794, %795) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%797 = "tensor.insert_slice"(%791, %796) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_45
Type: OpType.BroadcastType
Arguments: ['cat_8', 'unsqueeze_30']
Parents: ['cat_8', 'unsqueeze_30']
Children: ['add_26']
--------------------MLIR OPS--------------------
%798 = "tosa.mul"(%797, %789) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_26
Type: OpType.BroadcastType
Arguments: ['mul_44', 'mul_45']
Parents: ['mul_44', 'mul_45']
Children: ['_scaled_dot_product_flash_attention_for_cpu_4']
--------------------MLIR OPS--------------------
%799 = "tosa.add"(%790, %798) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_46
Type: OpType.BroadcastType
Arguments: ['permute_48', 'unsqueeze_29']
Parents: ['permute_48', 'unsqueeze_29']
Children: ['add_27']
--------------------MLIR OPS--------------------
%800 = "tosa.mul"(%776, %788) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_98
Type: OpType.ReshapeType
Arguments: ['permute_48', 3, 0, 64]
Parents: ['permute_48']
Children: ['cat_9']
--------------------MLIR OPS--------------------
%801 = "tensor.extract_slice"(%776) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_99
Type: OpType.ReshapeType
Arguments: ['permute_48', 3, 64, 9223372036854775807]
Parents: ['permute_48']
Children: ['neg_9']
--------------------MLIR OPS--------------------
%802 = "tensor.extract_slice"(%776) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_9
Type: OpType.ElementwiseType
Arguments: ['slice_99']
Parents: ['slice_99']
Children: ['cat_9']
--------------------MLIR OPS--------------------
%803 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%804 = "linalg.negf"(%802, %803) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %805 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%805) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_9
Type: OpType.ConcatType
Arguments: [[neg_9, slice_98], -1]
Parents: []
Children: ['mul_47']
--------------------MLIR OPS--------------------
%805 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%806 = "tensor.insert_slice"(%804, %805) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%807 = "tensor.insert_slice"(%801, %806) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_47
Type: OpType.BroadcastType
Arguments: ['cat_9', 'unsqueeze_30']
Parents: ['cat_9', 'unsqueeze_30']
Children: ['add_27']
--------------------MLIR OPS--------------------
%808 = "tosa.mul"(%807, %789) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_27
Type: OpType.BroadcastType
Arguments: ['mul_46', 'mul_47']
Parents: ['mul_46', 'mul_47']
Children: ['index_put_8']
--------------------MLIR OPS--------------------
%809 = "tosa.add"(%800, %808) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_8
Type: OpType.ElementwiseType
Arguments: ['arg8_1', [None, None, arg58_1], 'add_27']
Parents: ['arg8_1', 'add_27']
Children: ['slice_104', 'output']
--------------------MLIR OPS--------------------
%810 = "bufferization.to_memref"(%arg67) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%811 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%812 = "bufferization.to_memref"(%809) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%813 = "arith.constant"() <{value = 0 : index}> : () -> index
%814 = "arith.constant"() <{value = 1 : index}> : () -> index
%815 = "arith.constant"() <{value = 1 : index}> : () -> index
%816 = "arith.constant"() <{value = 2 : index}> : () -> index
%817 = "arith.constant"() <{value = 1 : index}> : () -> index
%818 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%813, %815, %814) ({
^bb0(%arg398: index):
  "scf.for"(%813, %816, %814) ({
  ^bb0(%arg399: index):
    "scf.for"(%813, %817, %814) ({
    ^bb0(%arg400: index):
      %820 = "memref.load"(%811, %arg400) : (memref<1xi64>, index) -> i64
      %821 = "arith.index_cast"(%820) : (i64) -> index
      "scf.for"(%813, %818, %814) ({
      ^bb0(%arg401: index):
        %822 = "memref.load"(%812, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%822, %810, %arg398, %arg399, %821, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%819 = "bufferization.to_tensor"(%810) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_9
Type: OpType.ElementwiseType
Arguments: ['arg9_1', [None, None, arg58_1], 'permute_50']
Parents: ['arg9_1', 'permute_50']
Children: ['slice_112', 'output']
--------------------MLIR OPS--------------------
%820 = "bufferization.to_memref"(%arg68) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%821 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%822 = "bufferization.to_memref"(%787) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%823 = "arith.constant"() <{value = 0 : index}> : () -> index
%824 = "arith.constant"() <{value = 1 : index}> : () -> index
%825 = "arith.constant"() <{value = 1 : index}> : () -> index
%826 = "arith.constant"() <{value = 2 : index}> : () -> index
%827 = "arith.constant"() <{value = 1 : index}> : () -> index
%828 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%823, %825, %824) ({
^bb0(%arg398: index):
  "scf.for"(%823, %826, %824) ({
  ^bb0(%arg399: index):
    "scf.for"(%823, %827, %824) ({
    ^bb0(%arg400: index):
      %830 = "memref.load"(%821, %arg400) : (memref<1xi64>, index) -> i64
      %831 = "arith.index_cast"(%830) : (i64) -> index
      "scf.for"(%823, %828, %824) ({
      ^bb0(%arg401: index):
        %832 = "memref.load"(%822, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%832, %820, %arg398, %arg399, %831, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%829 = "bufferization.to_tensor"(%820) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_104
Type: OpType.ReshapeType
Arguments: ['index_put_8', 0, 0, 9223372036854775807]
Parents: ['index_put_8']
Children: ['slice_105']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_105
Type: OpType.ReshapeType
Arguments: ['slice_104', 1, 0, 9223372036854775807]
Parents: ['slice_104']
Children: ['unsqueeze_32']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_32
Type: OpType.ReshapeType
Arguments: ['slice_105', 2]
Parents: ['slice_105']
Children: ['slice_106']
--------------------MLIR OPS--------------------
%830 = "tosa.reshape"(%819) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_106
Type: OpType.ReshapeType
Arguments: ['unsqueeze_32', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_32']
Children: ['slice_107']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_107
Type: OpType.ReshapeType
Arguments: ['slice_106', 4, 0, 9223372036854775807]
Parents: ['slice_106']
Children: ['expand_23']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_23
Type: OpType.ReshapeType
Arguments: ['slice_107', [1, 2, 6, 1024, 128]]
Parents: ['slice_107']
Children: ['clone_10']
--------------------MLIR OPS--------------------
%831 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%832 = "tosa.add"(%830, %831) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_10
Type: OpType.ReduceType
Arguments: ['expand_23']
Parents: ['expand_23']
Children: ['view_94']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_94
Type: OpType.ReshapeType
Arguments: ['clone_10', [1, 12, 1024, 128]]
Parents: ['clone_10']
Children: ['_scaled_dot_product_flash_attention_for_cpu_4']
--------------------MLIR OPS--------------------
%833 = "tosa.reshape"(%832) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_112
Type: OpType.ReshapeType
Arguments: ['index_put_9', 0, 0, 9223372036854775807]
Parents: ['index_put_9']
Children: ['slice_113']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_113
Type: OpType.ReshapeType
Arguments: ['slice_112', 1, 0, 9223372036854775807]
Parents: ['slice_112']
Children: ['unsqueeze_34']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_34
Type: OpType.ReshapeType
Arguments: ['slice_113', 2]
Parents: ['slice_113']
Children: ['slice_114']
--------------------MLIR OPS--------------------
%834 = "tosa.reshape"(%829) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_114
Type: OpType.ReshapeType
Arguments: ['unsqueeze_34', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_34']
Children: ['slice_115']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_115
Type: OpType.ReshapeType
Arguments: ['slice_114', 4, 0, 9223372036854775807]
Parents: ['slice_114']
Children: ['expand_25']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_25
Type: OpType.ReshapeType
Arguments: ['slice_115', [1, 2, 6, 1024, 128]]
Parents: ['slice_115']
Children: ['clone_11']
--------------------MLIR OPS--------------------
%835 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%836 = "tosa.add"(%834, %835) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_11
Type: OpType.ReduceType
Arguments: ['expand_25']
Parents: ['expand_25']
Children: ['view_95']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_95
Type: OpType.ReshapeType
Arguments: ['clone_11', [1, 12, 1024, 128]]
Parents: ['clone_11']
Children: ['_scaled_dot_product_flash_attention_for_cpu_4']
--------------------MLIR OPS--------------------
%837 = "tosa.reshape"(%836) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_116
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_117']
--------------------MLIR OPS--------------------
%838 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_117
Type: OpType.ReshapeType
Arguments: ['slice_116', 1, 0, 9223372036854775807]
Parents: ['slice_116']
Children: ['slice_118']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_118
Type: OpType.ReshapeType
Arguments: ['slice_117', 2, 0, 9223372036854775807]
Parents: ['slice_117']
Children: ['where_4']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_8
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_4']
--------------------MLIR OPS--------------------
%839 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_9
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_4']
--------------------MLIR OPS--------------------
%840 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_4
Type: OpType.ElementwiseType
Arguments: ['slice_118', 'scalar_tensor_9', 'scalar_tensor_8']
Parents: ['slice_118', 'scalar_tensor_9', 'scalar_tensor_8']
Children: ['_scaled_dot_product_flash_attention_for_cpu_4']
--------------------MLIR OPS--------------------
%841 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%842 = "tensor.splat"(%840) : (f32) -> tensor<1x1x1x1024xf32>
%843 = "tensor.splat"(%839) : (f32) -> tensor<1x1x1x1024xf32>
%844 = "linalg.generic"(%838, %842, %843, %841) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %845 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%845) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_4
Type: OpType.ElementwiseType
Arguments: ['add_26', 'view_94', 'view_95']
Parents: ['add_26', 'view_94', 'view_95']
Children: ['getitem_8']
--------------------MLIR OPS--------------------
%845 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%846 = "tensor.splat"(%845) : (f32) -> tensor<1x1024xf32>
%847 = "tosa.reshape"(%844) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%848 = "tosa.add"(%846, %847) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%849 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%850 = "tosa.transpose"(%833, %849) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%851 = "tosa.reshape"(%799) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%852 = "tosa.reshape"(%850) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%853 = "tosa.matmul"(%851, %852) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%854 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%855 = "tensor.splat"(%854) : (f32) -> tensor<12x1x1024xf32>
%856 = "tosa.mul"(%853, %855) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%857 = "tosa.reshape"(%848) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%858 = "tosa.add"(%856, %857) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%859 = "tosa.reduce_max"(%858) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%860 = "tosa.sub"(%858, %859) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%861 = "math.exp"(%860) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%862 = "tosa.reduce_sum"(%861) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%863 = "tosa.log"(%862) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%864 = "tosa.add"(%859, %863) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%865 = "tosa.sub"(%858, %864) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%866 = "math.exp"(%865) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%867 = "tosa.reshape"(%864) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%868 = "tosa.reshape"(%837) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%869 = "tosa.matmul"(%866, %868) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%870 = "tosa.reshape"(%869) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_8
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_4', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_4']
Children: ['permute_51']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_51
Type: OpType.ReshapeType
Arguments: ['getitem_8', [0, 2, 1, 3]]
Parents: ['getitem_8']
Children: ['view_96']
--------------------MLIR OPS--------------------
%871 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%872 = "tosa.transpose"(%870, %871) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_96
Type: OpType.ReshapeType
Arguments: ['permute_51', [1, 1, -1]]
Parents: ['permute_51']
Children: ['view_97']
--------------------MLIR OPS--------------------
%873 = "tosa.reshape"(%872) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_52
Type: OpType.ReshapeType
Arguments: ['arg115_1', [1, 0]]
Parents: ['arg115_1']
Children: ['mm_16']
--------------------MLIR OPS--------------------
%874 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%875 = "tosa.transpose"(%arg69, %874) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_97
Type: OpType.ReshapeType
Arguments: ['view_96', [1, 1536]]
Parents: ['view_96']
Children: ['mm_16']
--------------------MLIR OPS--------------------
%876 = "tosa.reshape"(%873) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_16
Type: OpType.ReduceType
Arguments: ['view_97', 'permute_52']
Parents: ['view_97', 'permute_52']
Children: ['view_98']
--------------------MLIR OPS--------------------
%877 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%878 = "linalg.matmul"(%876, %875, %877) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %879 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %880 = "arith.addf"(%arg400, %879) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%880) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_98
Type: OpType.ReshapeType
Arguments: ['mm_16', [1, 1, 1536]]
Parents: ['mm_16']
Children: ['add_28']
--------------------MLIR OPS--------------------
%879 = "tosa.reshape"(%878) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_28
Type: OpType.BroadcastType
Arguments: ['add_24', 'view_98']
Parents: ['add_24', 'view_98']
Children: ['pow_10', 'mul_48', 'add_30']
--------------------MLIR OPS--------------------
%880 = "tosa.add"(%740, %879) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_10
Type: OpType.BroadcastType
Arguments: ['add_28', 2]
Parents: ['add_28']
Children: ['mean_9']
--------------------MLIR OPS--------------------
%881 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%882 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%883 = "linalg.generic"(%880, %881) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %884 = "math.fpowi"(%arg398, %882) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%884) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_9
Type: OpType.ReduceType
Arguments: ['pow_10', [-1], True]
Parents: ['pow_10']
Children: ['add_29']
--------------------MLIR OPS--------------------
%884 = "tosa.reduce_sum"(%883) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%885 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%886 = "tosa.reciprocal"(%885) : (tensor<1xf32>) -> tensor<1xf32>
%887 = "tosa.reshape"(%886) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%888 = "tosa.mul"(%887, %884) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_29
Type: OpType.BroadcastType
Arguments: ['mean_9', 1e-06]
Parents: ['mean_9']
Children: ['rsqrt_9']
--------------------MLIR OPS--------------------
%889 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%890 = "tosa.add"(%888, %889) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_9
Type: OpType.ElementwiseType
Arguments: ['add_29']
Parents: ['add_29']
Children: ['mul_48']
--------------------MLIR OPS--------------------
%891 = "tosa.rsqrt"(%890) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_48
Type: OpType.BroadcastType
Arguments: ['add_28', 'rsqrt_9']
Parents: ['add_28', 'rsqrt_9']
Children: ['mul_49']
--------------------MLIR OPS--------------------
%892 = "tosa.mul"(%880, %891) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_49
Type: OpType.BroadcastType
Arguments: ['arg116_1', 'mul_48']
Parents: ['arg116_1', 'mul_48']
Children: ['view_99', 'view_101']
--------------------MLIR OPS--------------------
%893 = "tosa.reshape"(%arg70) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%894 = "tosa.mul"(%893, %892) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_53
Type: OpType.ReshapeType
Arguments: ['arg117_1', [1, 0]]
Parents: ['arg117_1']
Children: ['mm_17']
--------------------MLIR OPS--------------------
%895 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%896 = "tosa.transpose"(%arg71, %895) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_99
Type: OpType.ReshapeType
Arguments: ['mul_49', [1, 1536]]
Parents: ['mul_49']
Children: ['mm_17']
--------------------MLIR OPS--------------------
%897 = "tosa.reshape"(%894) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_17
Type: OpType.ReduceType
Arguments: ['view_99', 'permute_53']
Parents: ['view_99', 'permute_53']
Children: ['view_100']
--------------------MLIR OPS--------------------
%898 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%899 = "linalg.matmul"(%897, %896, %898) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %900 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %901 = "arith.addf"(%arg400, %900) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%901) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_100
Type: OpType.ReshapeType
Arguments: ['mm_17', [1, 1, 8960]]
Parents: ['mm_17']
Children: ['sigmoid_4', 'mul_50']
--------------------MLIR OPS--------------------
%900 = "tosa.reshape"(%899) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_4
Type: OpType.ElementwiseType
Arguments: ['view_100']
Parents: ['view_100']
Children: ['mul_50']
--------------------MLIR OPS--------------------
%901 = "tosa.sigmoid"(%900) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_50
Type: OpType.BroadcastType
Arguments: ['view_100', 'sigmoid_4']
Parents: ['view_100', 'sigmoid_4']
Children: ['mul_51']
--------------------MLIR OPS--------------------
%902 = "tosa.mul"(%900, %901) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_54
Type: OpType.ReshapeType
Arguments: ['arg118_1', [1, 0]]
Parents: ['arg118_1']
Children: ['mm_18']
--------------------MLIR OPS--------------------
%903 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%904 = "tosa.transpose"(%arg72, %903) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_101
Type: OpType.ReshapeType
Arguments: ['mul_49', [1, 1536]]
Parents: ['mul_49']
Children: ['mm_18']
--------------------MLIR OPS--------------------
%905 = "tosa.reshape"(%894) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_18
Type: OpType.ReduceType
Arguments: ['view_101', 'permute_54']
Parents: ['view_101', 'permute_54']
Children: ['view_102']
--------------------MLIR OPS--------------------
%906 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%907 = "linalg.matmul"(%905, %904, %906) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %908 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %909 = "arith.addf"(%arg400, %908) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%909) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_102
Type: OpType.ReshapeType
Arguments: ['mm_18', [1, 1, 8960]]
Parents: ['mm_18']
Children: ['mul_51']
--------------------MLIR OPS--------------------
%908 = "tosa.reshape"(%907) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_51
Type: OpType.BroadcastType
Arguments: ['mul_50', 'view_102']
Parents: ['mul_50', 'view_102']
Children: ['view_103']
--------------------MLIR OPS--------------------
%909 = "tosa.mul"(%902, %908) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_55
Type: OpType.ReshapeType
Arguments: ['arg119_1', [1, 0]]
Parents: ['arg119_1']
Children: ['mm_19']
--------------------MLIR OPS--------------------
%910 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%911 = "tosa.transpose"(%arg73, %910) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_103
Type: OpType.ReshapeType
Arguments: ['mul_51', [1, 8960]]
Parents: ['mul_51']
Children: ['mm_19']
--------------------MLIR OPS--------------------
%912 = "tosa.reshape"(%909) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_19
Type: OpType.ReduceType
Arguments: ['view_103', 'permute_55']
Parents: ['view_103', 'permute_55']
Children: ['view_104']
--------------------MLIR OPS--------------------
%913 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%914 = "linalg.matmul"(%912, %911, %913) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %915 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %916 = "arith.addf"(%arg400, %915) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%916) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_104
Type: OpType.ReshapeType
Arguments: ['mm_19', [1, 1, 1536]]
Parents: ['mm_19']
Children: ['add_30']
--------------------MLIR OPS--------------------
%915 = "tosa.reshape"(%914) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_30
Type: OpType.BroadcastType
Arguments: ['add_28', 'view_104']
Parents: ['add_28', 'view_104']
Children: ['pow_11', 'mul_52', 'add_34']
--------------------MLIR OPS--------------------
%916 = "tosa.add"(%880, %915) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_11
Type: OpType.BroadcastType
Arguments: ['add_30', 2]
Parents: ['add_30']
Children: ['mean_10']
--------------------MLIR OPS--------------------
%917 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%918 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%919 = "linalg.generic"(%916, %917) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %920 = "math.fpowi"(%arg398, %918) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%920) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_10
Type: OpType.ReduceType
Arguments: ['pow_11', [-1], True]
Parents: ['pow_11']
Children: ['add_31']
--------------------MLIR OPS--------------------
%920 = "tosa.reduce_sum"(%919) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%921 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%922 = "tosa.reciprocal"(%921) : (tensor<1xf32>) -> tensor<1xf32>
%923 = "tosa.reshape"(%922) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%924 = "tosa.mul"(%923, %920) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_31
Type: OpType.BroadcastType
Arguments: ['mean_10', 1e-06]
Parents: ['mean_10']
Children: ['rsqrt_10']
--------------------MLIR OPS--------------------
%925 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%926 = "tosa.add"(%924, %925) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_10
Type: OpType.ElementwiseType
Arguments: ['add_31']
Parents: ['add_31']
Children: ['mul_52']
--------------------MLIR OPS--------------------
%927 = "tosa.rsqrt"(%926) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_52
Type: OpType.BroadcastType
Arguments: ['add_30', 'rsqrt_10']
Parents: ['add_30', 'rsqrt_10']
Children: ['mul_53']
--------------------MLIR OPS--------------------
%928 = "tosa.mul"(%916, %927) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_53
Type: OpType.BroadcastType
Arguments: ['arg120_1', 'mul_52']
Parents: ['arg120_1', 'mul_52']
Children: ['view_105', 'view_108', 'view_111']
--------------------MLIR OPS--------------------
%929 = "tosa.reshape"(%arg74) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%930 = "tosa.mul"(%929, %928) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_105
Type: OpType.ReshapeType
Arguments: ['mul_53', [1, 1536]]
Parents: ['mul_53']
Children: ['addmm_15']
--------------------MLIR OPS--------------------
%931 = "tosa.reshape"(%930) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_56
Type: OpType.ReshapeType
Arguments: ['arg121_1', [1, 0]]
Parents: ['arg121_1']
Children: ['addmm_15']
--------------------MLIR OPS--------------------
%932 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%933 = "tosa.transpose"(%arg75, %932) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_15
Type: OpType.ReduceType
Arguments: ['arg122_1', 'view_105', 'permute_56']
Parents: ['arg122_1', 'view_105', 'permute_56']
Children: ['view_106']
--------------------MLIR OPS--------------------
%934 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%935 = "linalg.matmul"(%931, %933, %934) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %938 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %939 = "arith.addf"(%arg400, %938) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%939) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%936 = "tosa.reshape"(%arg76) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%937 = "tosa.add"(%936, %935) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_106
Type: OpType.ReshapeType
Arguments: ['addmm_15', [1, 1, 1536]]
Parents: ['addmm_15']
Children: ['view_107']
--------------------MLIR OPS--------------------
%938 = "tosa.reshape"(%937) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_107
Type: OpType.ReshapeType
Arguments: ['view_106', [1, 1, -1, 128]]
Parents: ['view_106']
Children: ['permute_57']
--------------------MLIR OPS--------------------
%939 = "tosa.reshape"(%938) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_57
Type: OpType.ReshapeType
Arguments: ['view_107', [0, 2, 1, 3]]
Parents: ['view_107']
Children: ['mul_54', 'slice_119', 'slice_120']
--------------------MLIR OPS--------------------
%940 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%941 = "tosa.transpose"(%939, %940) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_108
Type: OpType.ReshapeType
Arguments: ['mul_53', [1, 1536]]
Parents: ['mul_53']
Children: ['addmm_16']
--------------------MLIR OPS--------------------
%942 = "tosa.reshape"(%930) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_58
Type: OpType.ReshapeType
Arguments: ['arg123_1', [1, 0]]
Parents: ['arg123_1']
Children: ['addmm_16']
--------------------MLIR OPS--------------------
%943 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%944 = "tosa.transpose"(%arg77, %943) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_16
Type: OpType.ReduceType
Arguments: ['arg124_1', 'view_108', 'permute_58']
Parents: ['arg124_1', 'view_108', 'permute_58']
Children: ['view_109']
--------------------MLIR OPS--------------------
%945 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%946 = "linalg.matmul"(%942, %944, %945) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %949 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %950 = "arith.addf"(%arg400, %949) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%950) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%947 = "tosa.reshape"(%arg78) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%948 = "tosa.add"(%947, %946) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_109
Type: OpType.ReshapeType
Arguments: ['addmm_16', [1, 1, 256]]
Parents: ['addmm_16']
Children: ['view_110']
--------------------MLIR OPS--------------------
%949 = "tosa.reshape"(%948) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_110
Type: OpType.ReshapeType
Arguments: ['view_109', [1, 1, -1, 128]]
Parents: ['view_109']
Children: ['permute_59']
--------------------MLIR OPS--------------------
%950 = "tosa.reshape"(%949) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_59
Type: OpType.ReshapeType
Arguments: ['view_110', [0, 2, 1, 3]]
Parents: ['view_110']
Children: ['mul_56', 'slice_121', 'slice_122']
--------------------MLIR OPS--------------------
%951 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%952 = "tosa.transpose"(%950, %951) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_111
Type: OpType.ReshapeType
Arguments: ['mul_53', [1, 1536]]
Parents: ['mul_53']
Children: ['addmm_17']
--------------------MLIR OPS--------------------
%953 = "tosa.reshape"(%930) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_60
Type: OpType.ReshapeType
Arguments: ['arg125_1', [1, 0]]
Parents: ['arg125_1']
Children: ['addmm_17']
--------------------MLIR OPS--------------------
%954 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%955 = "tosa.transpose"(%arg79, %954) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_17
Type: OpType.ReduceType
Arguments: ['arg126_1', 'view_111', 'permute_60']
Parents: ['arg126_1', 'view_111', 'permute_60']
Children: ['view_112']
--------------------MLIR OPS--------------------
%956 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%957 = "linalg.matmul"(%953, %955, %956) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %960 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %961 = "arith.addf"(%arg400, %960) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%961) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%958 = "tosa.reshape"(%arg80) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%959 = "tosa.add"(%958, %957) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_112
Type: OpType.ReshapeType
Arguments: ['addmm_17', [1, 1, 256]]
Parents: ['addmm_17']
Children: ['view_113']
--------------------MLIR OPS--------------------
%960 = "tosa.reshape"(%959) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_113
Type: OpType.ReshapeType
Arguments: ['view_112', [1, 1, -1, 128]]
Parents: ['view_112']
Children: ['permute_61']
--------------------MLIR OPS--------------------
%961 = "tosa.reshape"(%960) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_61
Type: OpType.ReshapeType
Arguments: ['view_113', [0, 2, 1, 3]]
Parents: ['view_113']
Children: ['index_put_11']
--------------------MLIR OPS--------------------
%962 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%963 = "tosa.transpose"(%961, %962) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_35
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_54', 'mul_56']
--------------------MLIR OPS--------------------
%964 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_36
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_55', 'mul_57']
--------------------MLIR OPS--------------------
%965 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_54
Type: OpType.BroadcastType
Arguments: ['permute_57', 'unsqueeze_35']
Parents: ['permute_57', 'unsqueeze_35']
Children: ['add_32']
--------------------MLIR OPS--------------------
%966 = "tosa.mul"(%941, %964) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_119
Type: OpType.ReshapeType
Arguments: ['permute_57', 3, 0, 64]
Parents: ['permute_57']
Children: ['cat_10']
--------------------MLIR OPS--------------------
%967 = "tensor.extract_slice"(%941) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_120
Type: OpType.ReshapeType
Arguments: ['permute_57', 3, 64, 9223372036854775807]
Parents: ['permute_57']
Children: ['neg_10']
--------------------MLIR OPS--------------------
%968 = "tensor.extract_slice"(%941) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_10
Type: OpType.ElementwiseType
Arguments: ['slice_120']
Parents: ['slice_120']
Children: ['cat_10']
--------------------MLIR OPS--------------------
%969 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%970 = "linalg.negf"(%968, %969) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %971 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%971) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_10
Type: OpType.ConcatType
Arguments: [[neg_10, slice_119], -1]
Parents: []
Children: ['mul_55']
--------------------MLIR OPS--------------------
%971 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%972 = "tensor.insert_slice"(%970, %971) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%973 = "tensor.insert_slice"(%967, %972) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_55
Type: OpType.BroadcastType
Arguments: ['cat_10', 'unsqueeze_36']
Parents: ['cat_10', 'unsqueeze_36']
Children: ['add_32']
--------------------MLIR OPS--------------------
%974 = "tosa.mul"(%973, %965) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_32
Type: OpType.BroadcastType
Arguments: ['mul_54', 'mul_55']
Parents: ['mul_54', 'mul_55']
Children: ['_scaled_dot_product_flash_attention_for_cpu_5']
--------------------MLIR OPS--------------------
%975 = "tosa.add"(%966, %974) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_56
Type: OpType.BroadcastType
Arguments: ['permute_59', 'unsqueeze_35']
Parents: ['permute_59', 'unsqueeze_35']
Children: ['add_33']
--------------------MLIR OPS--------------------
%976 = "tosa.mul"(%952, %964) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_121
Type: OpType.ReshapeType
Arguments: ['permute_59', 3, 0, 64]
Parents: ['permute_59']
Children: ['cat_11']
--------------------MLIR OPS--------------------
%977 = "tensor.extract_slice"(%952) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_122
Type: OpType.ReshapeType
Arguments: ['permute_59', 3, 64, 9223372036854775807]
Parents: ['permute_59']
Children: ['neg_11']
--------------------MLIR OPS--------------------
%978 = "tensor.extract_slice"(%952) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_11
Type: OpType.ElementwiseType
Arguments: ['slice_122']
Parents: ['slice_122']
Children: ['cat_11']
--------------------MLIR OPS--------------------
%979 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%980 = "linalg.negf"(%978, %979) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %981 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%981) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_11
Type: OpType.ConcatType
Arguments: [[neg_11, slice_121], -1]
Parents: []
Children: ['mul_57']
--------------------MLIR OPS--------------------
%981 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%982 = "tensor.insert_slice"(%980, %981) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%983 = "tensor.insert_slice"(%977, %982) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_57
Type: OpType.BroadcastType
Arguments: ['cat_11', 'unsqueeze_36']
Parents: ['cat_11', 'unsqueeze_36']
Children: ['add_33']
--------------------MLIR OPS--------------------
%984 = "tosa.mul"(%983, %965) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_33
Type: OpType.BroadcastType
Arguments: ['mul_56', 'mul_57']
Parents: ['mul_56', 'mul_57']
Children: ['index_put_10']
--------------------MLIR OPS--------------------
%985 = "tosa.add"(%976, %984) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_10
Type: OpType.ElementwiseType
Arguments: ['arg10_1', [None, None, arg58_1], 'add_33']
Parents: ['arg10_1', 'add_33']
Children: ['slice_127', 'output']
--------------------MLIR OPS--------------------
%986 = "bufferization.to_memref"(%arg81) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%987 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%988 = "bufferization.to_memref"(%985) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%989 = "arith.constant"() <{value = 0 : index}> : () -> index
%990 = "arith.constant"() <{value = 1 : index}> : () -> index
%991 = "arith.constant"() <{value = 1 : index}> : () -> index
%992 = "arith.constant"() <{value = 2 : index}> : () -> index
%993 = "arith.constant"() <{value = 1 : index}> : () -> index
%994 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%989, %991, %990) ({
^bb0(%arg398: index):
  "scf.for"(%989, %992, %990) ({
  ^bb0(%arg399: index):
    "scf.for"(%989, %993, %990) ({
    ^bb0(%arg400: index):
      %996 = "memref.load"(%987, %arg400) : (memref<1xi64>, index) -> i64
      %997 = "arith.index_cast"(%996) : (i64) -> index
      "scf.for"(%989, %994, %990) ({
      ^bb0(%arg401: index):
        %998 = "memref.load"(%988, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%998, %986, %arg398, %arg399, %997, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%995 = "bufferization.to_tensor"(%986) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_11
Type: OpType.ElementwiseType
Arguments: ['arg11_1', [None, None, arg58_1], 'permute_61']
Parents: ['arg11_1', 'permute_61']
Children: ['slice_135', 'output']
--------------------MLIR OPS--------------------
%996 = "bufferization.to_memref"(%arg82) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%997 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%998 = "bufferization.to_memref"(%963) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%999 = "arith.constant"() <{value = 0 : index}> : () -> index
%1000 = "arith.constant"() <{value = 1 : index}> : () -> index
%1001 = "arith.constant"() <{value = 1 : index}> : () -> index
%1002 = "arith.constant"() <{value = 2 : index}> : () -> index
%1003 = "arith.constant"() <{value = 1 : index}> : () -> index
%1004 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%999, %1001, %1000) ({
^bb0(%arg398: index):
  "scf.for"(%999, %1002, %1000) ({
  ^bb0(%arg399: index):
    "scf.for"(%999, %1003, %1000) ({
    ^bb0(%arg400: index):
      %1006 = "memref.load"(%997, %arg400) : (memref<1xi64>, index) -> i64
      %1007 = "arith.index_cast"(%1006) : (i64) -> index
      "scf.for"(%999, %1004, %1000) ({
      ^bb0(%arg401: index):
        %1008 = "memref.load"(%998, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1008, %996, %arg398, %arg399, %1007, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1005 = "bufferization.to_tensor"(%996) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_127
Type: OpType.ReshapeType
Arguments: ['index_put_10', 0, 0, 9223372036854775807]
Parents: ['index_put_10']
Children: ['slice_128']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_128
Type: OpType.ReshapeType
Arguments: ['slice_127', 1, 0, 9223372036854775807]
Parents: ['slice_127']
Children: ['unsqueeze_38']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_38
Type: OpType.ReshapeType
Arguments: ['slice_128', 2]
Parents: ['slice_128']
Children: ['slice_129']
--------------------MLIR OPS--------------------
%1006 = "tosa.reshape"(%995) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_129
Type: OpType.ReshapeType
Arguments: ['unsqueeze_38', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_38']
Children: ['slice_130']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_130
Type: OpType.ReshapeType
Arguments: ['slice_129', 4, 0, 9223372036854775807]
Parents: ['slice_129']
Children: ['expand_27']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_27
Type: OpType.ReshapeType
Arguments: ['slice_130', [1, 2, 6, 1024, 128]]
Parents: ['slice_130']
Children: ['clone_12']
--------------------MLIR OPS--------------------
%1007 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1008 = "tosa.add"(%1006, %1007) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_12
Type: OpType.ReduceType
Arguments: ['expand_27']
Parents: ['expand_27']
Children: ['view_114']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_114
Type: OpType.ReshapeType
Arguments: ['clone_12', [1, 12, 1024, 128]]
Parents: ['clone_12']
Children: ['_scaled_dot_product_flash_attention_for_cpu_5']
--------------------MLIR OPS--------------------
%1009 = "tosa.reshape"(%1008) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_135
Type: OpType.ReshapeType
Arguments: ['index_put_11', 0, 0, 9223372036854775807]
Parents: ['index_put_11']
Children: ['slice_136']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_136
Type: OpType.ReshapeType
Arguments: ['slice_135', 1, 0, 9223372036854775807]
Parents: ['slice_135']
Children: ['unsqueeze_40']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_40
Type: OpType.ReshapeType
Arguments: ['slice_136', 2]
Parents: ['slice_136']
Children: ['slice_137']
--------------------MLIR OPS--------------------
%1010 = "tosa.reshape"(%1005) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_137
Type: OpType.ReshapeType
Arguments: ['unsqueeze_40', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_40']
Children: ['slice_138']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_138
Type: OpType.ReshapeType
Arguments: ['slice_137', 4, 0, 9223372036854775807]
Parents: ['slice_137']
Children: ['expand_29']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_29
Type: OpType.ReshapeType
Arguments: ['slice_138', [1, 2, 6, 1024, 128]]
Parents: ['slice_138']
Children: ['clone_13']
--------------------MLIR OPS--------------------
%1011 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1012 = "tosa.add"(%1010, %1011) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_13
Type: OpType.ReduceType
Arguments: ['expand_29']
Parents: ['expand_29']
Children: ['view_115']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_115
Type: OpType.ReshapeType
Arguments: ['clone_13', [1, 12, 1024, 128]]
Parents: ['clone_13']
Children: ['_scaled_dot_product_flash_attention_for_cpu_5']
--------------------MLIR OPS--------------------
%1013 = "tosa.reshape"(%1012) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_139
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_140']
--------------------MLIR OPS--------------------
%1014 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_140
Type: OpType.ReshapeType
Arguments: ['slice_139', 1, 0, 9223372036854775807]
Parents: ['slice_139']
Children: ['slice_141']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_141
Type: OpType.ReshapeType
Arguments: ['slice_140', 2, 0, 9223372036854775807]
Parents: ['slice_140']
Children: ['where_5']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_10
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_5']
--------------------MLIR OPS--------------------
%1015 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_11
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_5']
--------------------MLIR OPS--------------------
%1016 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_5
Type: OpType.ElementwiseType
Arguments: ['slice_141', 'scalar_tensor_11', 'scalar_tensor_10']
Parents: ['slice_141', 'scalar_tensor_11', 'scalar_tensor_10']
Children: ['_scaled_dot_product_flash_attention_for_cpu_5']
--------------------MLIR OPS--------------------
%1017 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%1018 = "tensor.splat"(%1016) : (f32) -> tensor<1x1x1x1024xf32>
%1019 = "tensor.splat"(%1015) : (f32) -> tensor<1x1x1x1024xf32>
%1020 = "linalg.generic"(%1014, %1018, %1019, %1017) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %1021 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%1021) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_5
Type: OpType.ElementwiseType
Arguments: ['add_32', 'view_114', 'view_115']
Parents: ['add_32', 'view_114', 'view_115']
Children: ['getitem_10']
--------------------MLIR OPS--------------------
%1021 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%1022 = "tensor.splat"(%1021) : (f32) -> tensor<1x1024xf32>
%1023 = "tosa.reshape"(%1020) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%1024 = "tosa.add"(%1022, %1023) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%1025 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1026 = "tosa.transpose"(%1009, %1025) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%1027 = "tosa.reshape"(%975) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%1028 = "tosa.reshape"(%1026) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%1029 = "tosa.matmul"(%1027, %1028) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%1030 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%1031 = "tensor.splat"(%1030) : (f32) -> tensor<12x1x1024xf32>
%1032 = "tosa.mul"(%1029, %1031) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1033 = "tosa.reshape"(%1024) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%1034 = "tosa.add"(%1032, %1033) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%1035 = "tosa.reduce_max"(%1034) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1036 = "tosa.sub"(%1034, %1035) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1037 = "math.exp"(%1036) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1038 = "tosa.reduce_sum"(%1037) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1039 = "tosa.log"(%1038) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1040 = "tosa.add"(%1035, %1039) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1041 = "tosa.sub"(%1034, %1040) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1042 = "math.exp"(%1041) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1043 = "tosa.reshape"(%1040) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%1044 = "tosa.reshape"(%1013) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%1045 = "tosa.matmul"(%1042, %1044) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%1046 = "tosa.reshape"(%1045) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_10
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_5', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_5']
Children: ['permute_62']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_62
Type: OpType.ReshapeType
Arguments: ['getitem_10', [0, 2, 1, 3]]
Parents: ['getitem_10']
Children: ['view_116']
--------------------MLIR OPS--------------------
%1047 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1048 = "tosa.transpose"(%1046, %1047) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_116
Type: OpType.ReshapeType
Arguments: ['permute_62', [1, 1, -1]]
Parents: ['permute_62']
Children: ['view_117']
--------------------MLIR OPS--------------------
%1049 = "tosa.reshape"(%1048) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_63
Type: OpType.ReshapeType
Arguments: ['arg127_1', [1, 0]]
Parents: ['arg127_1']
Children: ['mm_20']
--------------------MLIR OPS--------------------
%1050 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1051 = "tosa.transpose"(%arg83, %1050) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_117
Type: OpType.ReshapeType
Arguments: ['view_116', [1, 1536]]
Parents: ['view_116']
Children: ['mm_20']
--------------------MLIR OPS--------------------
%1052 = "tosa.reshape"(%1049) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_20
Type: OpType.ReduceType
Arguments: ['view_117', 'permute_63']
Parents: ['view_117', 'permute_63']
Children: ['view_118']
--------------------MLIR OPS--------------------
%1053 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1054 = "linalg.matmul"(%1052, %1051, %1053) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1055 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1056 = "arith.addf"(%arg400, %1055) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1056) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_118
Type: OpType.ReshapeType
Arguments: ['mm_20', [1, 1, 1536]]
Parents: ['mm_20']
Children: ['add_34']
--------------------MLIR OPS--------------------
%1055 = "tosa.reshape"(%1054) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_34
Type: OpType.BroadcastType
Arguments: ['add_30', 'view_118']
Parents: ['add_30', 'view_118']
Children: ['pow_12', 'mul_58', 'add_36']
--------------------MLIR OPS--------------------
%1056 = "tosa.add"(%916, %1055) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_12
Type: OpType.BroadcastType
Arguments: ['add_34', 2]
Parents: ['add_34']
Children: ['mean_11']
--------------------MLIR OPS--------------------
%1057 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1058 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1059 = "linalg.generic"(%1056, %1057) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1060 = "math.fpowi"(%arg398, %1058) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1060) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_11
Type: OpType.ReduceType
Arguments: ['pow_12', [-1], True]
Parents: ['pow_12']
Children: ['add_35']
--------------------MLIR OPS--------------------
%1060 = "tosa.reduce_sum"(%1059) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1061 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1062 = "tosa.reciprocal"(%1061) : (tensor<1xf32>) -> tensor<1xf32>
%1063 = "tosa.reshape"(%1062) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1064 = "tosa.mul"(%1063, %1060) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_35
Type: OpType.BroadcastType
Arguments: ['mean_11', 1e-06]
Parents: ['mean_11']
Children: ['rsqrt_11']
--------------------MLIR OPS--------------------
%1065 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1066 = "tosa.add"(%1064, %1065) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_11
Type: OpType.ElementwiseType
Arguments: ['add_35']
Parents: ['add_35']
Children: ['mul_58']
--------------------MLIR OPS--------------------
%1067 = "tosa.rsqrt"(%1066) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_58
Type: OpType.BroadcastType
Arguments: ['add_34', 'rsqrt_11']
Parents: ['add_34', 'rsqrt_11']
Children: ['mul_59']
--------------------MLIR OPS--------------------
%1068 = "tosa.mul"(%1056, %1067) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_59
Type: OpType.BroadcastType
Arguments: ['arg128_1', 'mul_58']
Parents: ['arg128_1', 'mul_58']
Children: ['view_119', 'view_121']
--------------------MLIR OPS--------------------
%1069 = "tosa.reshape"(%arg84) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1070 = "tosa.mul"(%1069, %1068) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_64
Type: OpType.ReshapeType
Arguments: ['arg129_1', [1, 0]]
Parents: ['arg129_1']
Children: ['mm_21']
--------------------MLIR OPS--------------------
%1071 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1072 = "tosa.transpose"(%arg85, %1071) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_119
Type: OpType.ReshapeType
Arguments: ['mul_59', [1, 1536]]
Parents: ['mul_59']
Children: ['mm_21']
--------------------MLIR OPS--------------------
%1073 = "tosa.reshape"(%1070) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_21
Type: OpType.ReduceType
Arguments: ['view_119', 'permute_64']
Parents: ['view_119', 'permute_64']
Children: ['view_120']
--------------------MLIR OPS--------------------
%1074 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1075 = "linalg.matmul"(%1073, %1072, %1074) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1076 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1077 = "arith.addf"(%arg400, %1076) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1077) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_120
Type: OpType.ReshapeType
Arguments: ['mm_21', [1, 1, 8960]]
Parents: ['mm_21']
Children: ['sigmoid_5', 'mul_60']
--------------------MLIR OPS--------------------
%1076 = "tosa.reshape"(%1075) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_5
Type: OpType.ElementwiseType
Arguments: ['view_120']
Parents: ['view_120']
Children: ['mul_60']
--------------------MLIR OPS--------------------
%1077 = "tosa.sigmoid"(%1076) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_60
Type: OpType.BroadcastType
Arguments: ['view_120', 'sigmoid_5']
Parents: ['view_120', 'sigmoid_5']
Children: ['mul_61']
--------------------MLIR OPS--------------------
%1078 = "tosa.mul"(%1076, %1077) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_65
Type: OpType.ReshapeType
Arguments: ['arg130_1', [1, 0]]
Parents: ['arg130_1']
Children: ['mm_22']
--------------------MLIR OPS--------------------
%1079 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1080 = "tosa.transpose"(%arg86, %1079) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_121
Type: OpType.ReshapeType
Arguments: ['mul_59', [1, 1536]]
Parents: ['mul_59']
Children: ['mm_22']
--------------------MLIR OPS--------------------
%1081 = "tosa.reshape"(%1070) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_22
Type: OpType.ReduceType
Arguments: ['view_121', 'permute_65']
Parents: ['view_121', 'permute_65']
Children: ['view_122']
--------------------MLIR OPS--------------------
%1082 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1083 = "linalg.matmul"(%1081, %1080, %1082) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1084 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1085 = "arith.addf"(%arg400, %1084) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1085) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_122
Type: OpType.ReshapeType
Arguments: ['mm_22', [1, 1, 8960]]
Parents: ['mm_22']
Children: ['mul_61']
--------------------MLIR OPS--------------------
%1084 = "tosa.reshape"(%1083) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_61
Type: OpType.BroadcastType
Arguments: ['mul_60', 'view_122']
Parents: ['mul_60', 'view_122']
Children: ['view_123']
--------------------MLIR OPS--------------------
%1085 = "tosa.mul"(%1078, %1084) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_66
Type: OpType.ReshapeType
Arguments: ['arg131_1', [1, 0]]
Parents: ['arg131_1']
Children: ['mm_23']
--------------------MLIR OPS--------------------
%1086 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1087 = "tosa.transpose"(%arg87, %1086) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_123
Type: OpType.ReshapeType
Arguments: ['mul_61', [1, 8960]]
Parents: ['mul_61']
Children: ['mm_23']
--------------------MLIR OPS--------------------
%1088 = "tosa.reshape"(%1085) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_23
Type: OpType.ReduceType
Arguments: ['view_123', 'permute_66']
Parents: ['view_123', 'permute_66']
Children: ['view_124']
--------------------MLIR OPS--------------------
%1089 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1090 = "linalg.matmul"(%1088, %1087, %1089) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1091 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1092 = "arith.addf"(%arg400, %1091) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1092) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_124
Type: OpType.ReshapeType
Arguments: ['mm_23', [1, 1, 1536]]
Parents: ['mm_23']
Children: ['add_36']
--------------------MLIR OPS--------------------
%1091 = "tosa.reshape"(%1090) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_36
Type: OpType.BroadcastType
Arguments: ['add_34', 'view_124']
Parents: ['add_34', 'view_124']
Children: ['pow_13', 'mul_62', 'add_40']
--------------------MLIR OPS--------------------
%1092 = "tosa.add"(%1056, %1091) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_13
Type: OpType.BroadcastType
Arguments: ['add_36', 2]
Parents: ['add_36']
Children: ['mean_12']
--------------------MLIR OPS--------------------
%1093 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1094 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1095 = "linalg.generic"(%1092, %1093) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1096 = "math.fpowi"(%arg398, %1094) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1096) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_12
Type: OpType.ReduceType
Arguments: ['pow_13', [-1], True]
Parents: ['pow_13']
Children: ['add_37']
--------------------MLIR OPS--------------------
%1096 = "tosa.reduce_sum"(%1095) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1097 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1098 = "tosa.reciprocal"(%1097) : (tensor<1xf32>) -> tensor<1xf32>
%1099 = "tosa.reshape"(%1098) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1100 = "tosa.mul"(%1099, %1096) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_37
Type: OpType.BroadcastType
Arguments: ['mean_12', 1e-06]
Parents: ['mean_12']
Children: ['rsqrt_12']
--------------------MLIR OPS--------------------
%1101 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1102 = "tosa.add"(%1100, %1101) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_12
Type: OpType.ElementwiseType
Arguments: ['add_37']
Parents: ['add_37']
Children: ['mul_62']
--------------------MLIR OPS--------------------
%1103 = "tosa.rsqrt"(%1102) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_62
Type: OpType.BroadcastType
Arguments: ['add_36', 'rsqrt_12']
Parents: ['add_36', 'rsqrt_12']
Children: ['mul_63']
--------------------MLIR OPS--------------------
%1104 = "tosa.mul"(%1092, %1103) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_63
Type: OpType.BroadcastType
Arguments: ['arg132_1', 'mul_62']
Parents: ['arg132_1', 'mul_62']
Children: ['view_125', 'view_128', 'view_131']
--------------------MLIR OPS--------------------
%1105 = "tosa.reshape"(%arg88) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1106 = "tosa.mul"(%1105, %1104) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_125
Type: OpType.ReshapeType
Arguments: ['mul_63', [1, 1536]]
Parents: ['mul_63']
Children: ['addmm_18']
--------------------MLIR OPS--------------------
%1107 = "tosa.reshape"(%1106) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_67
Type: OpType.ReshapeType
Arguments: ['arg133_1', [1, 0]]
Parents: ['arg133_1']
Children: ['addmm_18']
--------------------MLIR OPS--------------------
%1108 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1109 = "tosa.transpose"(%arg89, %1108) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_18
Type: OpType.ReduceType
Arguments: ['arg134_1', 'view_125', 'permute_67']
Parents: ['arg134_1', 'view_125', 'permute_67']
Children: ['view_126']
--------------------MLIR OPS--------------------
%1110 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1111 = "linalg.matmul"(%1107, %1109, %1110) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1114 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1115 = "arith.addf"(%arg400, %1114) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1115) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%1112 = "tosa.reshape"(%arg90) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%1113 = "tosa.add"(%1112, %1111) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_126
Type: OpType.ReshapeType
Arguments: ['addmm_18', [1, 1, 1536]]
Parents: ['addmm_18']
Children: ['view_127']
--------------------MLIR OPS--------------------
%1114 = "tosa.reshape"(%1113) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_127
Type: OpType.ReshapeType
Arguments: ['view_126', [1, 1, -1, 128]]
Parents: ['view_126']
Children: ['permute_68']
--------------------MLIR OPS--------------------
%1115 = "tosa.reshape"(%1114) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_68
Type: OpType.ReshapeType
Arguments: ['view_127', [0, 2, 1, 3]]
Parents: ['view_127']
Children: ['mul_64', 'slice_142', 'slice_143']
--------------------MLIR OPS--------------------
%1116 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1117 = "tosa.transpose"(%1115, %1116) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_128
Type: OpType.ReshapeType
Arguments: ['mul_63', [1, 1536]]
Parents: ['mul_63']
Children: ['addmm_19']
--------------------MLIR OPS--------------------
%1118 = "tosa.reshape"(%1106) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_69
Type: OpType.ReshapeType
Arguments: ['arg135_1', [1, 0]]
Parents: ['arg135_1']
Children: ['addmm_19']
--------------------MLIR OPS--------------------
%1119 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1120 = "tosa.transpose"(%arg91, %1119) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_19
Type: OpType.ReduceType
Arguments: ['arg136_1', 'view_128', 'permute_69']
Parents: ['arg136_1', 'view_128', 'permute_69']
Children: ['view_129']
--------------------MLIR OPS--------------------
%1121 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%1122 = "linalg.matmul"(%1118, %1120, %1121) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1125 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1126 = "arith.addf"(%arg400, %1125) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1126) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%1123 = "tosa.reshape"(%arg92) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%1124 = "tosa.add"(%1123, %1122) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_129
Type: OpType.ReshapeType
Arguments: ['addmm_19', [1, 1, 256]]
Parents: ['addmm_19']
Children: ['view_130']
--------------------MLIR OPS--------------------
%1125 = "tosa.reshape"(%1124) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_130
Type: OpType.ReshapeType
Arguments: ['view_129', [1, 1, -1, 128]]
Parents: ['view_129']
Children: ['permute_70']
--------------------MLIR OPS--------------------
%1126 = "tosa.reshape"(%1125) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_70
Type: OpType.ReshapeType
Arguments: ['view_130', [0, 2, 1, 3]]
Parents: ['view_130']
Children: ['mul_66', 'slice_144', 'slice_145']
--------------------MLIR OPS--------------------
%1127 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1128 = "tosa.transpose"(%1126, %1127) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_131
Type: OpType.ReshapeType
Arguments: ['mul_63', [1, 1536]]
Parents: ['mul_63']
Children: ['addmm_20']
--------------------MLIR OPS--------------------
%1129 = "tosa.reshape"(%1106) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_71
Type: OpType.ReshapeType
Arguments: ['arg137_1', [1, 0]]
Parents: ['arg137_1']
Children: ['addmm_20']
--------------------MLIR OPS--------------------
%1130 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1131 = "tosa.transpose"(%arg93, %1130) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_20
Type: OpType.ReduceType
Arguments: ['arg138_1', 'view_131', 'permute_71']
Parents: ['arg138_1', 'view_131', 'permute_71']
Children: ['view_132']
--------------------MLIR OPS--------------------
%1132 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%1133 = "linalg.matmul"(%1129, %1131, %1132) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1136 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1137 = "arith.addf"(%arg400, %1136) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1137) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%1134 = "tosa.reshape"(%arg94) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%1135 = "tosa.add"(%1134, %1133) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_132
Type: OpType.ReshapeType
Arguments: ['addmm_20', [1, 1, 256]]
Parents: ['addmm_20']
Children: ['view_133']
--------------------MLIR OPS--------------------
%1136 = "tosa.reshape"(%1135) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_133
Type: OpType.ReshapeType
Arguments: ['view_132', [1, 1, -1, 128]]
Parents: ['view_132']
Children: ['permute_72']
--------------------MLIR OPS--------------------
%1137 = "tosa.reshape"(%1136) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_72
Type: OpType.ReshapeType
Arguments: ['view_133', [0, 2, 1, 3]]
Parents: ['view_133']
Children: ['index_put_13']
--------------------MLIR OPS--------------------
%1138 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1139 = "tosa.transpose"(%1137, %1138) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_41
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_64', 'mul_66']
--------------------MLIR OPS--------------------
%1140 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_42
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_65', 'mul_67']
--------------------MLIR OPS--------------------
%1141 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_64
Type: OpType.BroadcastType
Arguments: ['permute_68', 'unsqueeze_41']
Parents: ['permute_68', 'unsqueeze_41']
Children: ['add_38']
--------------------MLIR OPS--------------------
%1142 = "tosa.mul"(%1117, %1140) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_142
Type: OpType.ReshapeType
Arguments: ['permute_68', 3, 0, 64]
Parents: ['permute_68']
Children: ['cat_12']
--------------------MLIR OPS--------------------
%1143 = "tensor.extract_slice"(%1117) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_143
Type: OpType.ReshapeType
Arguments: ['permute_68', 3, 64, 9223372036854775807]
Parents: ['permute_68']
Children: ['neg_12']
--------------------MLIR OPS--------------------
%1144 = "tensor.extract_slice"(%1117) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_12
Type: OpType.ElementwiseType
Arguments: ['slice_143']
Parents: ['slice_143']
Children: ['cat_12']
--------------------MLIR OPS--------------------
%1145 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%1146 = "linalg.negf"(%1144, %1145) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1147 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%1147) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_12
Type: OpType.ConcatType
Arguments: [[neg_12, slice_142], -1]
Parents: []
Children: ['mul_65']
--------------------MLIR OPS--------------------
%1147 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%1148 = "tensor.insert_slice"(%1146, %1147) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%1149 = "tensor.insert_slice"(%1143, %1148) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_65
Type: OpType.BroadcastType
Arguments: ['cat_12', 'unsqueeze_42']
Parents: ['cat_12', 'unsqueeze_42']
Children: ['add_38']
--------------------MLIR OPS--------------------
%1150 = "tosa.mul"(%1149, %1141) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_38
Type: OpType.BroadcastType
Arguments: ['mul_64', 'mul_65']
Parents: ['mul_64', 'mul_65']
Children: ['_scaled_dot_product_flash_attention_for_cpu_6']
--------------------MLIR OPS--------------------
%1151 = "tosa.add"(%1142, %1150) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_66
Type: OpType.BroadcastType
Arguments: ['permute_70', 'unsqueeze_41']
Parents: ['permute_70', 'unsqueeze_41']
Children: ['add_39']
--------------------MLIR OPS--------------------
%1152 = "tosa.mul"(%1128, %1140) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_144
Type: OpType.ReshapeType
Arguments: ['permute_70', 3, 0, 64]
Parents: ['permute_70']
Children: ['cat_13']
--------------------MLIR OPS--------------------
%1153 = "tensor.extract_slice"(%1128) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_145
Type: OpType.ReshapeType
Arguments: ['permute_70', 3, 64, 9223372036854775807]
Parents: ['permute_70']
Children: ['neg_13']
--------------------MLIR OPS--------------------
%1154 = "tensor.extract_slice"(%1128) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_13
Type: OpType.ElementwiseType
Arguments: ['slice_145']
Parents: ['slice_145']
Children: ['cat_13']
--------------------MLIR OPS--------------------
%1155 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%1156 = "linalg.negf"(%1154, %1155) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1157 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%1157) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_13
Type: OpType.ConcatType
Arguments: [[neg_13, slice_144], -1]
Parents: []
Children: ['mul_67']
--------------------MLIR OPS--------------------
%1157 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%1158 = "tensor.insert_slice"(%1156, %1157) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%1159 = "tensor.insert_slice"(%1153, %1158) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_67
Type: OpType.BroadcastType
Arguments: ['cat_13', 'unsqueeze_42']
Parents: ['cat_13', 'unsqueeze_42']
Children: ['add_39']
--------------------MLIR OPS--------------------
%1160 = "tosa.mul"(%1159, %1141) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_39
Type: OpType.BroadcastType
Arguments: ['mul_66', 'mul_67']
Parents: ['mul_66', 'mul_67']
Children: ['index_put_12']
--------------------MLIR OPS--------------------
%1161 = "tosa.add"(%1152, %1160) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_12
Type: OpType.ElementwiseType
Arguments: ['arg12_1', [None, None, arg58_1], 'add_39']
Parents: ['arg12_1', 'add_39']
Children: ['slice_150', 'output']
--------------------MLIR OPS--------------------
%1162 = "bufferization.to_memref"(%arg95) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%1163 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%1164 = "bufferization.to_memref"(%1161) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%1165 = "arith.constant"() <{value = 0 : index}> : () -> index
%1166 = "arith.constant"() <{value = 1 : index}> : () -> index
%1167 = "arith.constant"() <{value = 1 : index}> : () -> index
%1168 = "arith.constant"() <{value = 2 : index}> : () -> index
%1169 = "arith.constant"() <{value = 1 : index}> : () -> index
%1170 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%1165, %1167, %1166) ({
^bb0(%arg398: index):
  "scf.for"(%1165, %1168, %1166) ({
  ^bb0(%arg399: index):
    "scf.for"(%1165, %1169, %1166) ({
    ^bb0(%arg400: index):
      %1172 = "memref.load"(%1163, %arg400) : (memref<1xi64>, index) -> i64
      %1173 = "arith.index_cast"(%1172) : (i64) -> index
      "scf.for"(%1165, %1170, %1166) ({
      ^bb0(%arg401: index):
        %1174 = "memref.load"(%1164, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1174, %1162, %arg398, %arg399, %1173, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1171 = "bufferization.to_tensor"(%1162) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_13
Type: OpType.ElementwiseType
Arguments: ['arg13_1', [None, None, arg58_1], 'permute_72']
Parents: ['arg13_1', 'permute_72']
Children: ['slice_158', 'output']
--------------------MLIR OPS--------------------
%1172 = "bufferization.to_memref"(%arg96) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%1173 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%1174 = "bufferization.to_memref"(%1139) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%1175 = "arith.constant"() <{value = 0 : index}> : () -> index
%1176 = "arith.constant"() <{value = 1 : index}> : () -> index
%1177 = "arith.constant"() <{value = 1 : index}> : () -> index
%1178 = "arith.constant"() <{value = 2 : index}> : () -> index
%1179 = "arith.constant"() <{value = 1 : index}> : () -> index
%1180 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%1175, %1177, %1176) ({
^bb0(%arg398: index):
  "scf.for"(%1175, %1178, %1176) ({
  ^bb0(%arg399: index):
    "scf.for"(%1175, %1179, %1176) ({
    ^bb0(%arg400: index):
      %1182 = "memref.load"(%1173, %arg400) : (memref<1xi64>, index) -> i64
      %1183 = "arith.index_cast"(%1182) : (i64) -> index
      "scf.for"(%1175, %1180, %1176) ({
      ^bb0(%arg401: index):
        %1184 = "memref.load"(%1174, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1184, %1172, %arg398, %arg399, %1183, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1181 = "bufferization.to_tensor"(%1172) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_150
Type: OpType.ReshapeType
Arguments: ['index_put_12', 0, 0, 9223372036854775807]
Parents: ['index_put_12']
Children: ['slice_151']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_151
Type: OpType.ReshapeType
Arguments: ['slice_150', 1, 0, 9223372036854775807]
Parents: ['slice_150']
Children: ['unsqueeze_44']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_44
Type: OpType.ReshapeType
Arguments: ['slice_151', 2]
Parents: ['slice_151']
Children: ['slice_152']
--------------------MLIR OPS--------------------
%1182 = "tosa.reshape"(%1171) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_152
Type: OpType.ReshapeType
Arguments: ['unsqueeze_44', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_44']
Children: ['slice_153']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_153
Type: OpType.ReshapeType
Arguments: ['slice_152', 4, 0, 9223372036854775807]
Parents: ['slice_152']
Children: ['expand_31']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_31
Type: OpType.ReshapeType
Arguments: ['slice_153', [1, 2, 6, 1024, 128]]
Parents: ['slice_153']
Children: ['clone_14']
--------------------MLIR OPS--------------------
%1183 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1184 = "tosa.add"(%1182, %1183) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_14
Type: OpType.ReduceType
Arguments: ['expand_31']
Parents: ['expand_31']
Children: ['view_134']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_134
Type: OpType.ReshapeType
Arguments: ['clone_14', [1, 12, 1024, 128]]
Parents: ['clone_14']
Children: ['_scaled_dot_product_flash_attention_for_cpu_6']
--------------------MLIR OPS--------------------
%1185 = "tosa.reshape"(%1184) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_158
Type: OpType.ReshapeType
Arguments: ['index_put_13', 0, 0, 9223372036854775807]
Parents: ['index_put_13']
Children: ['slice_159']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_159
Type: OpType.ReshapeType
Arguments: ['slice_158', 1, 0, 9223372036854775807]
Parents: ['slice_158']
Children: ['unsqueeze_46']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_46
Type: OpType.ReshapeType
Arguments: ['slice_159', 2]
Parents: ['slice_159']
Children: ['slice_160']
--------------------MLIR OPS--------------------
%1186 = "tosa.reshape"(%1181) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_160
Type: OpType.ReshapeType
Arguments: ['unsqueeze_46', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_46']
Children: ['slice_161']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_161
Type: OpType.ReshapeType
Arguments: ['slice_160', 4, 0, 9223372036854775807]
Parents: ['slice_160']
Children: ['expand_33']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_33
Type: OpType.ReshapeType
Arguments: ['slice_161', [1, 2, 6, 1024, 128]]
Parents: ['slice_161']
Children: ['clone_15']
--------------------MLIR OPS--------------------
%1187 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1188 = "tosa.add"(%1186, %1187) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_15
Type: OpType.ReduceType
Arguments: ['expand_33']
Parents: ['expand_33']
Children: ['view_135']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_135
Type: OpType.ReshapeType
Arguments: ['clone_15', [1, 12, 1024, 128]]
Parents: ['clone_15']
Children: ['_scaled_dot_product_flash_attention_for_cpu_6']
--------------------MLIR OPS--------------------
%1189 = "tosa.reshape"(%1188) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_162
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_163']
--------------------MLIR OPS--------------------
%1190 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_163
Type: OpType.ReshapeType
Arguments: ['slice_162', 1, 0, 9223372036854775807]
Parents: ['slice_162']
Children: ['slice_164']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_164
Type: OpType.ReshapeType
Arguments: ['slice_163', 2, 0, 9223372036854775807]
Parents: ['slice_163']
Children: ['where_6']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_12
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_6']
--------------------MLIR OPS--------------------
%1191 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_13
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_6']
--------------------MLIR OPS--------------------
%1192 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_6
Type: OpType.ElementwiseType
Arguments: ['slice_164', 'scalar_tensor_13', 'scalar_tensor_12']
Parents: ['slice_164', 'scalar_tensor_13', 'scalar_tensor_12']
Children: ['_scaled_dot_product_flash_attention_for_cpu_6']
--------------------MLIR OPS--------------------
%1193 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%1194 = "tensor.splat"(%1192) : (f32) -> tensor<1x1x1x1024xf32>
%1195 = "tensor.splat"(%1191) : (f32) -> tensor<1x1x1x1024xf32>
%1196 = "linalg.generic"(%1190, %1194, %1195, %1193) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %1197 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%1197) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_6
Type: OpType.ElementwiseType
Arguments: ['add_38', 'view_134', 'view_135']
Parents: ['add_38', 'view_134', 'view_135']
Children: ['getitem_12']
--------------------MLIR OPS--------------------
%1197 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%1198 = "tensor.splat"(%1197) : (f32) -> tensor<1x1024xf32>
%1199 = "tosa.reshape"(%1196) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%1200 = "tosa.add"(%1198, %1199) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%1201 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1202 = "tosa.transpose"(%1185, %1201) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%1203 = "tosa.reshape"(%1151) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%1204 = "tosa.reshape"(%1202) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%1205 = "tosa.matmul"(%1203, %1204) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%1206 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%1207 = "tensor.splat"(%1206) : (f32) -> tensor<12x1x1024xf32>
%1208 = "tosa.mul"(%1205, %1207) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1209 = "tosa.reshape"(%1200) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%1210 = "tosa.add"(%1208, %1209) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%1211 = "tosa.reduce_max"(%1210) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1212 = "tosa.sub"(%1210, %1211) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1213 = "math.exp"(%1212) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1214 = "tosa.reduce_sum"(%1213) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1215 = "tosa.log"(%1214) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1216 = "tosa.add"(%1211, %1215) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1217 = "tosa.sub"(%1210, %1216) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1218 = "math.exp"(%1217) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1219 = "tosa.reshape"(%1216) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%1220 = "tosa.reshape"(%1189) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%1221 = "tosa.matmul"(%1218, %1220) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%1222 = "tosa.reshape"(%1221) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_12
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_6', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_6']
Children: ['permute_73']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_73
Type: OpType.ReshapeType
Arguments: ['getitem_12', [0, 2, 1, 3]]
Parents: ['getitem_12']
Children: ['view_136']
--------------------MLIR OPS--------------------
%1223 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1224 = "tosa.transpose"(%1222, %1223) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_136
Type: OpType.ReshapeType
Arguments: ['permute_73', [1, 1, -1]]
Parents: ['permute_73']
Children: ['view_137']
--------------------MLIR OPS--------------------
%1225 = "tosa.reshape"(%1224) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_74
Type: OpType.ReshapeType
Arguments: ['arg139_1', [1, 0]]
Parents: ['arg139_1']
Children: ['mm_24']
--------------------MLIR OPS--------------------
%1226 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1227 = "tosa.transpose"(%arg97, %1226) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_137
Type: OpType.ReshapeType
Arguments: ['view_136', [1, 1536]]
Parents: ['view_136']
Children: ['mm_24']
--------------------MLIR OPS--------------------
%1228 = "tosa.reshape"(%1225) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_24
Type: OpType.ReduceType
Arguments: ['view_137', 'permute_74']
Parents: ['view_137', 'permute_74']
Children: ['view_138']
--------------------MLIR OPS--------------------
%1229 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1230 = "linalg.matmul"(%1228, %1227, %1229) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1231 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1232 = "arith.addf"(%arg400, %1231) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1232) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_138
Type: OpType.ReshapeType
Arguments: ['mm_24', [1, 1, 1536]]
Parents: ['mm_24']
Children: ['add_40']
--------------------MLIR OPS--------------------
%1231 = "tosa.reshape"(%1230) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_40
Type: OpType.BroadcastType
Arguments: ['add_36', 'view_138']
Parents: ['add_36', 'view_138']
Children: ['pow_14', 'mul_68', 'add_42']
--------------------MLIR OPS--------------------
%1232 = "tosa.add"(%1092, %1231) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_14
Type: OpType.BroadcastType
Arguments: ['add_40', 2]
Parents: ['add_40']
Children: ['mean_13']
--------------------MLIR OPS--------------------
%1233 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1234 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1235 = "linalg.generic"(%1232, %1233) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1236 = "math.fpowi"(%arg398, %1234) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1236) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_13
Type: OpType.ReduceType
Arguments: ['pow_14', [-1], True]
Parents: ['pow_14']
Children: ['add_41']
--------------------MLIR OPS--------------------
%1236 = "tosa.reduce_sum"(%1235) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1237 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1238 = "tosa.reciprocal"(%1237) : (tensor<1xf32>) -> tensor<1xf32>
%1239 = "tosa.reshape"(%1238) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1240 = "tosa.mul"(%1239, %1236) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_41
Type: OpType.BroadcastType
Arguments: ['mean_13', 1e-06]
Parents: ['mean_13']
Children: ['rsqrt_13']
--------------------MLIR OPS--------------------
%1241 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1242 = "tosa.add"(%1240, %1241) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_13
Type: OpType.ElementwiseType
Arguments: ['add_41']
Parents: ['add_41']
Children: ['mul_68']
--------------------MLIR OPS--------------------
%1243 = "tosa.rsqrt"(%1242) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_68
Type: OpType.BroadcastType
Arguments: ['add_40', 'rsqrt_13']
Parents: ['add_40', 'rsqrt_13']
Children: ['mul_69']
--------------------MLIR OPS--------------------
%1244 = "tosa.mul"(%1232, %1243) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_69
Type: OpType.BroadcastType
Arguments: ['arg140_1', 'mul_68']
Parents: ['arg140_1', 'mul_68']
Children: ['view_139', 'view_141']
--------------------MLIR OPS--------------------
%1245 = "tosa.reshape"(%arg98) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1246 = "tosa.mul"(%1245, %1244) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_75
Type: OpType.ReshapeType
Arguments: ['arg141_1', [1, 0]]
Parents: ['arg141_1']
Children: ['mm_25']
--------------------MLIR OPS--------------------
%1247 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1248 = "tosa.transpose"(%arg99, %1247) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_139
Type: OpType.ReshapeType
Arguments: ['mul_69', [1, 1536]]
Parents: ['mul_69']
Children: ['mm_25']
--------------------MLIR OPS--------------------
%1249 = "tosa.reshape"(%1246) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_25
Type: OpType.ReduceType
Arguments: ['view_139', 'permute_75']
Parents: ['view_139', 'permute_75']
Children: ['view_140']
--------------------MLIR OPS--------------------
%1250 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1251 = "linalg.matmul"(%1249, %1248, %1250) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1252 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1253 = "arith.addf"(%arg400, %1252) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1253) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_140
Type: OpType.ReshapeType
Arguments: ['mm_25', [1, 1, 8960]]
Parents: ['mm_25']
Children: ['sigmoid_6', 'mul_70']
--------------------MLIR OPS--------------------
%1252 = "tosa.reshape"(%1251) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_6
Type: OpType.ElementwiseType
Arguments: ['view_140']
Parents: ['view_140']
Children: ['mul_70']
--------------------MLIR OPS--------------------
%1253 = "tosa.sigmoid"(%1252) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_70
Type: OpType.BroadcastType
Arguments: ['view_140', 'sigmoid_6']
Parents: ['view_140', 'sigmoid_6']
Children: ['mul_71']
--------------------MLIR OPS--------------------
%1254 = "tosa.mul"(%1252, %1253) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_76
Type: OpType.ReshapeType
Arguments: ['arg142_1', [1, 0]]
Parents: ['arg142_1']
Children: ['mm_26']
--------------------MLIR OPS--------------------
%1255 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1256 = "tosa.transpose"(%arg100, %1255) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_141
Type: OpType.ReshapeType
Arguments: ['mul_69', [1, 1536]]
Parents: ['mul_69']
Children: ['mm_26']
--------------------MLIR OPS--------------------
%1257 = "tosa.reshape"(%1246) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_26
Type: OpType.ReduceType
Arguments: ['view_141', 'permute_76']
Parents: ['view_141', 'permute_76']
Children: ['view_142']
--------------------MLIR OPS--------------------
%1258 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1259 = "linalg.matmul"(%1257, %1256, %1258) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1260 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1261 = "arith.addf"(%arg400, %1260) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1261) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_142
Type: OpType.ReshapeType
Arguments: ['mm_26', [1, 1, 8960]]
Parents: ['mm_26']
Children: ['mul_71']
--------------------MLIR OPS--------------------
%1260 = "tosa.reshape"(%1259) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_71
Type: OpType.BroadcastType
Arguments: ['mul_70', 'view_142']
Parents: ['mul_70', 'view_142']
Children: ['view_143']
--------------------MLIR OPS--------------------
%1261 = "tosa.mul"(%1254, %1260) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_77
Type: OpType.ReshapeType
Arguments: ['arg143_1', [1, 0]]
Parents: ['arg143_1']
Children: ['mm_27']
--------------------MLIR OPS--------------------
%1262 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1263 = "tosa.transpose"(%arg101, %1262) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_143
Type: OpType.ReshapeType
Arguments: ['mul_71', [1, 8960]]
Parents: ['mul_71']
Children: ['mm_27']
--------------------MLIR OPS--------------------
%1264 = "tosa.reshape"(%1261) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_27
Type: OpType.ReduceType
Arguments: ['view_143', 'permute_77']
Parents: ['view_143', 'permute_77']
Children: ['view_144']
--------------------MLIR OPS--------------------
%1265 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1266 = "linalg.matmul"(%1264, %1263, %1265) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1267 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1268 = "arith.addf"(%arg400, %1267) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1268) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_144
Type: OpType.ReshapeType
Arguments: ['mm_27', [1, 1, 1536]]
Parents: ['mm_27']
Children: ['add_42']
--------------------MLIR OPS--------------------
%1267 = "tosa.reshape"(%1266) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_42
Type: OpType.BroadcastType
Arguments: ['add_40', 'view_144']
Parents: ['add_40', 'view_144']
Children: ['pow_15', 'mul_72', 'add_46']
--------------------MLIR OPS--------------------
%1268 = "tosa.add"(%1232, %1267) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_15
Type: OpType.BroadcastType
Arguments: ['add_42', 2]
Parents: ['add_42']
Children: ['mean_14']
--------------------MLIR OPS--------------------
%1269 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1270 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1271 = "linalg.generic"(%1268, %1269) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1272 = "math.fpowi"(%arg398, %1270) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1272) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_14
Type: OpType.ReduceType
Arguments: ['pow_15', [-1], True]
Parents: ['pow_15']
Children: ['add_43']
--------------------MLIR OPS--------------------
%1272 = "tosa.reduce_sum"(%1271) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1273 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1274 = "tosa.reciprocal"(%1273) : (tensor<1xf32>) -> tensor<1xf32>
%1275 = "tosa.reshape"(%1274) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1276 = "tosa.mul"(%1275, %1272) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_43
Type: OpType.BroadcastType
Arguments: ['mean_14', 1e-06]
Parents: ['mean_14']
Children: ['rsqrt_14']
--------------------MLIR OPS--------------------
%1277 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1278 = "tosa.add"(%1276, %1277) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_14
Type: OpType.ElementwiseType
Arguments: ['add_43']
Parents: ['add_43']
Children: ['mul_72']
--------------------MLIR OPS--------------------
%1279 = "tosa.rsqrt"(%1278) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_72
Type: OpType.BroadcastType
Arguments: ['add_42', 'rsqrt_14']
Parents: ['add_42', 'rsqrt_14']
Children: ['mul_73']
--------------------MLIR OPS--------------------
%1280 = "tosa.mul"(%1268, %1279) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_73
Type: OpType.BroadcastType
Arguments: ['arg144_1', 'mul_72']
Parents: ['arg144_1', 'mul_72']
Children: ['view_145', 'view_148', 'view_151']
--------------------MLIR OPS--------------------
%1281 = "tosa.reshape"(%arg102) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1282 = "tosa.mul"(%1281, %1280) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_145
Type: OpType.ReshapeType
Arguments: ['mul_73', [1, 1536]]
Parents: ['mul_73']
Children: ['addmm_21']
--------------------MLIR OPS--------------------
%1283 = "tosa.reshape"(%1282) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_78
Type: OpType.ReshapeType
Arguments: ['arg145_1', [1, 0]]
Parents: ['arg145_1']
Children: ['addmm_21']
--------------------MLIR OPS--------------------
%1284 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1285 = "tosa.transpose"(%arg103, %1284) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_21
Type: OpType.ReduceType
Arguments: ['arg146_1', 'view_145', 'permute_78']
Parents: ['arg146_1', 'view_145', 'permute_78']
Children: ['view_146']
--------------------MLIR OPS--------------------
%1286 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1287 = "linalg.matmul"(%1283, %1285, %1286) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1290 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1291 = "arith.addf"(%arg400, %1290) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1291) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%1288 = "tosa.reshape"(%arg104) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%1289 = "tosa.add"(%1288, %1287) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_146
Type: OpType.ReshapeType
Arguments: ['addmm_21', [1, 1, 1536]]
Parents: ['addmm_21']
Children: ['view_147']
--------------------MLIR OPS--------------------
%1290 = "tosa.reshape"(%1289) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_147
Type: OpType.ReshapeType
Arguments: ['view_146', [1, 1, -1, 128]]
Parents: ['view_146']
Children: ['permute_79']
--------------------MLIR OPS--------------------
%1291 = "tosa.reshape"(%1290) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_79
Type: OpType.ReshapeType
Arguments: ['view_147', [0, 2, 1, 3]]
Parents: ['view_147']
Children: ['mul_74', 'slice_165', 'slice_166']
--------------------MLIR OPS--------------------
%1292 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1293 = "tosa.transpose"(%1291, %1292) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_148
Type: OpType.ReshapeType
Arguments: ['mul_73', [1, 1536]]
Parents: ['mul_73']
Children: ['addmm_22']
--------------------MLIR OPS--------------------
%1294 = "tosa.reshape"(%1282) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_80
Type: OpType.ReshapeType
Arguments: ['arg147_1', [1, 0]]
Parents: ['arg147_1']
Children: ['addmm_22']
--------------------MLIR OPS--------------------
%1295 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1296 = "tosa.transpose"(%arg105, %1295) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_22
Type: OpType.ReduceType
Arguments: ['arg148_1', 'view_148', 'permute_80']
Parents: ['arg148_1', 'view_148', 'permute_80']
Children: ['view_149']
--------------------MLIR OPS--------------------
%1297 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%1298 = "linalg.matmul"(%1294, %1296, %1297) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1301 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1302 = "arith.addf"(%arg400, %1301) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1302) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%1299 = "tosa.reshape"(%arg106) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%1300 = "tosa.add"(%1299, %1298) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_149
Type: OpType.ReshapeType
Arguments: ['addmm_22', [1, 1, 256]]
Parents: ['addmm_22']
Children: ['view_150']
--------------------MLIR OPS--------------------
%1301 = "tosa.reshape"(%1300) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_150
Type: OpType.ReshapeType
Arguments: ['view_149', [1, 1, -1, 128]]
Parents: ['view_149']
Children: ['permute_81']
--------------------MLIR OPS--------------------
%1302 = "tosa.reshape"(%1301) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_81
Type: OpType.ReshapeType
Arguments: ['view_150', [0, 2, 1, 3]]
Parents: ['view_150']
Children: ['mul_76', 'slice_167', 'slice_168']
--------------------MLIR OPS--------------------
%1303 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1304 = "tosa.transpose"(%1302, %1303) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_151
Type: OpType.ReshapeType
Arguments: ['mul_73', [1, 1536]]
Parents: ['mul_73']
Children: ['addmm_23']
--------------------MLIR OPS--------------------
%1305 = "tosa.reshape"(%1282) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_82
Type: OpType.ReshapeType
Arguments: ['arg149_1', [1, 0]]
Parents: ['arg149_1']
Children: ['addmm_23']
--------------------MLIR OPS--------------------
%1306 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1307 = "tosa.transpose"(%arg107, %1306) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_23
Type: OpType.ReduceType
Arguments: ['arg150_1', 'view_151', 'permute_82']
Parents: ['arg150_1', 'view_151', 'permute_82']
Children: ['view_152']
--------------------MLIR OPS--------------------
%1308 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%1309 = "linalg.matmul"(%1305, %1307, %1308) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1312 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1313 = "arith.addf"(%arg400, %1312) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1313) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%1310 = "tosa.reshape"(%arg108) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%1311 = "tosa.add"(%1310, %1309) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_152
Type: OpType.ReshapeType
Arguments: ['addmm_23', [1, 1, 256]]
Parents: ['addmm_23']
Children: ['view_153']
--------------------MLIR OPS--------------------
%1312 = "tosa.reshape"(%1311) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_153
Type: OpType.ReshapeType
Arguments: ['view_152', [1, 1, -1, 128]]
Parents: ['view_152']
Children: ['permute_83']
--------------------MLIR OPS--------------------
%1313 = "tosa.reshape"(%1312) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_83
Type: OpType.ReshapeType
Arguments: ['view_153', [0, 2, 1, 3]]
Parents: ['view_153']
Children: ['index_put_15']
--------------------MLIR OPS--------------------
%1314 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1315 = "tosa.transpose"(%1313, %1314) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_47
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_74', 'mul_76']
--------------------MLIR OPS--------------------
%1316 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_48
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_75', 'mul_77']
--------------------MLIR OPS--------------------
%1317 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_74
Type: OpType.BroadcastType
Arguments: ['permute_79', 'unsqueeze_47']
Parents: ['permute_79', 'unsqueeze_47']
Children: ['add_44']
--------------------MLIR OPS--------------------
%1318 = "tosa.mul"(%1293, %1316) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_165
Type: OpType.ReshapeType
Arguments: ['permute_79', 3, 0, 64]
Parents: ['permute_79']
Children: ['cat_14']
--------------------MLIR OPS--------------------
%1319 = "tensor.extract_slice"(%1293) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_166
Type: OpType.ReshapeType
Arguments: ['permute_79', 3, 64, 9223372036854775807]
Parents: ['permute_79']
Children: ['neg_14']
--------------------MLIR OPS--------------------
%1320 = "tensor.extract_slice"(%1293) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_14
Type: OpType.ElementwiseType
Arguments: ['slice_166']
Parents: ['slice_166']
Children: ['cat_14']
--------------------MLIR OPS--------------------
%1321 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%1322 = "linalg.negf"(%1320, %1321) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1323 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%1323) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_14
Type: OpType.ConcatType
Arguments: [[neg_14, slice_165], -1]
Parents: []
Children: ['mul_75']
--------------------MLIR OPS--------------------
%1323 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%1324 = "tensor.insert_slice"(%1322, %1323) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%1325 = "tensor.insert_slice"(%1319, %1324) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_75
Type: OpType.BroadcastType
Arguments: ['cat_14', 'unsqueeze_48']
Parents: ['cat_14', 'unsqueeze_48']
Children: ['add_44']
--------------------MLIR OPS--------------------
%1326 = "tosa.mul"(%1325, %1317) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_44
Type: OpType.BroadcastType
Arguments: ['mul_74', 'mul_75']
Parents: ['mul_74', 'mul_75']
Children: ['_scaled_dot_product_flash_attention_for_cpu_7']
--------------------MLIR OPS--------------------
%1327 = "tosa.add"(%1318, %1326) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_76
Type: OpType.BroadcastType
Arguments: ['permute_81', 'unsqueeze_47']
Parents: ['permute_81', 'unsqueeze_47']
Children: ['add_45']
--------------------MLIR OPS--------------------
%1328 = "tosa.mul"(%1304, %1316) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_167
Type: OpType.ReshapeType
Arguments: ['permute_81', 3, 0, 64]
Parents: ['permute_81']
Children: ['cat_15']
--------------------MLIR OPS--------------------
%1329 = "tensor.extract_slice"(%1304) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_168
Type: OpType.ReshapeType
Arguments: ['permute_81', 3, 64, 9223372036854775807]
Parents: ['permute_81']
Children: ['neg_15']
--------------------MLIR OPS--------------------
%1330 = "tensor.extract_slice"(%1304) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_15
Type: OpType.ElementwiseType
Arguments: ['slice_168']
Parents: ['slice_168']
Children: ['cat_15']
--------------------MLIR OPS--------------------
%1331 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%1332 = "linalg.negf"(%1330, %1331) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1333 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%1333) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_15
Type: OpType.ConcatType
Arguments: [[neg_15, slice_167], -1]
Parents: []
Children: ['mul_77']
--------------------MLIR OPS--------------------
%1333 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%1334 = "tensor.insert_slice"(%1332, %1333) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%1335 = "tensor.insert_slice"(%1329, %1334) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_77
Type: OpType.BroadcastType
Arguments: ['cat_15', 'unsqueeze_48']
Parents: ['cat_15', 'unsqueeze_48']
Children: ['add_45']
--------------------MLIR OPS--------------------
%1336 = "tosa.mul"(%1335, %1317) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_45
Type: OpType.BroadcastType
Arguments: ['mul_76', 'mul_77']
Parents: ['mul_76', 'mul_77']
Children: ['index_put_14']
--------------------MLIR OPS--------------------
%1337 = "tosa.add"(%1328, %1336) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_14
Type: OpType.ElementwiseType
Arguments: ['arg14_1', [None, None, arg58_1], 'add_45']
Parents: ['arg14_1', 'add_45']
Children: ['slice_173', 'output']
--------------------MLIR OPS--------------------
%1338 = "bufferization.to_memref"(%arg109) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%1339 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%1340 = "bufferization.to_memref"(%1337) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%1341 = "arith.constant"() <{value = 0 : index}> : () -> index
%1342 = "arith.constant"() <{value = 1 : index}> : () -> index
%1343 = "arith.constant"() <{value = 1 : index}> : () -> index
%1344 = "arith.constant"() <{value = 2 : index}> : () -> index
%1345 = "arith.constant"() <{value = 1 : index}> : () -> index
%1346 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%1341, %1343, %1342) ({
^bb0(%arg398: index):
  "scf.for"(%1341, %1344, %1342) ({
  ^bb0(%arg399: index):
    "scf.for"(%1341, %1345, %1342) ({
    ^bb0(%arg400: index):
      %1348 = "memref.load"(%1339, %arg400) : (memref<1xi64>, index) -> i64
      %1349 = "arith.index_cast"(%1348) : (i64) -> index
      "scf.for"(%1341, %1346, %1342) ({
      ^bb0(%arg401: index):
        %1350 = "memref.load"(%1340, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1350, %1338, %arg398, %arg399, %1349, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1347 = "bufferization.to_tensor"(%1338) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_15
Type: OpType.ElementwiseType
Arguments: ['arg15_1', [None, None, arg58_1], 'permute_83']
Parents: ['arg15_1', 'permute_83']
Children: ['slice_181', 'output']
--------------------MLIR OPS--------------------
%1348 = "bufferization.to_memref"(%arg110) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%1349 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%1350 = "bufferization.to_memref"(%1315) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%1351 = "arith.constant"() <{value = 0 : index}> : () -> index
%1352 = "arith.constant"() <{value = 1 : index}> : () -> index
%1353 = "arith.constant"() <{value = 1 : index}> : () -> index
%1354 = "arith.constant"() <{value = 2 : index}> : () -> index
%1355 = "arith.constant"() <{value = 1 : index}> : () -> index
%1356 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%1351, %1353, %1352) ({
^bb0(%arg398: index):
  "scf.for"(%1351, %1354, %1352) ({
  ^bb0(%arg399: index):
    "scf.for"(%1351, %1355, %1352) ({
    ^bb0(%arg400: index):
      %1358 = "memref.load"(%1349, %arg400) : (memref<1xi64>, index) -> i64
      %1359 = "arith.index_cast"(%1358) : (i64) -> index
      "scf.for"(%1351, %1356, %1352) ({
      ^bb0(%arg401: index):
        %1360 = "memref.load"(%1350, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1360, %1348, %arg398, %arg399, %1359, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1357 = "bufferization.to_tensor"(%1348) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_173
Type: OpType.ReshapeType
Arguments: ['index_put_14', 0, 0, 9223372036854775807]
Parents: ['index_put_14']
Children: ['slice_174']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_174
Type: OpType.ReshapeType
Arguments: ['slice_173', 1, 0, 9223372036854775807]
Parents: ['slice_173']
Children: ['unsqueeze_50']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_50
Type: OpType.ReshapeType
Arguments: ['slice_174', 2]
Parents: ['slice_174']
Children: ['slice_175']
--------------------MLIR OPS--------------------
%1358 = "tosa.reshape"(%1347) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_175
Type: OpType.ReshapeType
Arguments: ['unsqueeze_50', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_50']
Children: ['slice_176']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_176
Type: OpType.ReshapeType
Arguments: ['slice_175', 4, 0, 9223372036854775807]
Parents: ['slice_175']
Children: ['expand_35']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_35
Type: OpType.ReshapeType
Arguments: ['slice_176', [1, 2, 6, 1024, 128]]
Parents: ['slice_176']
Children: ['clone_16']
--------------------MLIR OPS--------------------
%1359 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1360 = "tosa.add"(%1358, %1359) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_16
Type: OpType.ReduceType
Arguments: ['expand_35']
Parents: ['expand_35']
Children: ['view_154']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_154
Type: OpType.ReshapeType
Arguments: ['clone_16', [1, 12, 1024, 128]]
Parents: ['clone_16']
Children: ['_scaled_dot_product_flash_attention_for_cpu_7']
--------------------MLIR OPS--------------------
%1361 = "tosa.reshape"(%1360) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_181
Type: OpType.ReshapeType
Arguments: ['index_put_15', 0, 0, 9223372036854775807]
Parents: ['index_put_15']
Children: ['slice_182']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_182
Type: OpType.ReshapeType
Arguments: ['slice_181', 1, 0, 9223372036854775807]
Parents: ['slice_181']
Children: ['unsqueeze_52']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_52
Type: OpType.ReshapeType
Arguments: ['slice_182', 2]
Parents: ['slice_182']
Children: ['slice_183']
--------------------MLIR OPS--------------------
%1362 = "tosa.reshape"(%1357) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_183
Type: OpType.ReshapeType
Arguments: ['unsqueeze_52', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_52']
Children: ['slice_184']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_184
Type: OpType.ReshapeType
Arguments: ['slice_183', 4, 0, 9223372036854775807]
Parents: ['slice_183']
Children: ['expand_37']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_37
Type: OpType.ReshapeType
Arguments: ['slice_184', [1, 2, 6, 1024, 128]]
Parents: ['slice_184']
Children: ['clone_17']
--------------------MLIR OPS--------------------
%1363 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1364 = "tosa.add"(%1362, %1363) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_17
Type: OpType.ReduceType
Arguments: ['expand_37']
Parents: ['expand_37']
Children: ['view_155']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_155
Type: OpType.ReshapeType
Arguments: ['clone_17', [1, 12, 1024, 128]]
Parents: ['clone_17']
Children: ['_scaled_dot_product_flash_attention_for_cpu_7']
--------------------MLIR OPS--------------------
%1365 = "tosa.reshape"(%1364) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_185
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_186']
--------------------MLIR OPS--------------------
%1366 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_186
Type: OpType.ReshapeType
Arguments: ['slice_185', 1, 0, 9223372036854775807]
Parents: ['slice_185']
Children: ['slice_187']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_187
Type: OpType.ReshapeType
Arguments: ['slice_186', 2, 0, 9223372036854775807]
Parents: ['slice_186']
Children: ['where_7']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_14
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_7']
--------------------MLIR OPS--------------------
%1367 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_15
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_7']
--------------------MLIR OPS--------------------
%1368 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_7
Type: OpType.ElementwiseType
Arguments: ['slice_187', 'scalar_tensor_15', 'scalar_tensor_14']
Parents: ['slice_187', 'scalar_tensor_15', 'scalar_tensor_14']
Children: ['_scaled_dot_product_flash_attention_for_cpu_7']
--------------------MLIR OPS--------------------
%1369 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%1370 = "tensor.splat"(%1368) : (f32) -> tensor<1x1x1x1024xf32>
%1371 = "tensor.splat"(%1367) : (f32) -> tensor<1x1x1x1024xf32>
%1372 = "linalg.generic"(%1366, %1370, %1371, %1369) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %1373 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%1373) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_7
Type: OpType.ElementwiseType
Arguments: ['add_44', 'view_154', 'view_155']
Parents: ['add_44', 'view_154', 'view_155']
Children: ['getitem_14']
--------------------MLIR OPS--------------------
%1373 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%1374 = "tensor.splat"(%1373) : (f32) -> tensor<1x1024xf32>
%1375 = "tosa.reshape"(%1372) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%1376 = "tosa.add"(%1374, %1375) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%1377 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1378 = "tosa.transpose"(%1361, %1377) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%1379 = "tosa.reshape"(%1327) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%1380 = "tosa.reshape"(%1378) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%1381 = "tosa.matmul"(%1379, %1380) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%1382 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%1383 = "tensor.splat"(%1382) : (f32) -> tensor<12x1x1024xf32>
%1384 = "tosa.mul"(%1381, %1383) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1385 = "tosa.reshape"(%1376) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%1386 = "tosa.add"(%1384, %1385) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%1387 = "tosa.reduce_max"(%1386) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1388 = "tosa.sub"(%1386, %1387) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1389 = "math.exp"(%1388) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1390 = "tosa.reduce_sum"(%1389) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1391 = "tosa.log"(%1390) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1392 = "tosa.add"(%1387, %1391) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1393 = "tosa.sub"(%1386, %1392) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1394 = "math.exp"(%1393) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1395 = "tosa.reshape"(%1392) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%1396 = "tosa.reshape"(%1365) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%1397 = "tosa.matmul"(%1394, %1396) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%1398 = "tosa.reshape"(%1397) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_14
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_7', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_7']
Children: ['permute_84']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_84
Type: OpType.ReshapeType
Arguments: ['getitem_14', [0, 2, 1, 3]]
Parents: ['getitem_14']
Children: ['view_156']
--------------------MLIR OPS--------------------
%1399 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1400 = "tosa.transpose"(%1398, %1399) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_156
Type: OpType.ReshapeType
Arguments: ['permute_84', [1, 1, -1]]
Parents: ['permute_84']
Children: ['view_157']
--------------------MLIR OPS--------------------
%1401 = "tosa.reshape"(%1400) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_85
Type: OpType.ReshapeType
Arguments: ['arg151_1', [1, 0]]
Parents: ['arg151_1']
Children: ['mm_28']
--------------------MLIR OPS--------------------
%1402 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1403 = "tosa.transpose"(%arg111, %1402) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_157
Type: OpType.ReshapeType
Arguments: ['view_156', [1, 1536]]
Parents: ['view_156']
Children: ['mm_28']
--------------------MLIR OPS--------------------
%1404 = "tosa.reshape"(%1401) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_28
Type: OpType.ReduceType
Arguments: ['view_157', 'permute_85']
Parents: ['view_157', 'permute_85']
Children: ['view_158']
--------------------MLIR OPS--------------------
%1405 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1406 = "linalg.matmul"(%1404, %1403, %1405) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1407 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1408 = "arith.addf"(%arg400, %1407) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1408) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_158
Type: OpType.ReshapeType
Arguments: ['mm_28', [1, 1, 1536]]
Parents: ['mm_28']
Children: ['add_46']
--------------------MLIR OPS--------------------
%1407 = "tosa.reshape"(%1406) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_46
Type: OpType.BroadcastType
Arguments: ['add_42', 'view_158']
Parents: ['add_42', 'view_158']
Children: ['pow_16', 'mul_78', 'add_48']
--------------------MLIR OPS--------------------
%1408 = "tosa.add"(%1268, %1407) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_16
Type: OpType.BroadcastType
Arguments: ['add_46', 2]
Parents: ['add_46']
Children: ['mean_15']
--------------------MLIR OPS--------------------
%1409 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1410 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1411 = "linalg.generic"(%1408, %1409) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1412 = "math.fpowi"(%arg398, %1410) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1412) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_15
Type: OpType.ReduceType
Arguments: ['pow_16', [-1], True]
Parents: ['pow_16']
Children: ['add_47']
--------------------MLIR OPS--------------------
%1412 = "tosa.reduce_sum"(%1411) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1413 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1414 = "tosa.reciprocal"(%1413) : (tensor<1xf32>) -> tensor<1xf32>
%1415 = "tosa.reshape"(%1414) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1416 = "tosa.mul"(%1415, %1412) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_47
Type: OpType.BroadcastType
Arguments: ['mean_15', 1e-06]
Parents: ['mean_15']
Children: ['rsqrt_15']
--------------------MLIR OPS--------------------
%1417 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1418 = "tosa.add"(%1416, %1417) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_15
Type: OpType.ElementwiseType
Arguments: ['add_47']
Parents: ['add_47']
Children: ['mul_78']
--------------------MLIR OPS--------------------
%1419 = "tosa.rsqrt"(%1418) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_78
Type: OpType.BroadcastType
Arguments: ['add_46', 'rsqrt_15']
Parents: ['add_46', 'rsqrt_15']
Children: ['mul_79']
--------------------MLIR OPS--------------------
%1420 = "tosa.mul"(%1408, %1419) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_79
Type: OpType.BroadcastType
Arguments: ['arg152_1', 'mul_78']
Parents: ['arg152_1', 'mul_78']
Children: ['view_159', 'view_161']
--------------------MLIR OPS--------------------
%1421 = "tosa.reshape"(%arg112) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1422 = "tosa.mul"(%1421, %1420) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_86
Type: OpType.ReshapeType
Arguments: ['arg153_1', [1, 0]]
Parents: ['arg153_1']
Children: ['mm_29']
--------------------MLIR OPS--------------------
%1423 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1424 = "tosa.transpose"(%arg113, %1423) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_159
Type: OpType.ReshapeType
Arguments: ['mul_79', [1, 1536]]
Parents: ['mul_79']
Children: ['mm_29']
--------------------MLIR OPS--------------------
%1425 = "tosa.reshape"(%1422) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_29
Type: OpType.ReduceType
Arguments: ['view_159', 'permute_86']
Parents: ['view_159', 'permute_86']
Children: ['view_160']
--------------------MLIR OPS--------------------
%1426 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1427 = "linalg.matmul"(%1425, %1424, %1426) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1428 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1429 = "arith.addf"(%arg400, %1428) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1429) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_160
Type: OpType.ReshapeType
Arguments: ['mm_29', [1, 1, 8960]]
Parents: ['mm_29']
Children: ['sigmoid_7', 'mul_80']
--------------------MLIR OPS--------------------
%1428 = "tosa.reshape"(%1427) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_7
Type: OpType.ElementwiseType
Arguments: ['view_160']
Parents: ['view_160']
Children: ['mul_80']
--------------------MLIR OPS--------------------
%1429 = "tosa.sigmoid"(%1428) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_80
Type: OpType.BroadcastType
Arguments: ['view_160', 'sigmoid_7']
Parents: ['view_160', 'sigmoid_7']
Children: ['mul_81']
--------------------MLIR OPS--------------------
%1430 = "tosa.mul"(%1428, %1429) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_87
Type: OpType.ReshapeType
Arguments: ['arg154_1', [1, 0]]
Parents: ['arg154_1']
Children: ['mm_30']
--------------------MLIR OPS--------------------
%1431 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1432 = "tosa.transpose"(%arg114, %1431) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_161
Type: OpType.ReshapeType
Arguments: ['mul_79', [1, 1536]]
Parents: ['mul_79']
Children: ['mm_30']
--------------------MLIR OPS--------------------
%1433 = "tosa.reshape"(%1422) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_30
Type: OpType.ReduceType
Arguments: ['view_161', 'permute_87']
Parents: ['view_161', 'permute_87']
Children: ['view_162']
--------------------MLIR OPS--------------------
%1434 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1435 = "linalg.matmul"(%1433, %1432, %1434) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1436 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1437 = "arith.addf"(%arg400, %1436) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1437) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_162
Type: OpType.ReshapeType
Arguments: ['mm_30', [1, 1, 8960]]
Parents: ['mm_30']
Children: ['mul_81']
--------------------MLIR OPS--------------------
%1436 = "tosa.reshape"(%1435) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_81
Type: OpType.BroadcastType
Arguments: ['mul_80', 'view_162']
Parents: ['mul_80', 'view_162']
Children: ['view_163']
--------------------MLIR OPS--------------------
%1437 = "tosa.mul"(%1430, %1436) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_88
Type: OpType.ReshapeType
Arguments: ['arg155_1', [1, 0]]
Parents: ['arg155_1']
Children: ['mm_31']
--------------------MLIR OPS--------------------
%1438 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1439 = "tosa.transpose"(%arg115, %1438) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_163
Type: OpType.ReshapeType
Arguments: ['mul_81', [1, 8960]]
Parents: ['mul_81']
Children: ['mm_31']
--------------------MLIR OPS--------------------
%1440 = "tosa.reshape"(%1437) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_31
Type: OpType.ReduceType
Arguments: ['view_163', 'permute_88']
Parents: ['view_163', 'permute_88']
Children: ['view_164']
--------------------MLIR OPS--------------------
%1441 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1442 = "linalg.matmul"(%1440, %1439, %1441) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1443 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1444 = "arith.addf"(%arg400, %1443) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1444) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_164
Type: OpType.ReshapeType
Arguments: ['mm_31', [1, 1, 1536]]
Parents: ['mm_31']
Children: ['add_48']
--------------------MLIR OPS--------------------
%1443 = "tosa.reshape"(%1442) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_48
Type: OpType.BroadcastType
Arguments: ['add_46', 'view_164']
Parents: ['add_46', 'view_164']
Children: ['pow_17', 'mul_82', 'add_52']
--------------------MLIR OPS--------------------
%1444 = "tosa.add"(%1408, %1443) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_17
Type: OpType.BroadcastType
Arguments: ['add_48', 2]
Parents: ['add_48']
Children: ['mean_16']
--------------------MLIR OPS--------------------
%1445 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1446 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1447 = "linalg.generic"(%1444, %1445) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1448 = "math.fpowi"(%arg398, %1446) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1448) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_16
Type: OpType.ReduceType
Arguments: ['pow_17', [-1], True]
Parents: ['pow_17']
Children: ['add_49']
--------------------MLIR OPS--------------------
%1448 = "tosa.reduce_sum"(%1447) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1449 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1450 = "tosa.reciprocal"(%1449) : (tensor<1xf32>) -> tensor<1xf32>
%1451 = "tosa.reshape"(%1450) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1452 = "tosa.mul"(%1451, %1448) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_49
Type: OpType.BroadcastType
Arguments: ['mean_16', 1e-06]
Parents: ['mean_16']
Children: ['rsqrt_16']
--------------------MLIR OPS--------------------
%1453 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1454 = "tosa.add"(%1452, %1453) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_16
Type: OpType.ElementwiseType
Arguments: ['add_49']
Parents: ['add_49']
Children: ['mul_82']
--------------------MLIR OPS--------------------
%1455 = "tosa.rsqrt"(%1454) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_82
Type: OpType.BroadcastType
Arguments: ['add_48', 'rsqrt_16']
Parents: ['add_48', 'rsqrt_16']
Children: ['mul_83']
--------------------MLIR OPS--------------------
%1456 = "tosa.mul"(%1444, %1455) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_83
Type: OpType.BroadcastType
Arguments: ['arg156_1', 'mul_82']
Parents: ['arg156_1', 'mul_82']
Children: ['view_165', 'view_168', 'view_171']
--------------------MLIR OPS--------------------
%1457 = "tosa.reshape"(%arg116) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1458 = "tosa.mul"(%1457, %1456) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_165
Type: OpType.ReshapeType
Arguments: ['mul_83', [1, 1536]]
Parents: ['mul_83']
Children: ['addmm_24']
--------------------MLIR OPS--------------------
%1459 = "tosa.reshape"(%1458) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_89
Type: OpType.ReshapeType
Arguments: ['arg157_1', [1, 0]]
Parents: ['arg157_1']
Children: ['addmm_24']
--------------------MLIR OPS--------------------
%1460 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1461 = "tosa.transpose"(%arg117, %1460) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_24
Type: OpType.ReduceType
Arguments: ['arg158_1', 'view_165', 'permute_89']
Parents: ['arg158_1', 'view_165', 'permute_89']
Children: ['view_166']
--------------------MLIR OPS--------------------
%1462 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1463 = "linalg.matmul"(%1459, %1461, %1462) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1466 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1467 = "arith.addf"(%arg400, %1466) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1467) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%1464 = "tosa.reshape"(%arg118) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%1465 = "tosa.add"(%1464, %1463) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_166
Type: OpType.ReshapeType
Arguments: ['addmm_24', [1, 1, 1536]]
Parents: ['addmm_24']
Children: ['view_167']
--------------------MLIR OPS--------------------
%1466 = "tosa.reshape"(%1465) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_167
Type: OpType.ReshapeType
Arguments: ['view_166', [1, 1, -1, 128]]
Parents: ['view_166']
Children: ['permute_90']
--------------------MLIR OPS--------------------
%1467 = "tosa.reshape"(%1466) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_90
Type: OpType.ReshapeType
Arguments: ['view_167', [0, 2, 1, 3]]
Parents: ['view_167']
Children: ['mul_84', 'slice_188', 'slice_189']
--------------------MLIR OPS--------------------
%1468 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1469 = "tosa.transpose"(%1467, %1468) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_168
Type: OpType.ReshapeType
Arguments: ['mul_83', [1, 1536]]
Parents: ['mul_83']
Children: ['addmm_25']
--------------------MLIR OPS--------------------
%1470 = "tosa.reshape"(%1458) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_91
Type: OpType.ReshapeType
Arguments: ['arg159_1', [1, 0]]
Parents: ['arg159_1']
Children: ['addmm_25']
--------------------MLIR OPS--------------------
%1471 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1472 = "tosa.transpose"(%arg119, %1471) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_25
Type: OpType.ReduceType
Arguments: ['arg160_1', 'view_168', 'permute_91']
Parents: ['arg160_1', 'view_168', 'permute_91']
Children: ['view_169']
--------------------MLIR OPS--------------------
%1473 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%1474 = "linalg.matmul"(%1470, %1472, %1473) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1477 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1478 = "arith.addf"(%arg400, %1477) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1478) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%1475 = "tosa.reshape"(%arg120) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%1476 = "tosa.add"(%1475, %1474) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_169
Type: OpType.ReshapeType
Arguments: ['addmm_25', [1, 1, 256]]
Parents: ['addmm_25']
Children: ['view_170']
--------------------MLIR OPS--------------------
%1477 = "tosa.reshape"(%1476) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_170
Type: OpType.ReshapeType
Arguments: ['view_169', [1, 1, -1, 128]]
Parents: ['view_169']
Children: ['permute_92']
--------------------MLIR OPS--------------------
%1478 = "tosa.reshape"(%1477) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_92
Type: OpType.ReshapeType
Arguments: ['view_170', [0, 2, 1, 3]]
Parents: ['view_170']
Children: ['mul_86', 'slice_190', 'slice_191']
--------------------MLIR OPS--------------------
%1479 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1480 = "tosa.transpose"(%1478, %1479) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_171
Type: OpType.ReshapeType
Arguments: ['mul_83', [1, 1536]]
Parents: ['mul_83']
Children: ['addmm_26']
--------------------MLIR OPS--------------------
%1481 = "tosa.reshape"(%1458) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_93
Type: OpType.ReshapeType
Arguments: ['arg161_1', [1, 0]]
Parents: ['arg161_1']
Children: ['addmm_26']
--------------------MLIR OPS--------------------
%1482 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1483 = "tosa.transpose"(%arg121, %1482) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_26
Type: OpType.ReduceType
Arguments: ['arg162_1', 'view_171', 'permute_93']
Parents: ['arg162_1', 'view_171', 'permute_93']
Children: ['view_172']
--------------------MLIR OPS--------------------
%1484 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%1485 = "linalg.matmul"(%1481, %1483, %1484) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1488 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1489 = "arith.addf"(%arg400, %1488) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1489) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%1486 = "tosa.reshape"(%arg122) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%1487 = "tosa.add"(%1486, %1485) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_172
Type: OpType.ReshapeType
Arguments: ['addmm_26', [1, 1, 256]]
Parents: ['addmm_26']
Children: ['view_173']
--------------------MLIR OPS--------------------
%1488 = "tosa.reshape"(%1487) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_173
Type: OpType.ReshapeType
Arguments: ['view_172', [1, 1, -1, 128]]
Parents: ['view_172']
Children: ['permute_94']
--------------------MLIR OPS--------------------
%1489 = "tosa.reshape"(%1488) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_94
Type: OpType.ReshapeType
Arguments: ['view_173', [0, 2, 1, 3]]
Parents: ['view_173']
Children: ['index_put_17']
--------------------MLIR OPS--------------------
%1490 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1491 = "tosa.transpose"(%1489, %1490) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_53
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_84', 'mul_86']
--------------------MLIR OPS--------------------
%1492 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_54
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_85', 'mul_87']
--------------------MLIR OPS--------------------
%1493 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_84
Type: OpType.BroadcastType
Arguments: ['permute_90', 'unsqueeze_53']
Parents: ['permute_90', 'unsqueeze_53']
Children: ['add_50']
--------------------MLIR OPS--------------------
%1494 = "tosa.mul"(%1469, %1492) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_188
Type: OpType.ReshapeType
Arguments: ['permute_90', 3, 0, 64]
Parents: ['permute_90']
Children: ['cat_16']
--------------------MLIR OPS--------------------
%1495 = "tensor.extract_slice"(%1469) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_189
Type: OpType.ReshapeType
Arguments: ['permute_90', 3, 64, 9223372036854775807]
Parents: ['permute_90']
Children: ['neg_16']
--------------------MLIR OPS--------------------
%1496 = "tensor.extract_slice"(%1469) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_16
Type: OpType.ElementwiseType
Arguments: ['slice_189']
Parents: ['slice_189']
Children: ['cat_16']
--------------------MLIR OPS--------------------
%1497 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%1498 = "linalg.negf"(%1496, %1497) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1499 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%1499) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_16
Type: OpType.ConcatType
Arguments: [[neg_16, slice_188], -1]
Parents: []
Children: ['mul_85']
--------------------MLIR OPS--------------------
%1499 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%1500 = "tensor.insert_slice"(%1498, %1499) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%1501 = "tensor.insert_slice"(%1495, %1500) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_85
Type: OpType.BroadcastType
Arguments: ['cat_16', 'unsqueeze_54']
Parents: ['cat_16', 'unsqueeze_54']
Children: ['add_50']
--------------------MLIR OPS--------------------
%1502 = "tosa.mul"(%1501, %1493) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_50
Type: OpType.BroadcastType
Arguments: ['mul_84', 'mul_85']
Parents: ['mul_84', 'mul_85']
Children: ['_scaled_dot_product_flash_attention_for_cpu_8']
--------------------MLIR OPS--------------------
%1503 = "tosa.add"(%1494, %1502) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_86
Type: OpType.BroadcastType
Arguments: ['permute_92', 'unsqueeze_53']
Parents: ['permute_92', 'unsqueeze_53']
Children: ['add_51']
--------------------MLIR OPS--------------------
%1504 = "tosa.mul"(%1480, %1492) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_190
Type: OpType.ReshapeType
Arguments: ['permute_92', 3, 0, 64]
Parents: ['permute_92']
Children: ['cat_17']
--------------------MLIR OPS--------------------
%1505 = "tensor.extract_slice"(%1480) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_191
Type: OpType.ReshapeType
Arguments: ['permute_92', 3, 64, 9223372036854775807]
Parents: ['permute_92']
Children: ['neg_17']
--------------------MLIR OPS--------------------
%1506 = "tensor.extract_slice"(%1480) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_17
Type: OpType.ElementwiseType
Arguments: ['slice_191']
Parents: ['slice_191']
Children: ['cat_17']
--------------------MLIR OPS--------------------
%1507 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%1508 = "linalg.negf"(%1506, %1507) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1509 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%1509) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_17
Type: OpType.ConcatType
Arguments: [[neg_17, slice_190], -1]
Parents: []
Children: ['mul_87']
--------------------MLIR OPS--------------------
%1509 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%1510 = "tensor.insert_slice"(%1508, %1509) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%1511 = "tensor.insert_slice"(%1505, %1510) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_87
Type: OpType.BroadcastType
Arguments: ['cat_17', 'unsqueeze_54']
Parents: ['cat_17', 'unsqueeze_54']
Children: ['add_51']
--------------------MLIR OPS--------------------
%1512 = "tosa.mul"(%1511, %1493) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_51
Type: OpType.BroadcastType
Arguments: ['mul_86', 'mul_87']
Parents: ['mul_86', 'mul_87']
Children: ['index_put_16']
--------------------MLIR OPS--------------------
%1513 = "tosa.add"(%1504, %1512) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_16
Type: OpType.ElementwiseType
Arguments: ['arg16_1', [None, None, arg58_1], 'add_51']
Parents: ['arg16_1', 'add_51']
Children: ['slice_196', 'output']
--------------------MLIR OPS--------------------
%1514 = "bufferization.to_memref"(%arg123) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%1515 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%1516 = "bufferization.to_memref"(%1513) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%1517 = "arith.constant"() <{value = 0 : index}> : () -> index
%1518 = "arith.constant"() <{value = 1 : index}> : () -> index
%1519 = "arith.constant"() <{value = 1 : index}> : () -> index
%1520 = "arith.constant"() <{value = 2 : index}> : () -> index
%1521 = "arith.constant"() <{value = 1 : index}> : () -> index
%1522 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%1517, %1519, %1518) ({
^bb0(%arg398: index):
  "scf.for"(%1517, %1520, %1518) ({
  ^bb0(%arg399: index):
    "scf.for"(%1517, %1521, %1518) ({
    ^bb0(%arg400: index):
      %1524 = "memref.load"(%1515, %arg400) : (memref<1xi64>, index) -> i64
      %1525 = "arith.index_cast"(%1524) : (i64) -> index
      "scf.for"(%1517, %1522, %1518) ({
      ^bb0(%arg401: index):
        %1526 = "memref.load"(%1516, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1526, %1514, %arg398, %arg399, %1525, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1523 = "bufferization.to_tensor"(%1514) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_17
Type: OpType.ElementwiseType
Arguments: ['arg17_1', [None, None, arg58_1], 'permute_94']
Parents: ['arg17_1', 'permute_94']
Children: ['slice_204', 'output']
--------------------MLIR OPS--------------------
%1524 = "bufferization.to_memref"(%arg124) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%1525 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%1526 = "bufferization.to_memref"(%1491) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%1527 = "arith.constant"() <{value = 0 : index}> : () -> index
%1528 = "arith.constant"() <{value = 1 : index}> : () -> index
%1529 = "arith.constant"() <{value = 1 : index}> : () -> index
%1530 = "arith.constant"() <{value = 2 : index}> : () -> index
%1531 = "arith.constant"() <{value = 1 : index}> : () -> index
%1532 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%1527, %1529, %1528) ({
^bb0(%arg398: index):
  "scf.for"(%1527, %1530, %1528) ({
  ^bb0(%arg399: index):
    "scf.for"(%1527, %1531, %1528) ({
    ^bb0(%arg400: index):
      %1534 = "memref.load"(%1525, %arg400) : (memref<1xi64>, index) -> i64
      %1535 = "arith.index_cast"(%1534) : (i64) -> index
      "scf.for"(%1527, %1532, %1528) ({
      ^bb0(%arg401: index):
        %1536 = "memref.load"(%1526, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1536, %1524, %arg398, %arg399, %1535, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1533 = "bufferization.to_tensor"(%1524) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_196
Type: OpType.ReshapeType
Arguments: ['index_put_16', 0, 0, 9223372036854775807]
Parents: ['index_put_16']
Children: ['slice_197']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_197
Type: OpType.ReshapeType
Arguments: ['slice_196', 1, 0, 9223372036854775807]
Parents: ['slice_196']
Children: ['unsqueeze_56']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_56
Type: OpType.ReshapeType
Arguments: ['slice_197', 2]
Parents: ['slice_197']
Children: ['slice_198']
--------------------MLIR OPS--------------------
%1534 = "tosa.reshape"(%1523) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_198
Type: OpType.ReshapeType
Arguments: ['unsqueeze_56', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_56']
Children: ['slice_199']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_199
Type: OpType.ReshapeType
Arguments: ['slice_198', 4, 0, 9223372036854775807]
Parents: ['slice_198']
Children: ['expand_39']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_39
Type: OpType.ReshapeType
Arguments: ['slice_199', [1, 2, 6, 1024, 128]]
Parents: ['slice_199']
Children: ['clone_18']
--------------------MLIR OPS--------------------
%1535 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1536 = "tosa.add"(%1534, %1535) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_18
Type: OpType.ReduceType
Arguments: ['expand_39']
Parents: ['expand_39']
Children: ['view_174']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_174
Type: OpType.ReshapeType
Arguments: ['clone_18', [1, 12, 1024, 128]]
Parents: ['clone_18']
Children: ['_scaled_dot_product_flash_attention_for_cpu_8']
--------------------MLIR OPS--------------------
%1537 = "tosa.reshape"(%1536) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_204
Type: OpType.ReshapeType
Arguments: ['index_put_17', 0, 0, 9223372036854775807]
Parents: ['index_put_17']
Children: ['slice_205']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_205
Type: OpType.ReshapeType
Arguments: ['slice_204', 1, 0, 9223372036854775807]
Parents: ['slice_204']
Children: ['unsqueeze_58']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_58
Type: OpType.ReshapeType
Arguments: ['slice_205', 2]
Parents: ['slice_205']
Children: ['slice_206']
--------------------MLIR OPS--------------------
%1538 = "tosa.reshape"(%1533) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_206
Type: OpType.ReshapeType
Arguments: ['unsqueeze_58', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_58']
Children: ['slice_207']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_207
Type: OpType.ReshapeType
Arguments: ['slice_206', 4, 0, 9223372036854775807]
Parents: ['slice_206']
Children: ['expand_41']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_41
Type: OpType.ReshapeType
Arguments: ['slice_207', [1, 2, 6, 1024, 128]]
Parents: ['slice_207']
Children: ['clone_19']
--------------------MLIR OPS--------------------
%1539 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1540 = "tosa.add"(%1538, %1539) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_19
Type: OpType.ReduceType
Arguments: ['expand_41']
Parents: ['expand_41']
Children: ['view_175']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_175
Type: OpType.ReshapeType
Arguments: ['clone_19', [1, 12, 1024, 128]]
Parents: ['clone_19']
Children: ['_scaled_dot_product_flash_attention_for_cpu_8']
--------------------MLIR OPS--------------------
%1541 = "tosa.reshape"(%1540) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_208
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_209']
--------------------MLIR OPS--------------------
%1542 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_209
Type: OpType.ReshapeType
Arguments: ['slice_208', 1, 0, 9223372036854775807]
Parents: ['slice_208']
Children: ['slice_210']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_210
Type: OpType.ReshapeType
Arguments: ['slice_209', 2, 0, 9223372036854775807]
Parents: ['slice_209']
Children: ['where_8']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_16
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_8']
--------------------MLIR OPS--------------------
%1543 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_17
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_8']
--------------------MLIR OPS--------------------
%1544 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_8
Type: OpType.ElementwiseType
Arguments: ['slice_210', 'scalar_tensor_17', 'scalar_tensor_16']
Parents: ['slice_210', 'scalar_tensor_17', 'scalar_tensor_16']
Children: ['_scaled_dot_product_flash_attention_for_cpu_8']
--------------------MLIR OPS--------------------
%1545 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%1546 = "tensor.splat"(%1544) : (f32) -> tensor<1x1x1x1024xf32>
%1547 = "tensor.splat"(%1543) : (f32) -> tensor<1x1x1x1024xf32>
%1548 = "linalg.generic"(%1542, %1546, %1547, %1545) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %1549 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%1549) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_8
Type: OpType.ElementwiseType
Arguments: ['add_50', 'view_174', 'view_175']
Parents: ['add_50', 'view_174', 'view_175']
Children: ['getitem_16']
--------------------MLIR OPS--------------------
%1549 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%1550 = "tensor.splat"(%1549) : (f32) -> tensor<1x1024xf32>
%1551 = "tosa.reshape"(%1548) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%1552 = "tosa.add"(%1550, %1551) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%1553 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1554 = "tosa.transpose"(%1537, %1553) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%1555 = "tosa.reshape"(%1503) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%1556 = "tosa.reshape"(%1554) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%1557 = "tosa.matmul"(%1555, %1556) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%1558 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%1559 = "tensor.splat"(%1558) : (f32) -> tensor<12x1x1024xf32>
%1560 = "tosa.mul"(%1557, %1559) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1561 = "tosa.reshape"(%1552) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%1562 = "tosa.add"(%1560, %1561) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%1563 = "tosa.reduce_max"(%1562) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1564 = "tosa.sub"(%1562, %1563) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1565 = "math.exp"(%1564) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1566 = "tosa.reduce_sum"(%1565) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1567 = "tosa.log"(%1566) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1568 = "tosa.add"(%1563, %1567) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1569 = "tosa.sub"(%1562, %1568) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1570 = "math.exp"(%1569) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1571 = "tosa.reshape"(%1568) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%1572 = "tosa.reshape"(%1541) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%1573 = "tosa.matmul"(%1570, %1572) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%1574 = "tosa.reshape"(%1573) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_16
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_8', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_8']
Children: ['permute_95']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_95
Type: OpType.ReshapeType
Arguments: ['getitem_16', [0, 2, 1, 3]]
Parents: ['getitem_16']
Children: ['view_176']
--------------------MLIR OPS--------------------
%1575 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1576 = "tosa.transpose"(%1574, %1575) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_176
Type: OpType.ReshapeType
Arguments: ['permute_95', [1, 1, -1]]
Parents: ['permute_95']
Children: ['view_177']
--------------------MLIR OPS--------------------
%1577 = "tosa.reshape"(%1576) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_96
Type: OpType.ReshapeType
Arguments: ['arg163_1', [1, 0]]
Parents: ['arg163_1']
Children: ['mm_32']
--------------------MLIR OPS--------------------
%1578 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1579 = "tosa.transpose"(%arg125, %1578) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_177
Type: OpType.ReshapeType
Arguments: ['view_176', [1, 1536]]
Parents: ['view_176']
Children: ['mm_32']
--------------------MLIR OPS--------------------
%1580 = "tosa.reshape"(%1577) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_32
Type: OpType.ReduceType
Arguments: ['view_177', 'permute_96']
Parents: ['view_177', 'permute_96']
Children: ['view_178']
--------------------MLIR OPS--------------------
%1581 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1582 = "linalg.matmul"(%1580, %1579, %1581) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1583 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1584 = "arith.addf"(%arg400, %1583) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1584) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_178
Type: OpType.ReshapeType
Arguments: ['mm_32', [1, 1, 1536]]
Parents: ['mm_32']
Children: ['add_52']
--------------------MLIR OPS--------------------
%1583 = "tosa.reshape"(%1582) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_52
Type: OpType.BroadcastType
Arguments: ['add_48', 'view_178']
Parents: ['add_48', 'view_178']
Children: ['pow_18', 'mul_88', 'add_54']
--------------------MLIR OPS--------------------
%1584 = "tosa.add"(%1444, %1583) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_18
Type: OpType.BroadcastType
Arguments: ['add_52', 2]
Parents: ['add_52']
Children: ['mean_17']
--------------------MLIR OPS--------------------
%1585 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1586 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1587 = "linalg.generic"(%1584, %1585) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1588 = "math.fpowi"(%arg398, %1586) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1588) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_17
Type: OpType.ReduceType
Arguments: ['pow_18', [-1], True]
Parents: ['pow_18']
Children: ['add_53']
--------------------MLIR OPS--------------------
%1588 = "tosa.reduce_sum"(%1587) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1589 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1590 = "tosa.reciprocal"(%1589) : (tensor<1xf32>) -> tensor<1xf32>
%1591 = "tosa.reshape"(%1590) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1592 = "tosa.mul"(%1591, %1588) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_53
Type: OpType.BroadcastType
Arguments: ['mean_17', 1e-06]
Parents: ['mean_17']
Children: ['rsqrt_17']
--------------------MLIR OPS--------------------
%1593 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1594 = "tosa.add"(%1592, %1593) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_17
Type: OpType.ElementwiseType
Arguments: ['add_53']
Parents: ['add_53']
Children: ['mul_88']
--------------------MLIR OPS--------------------
%1595 = "tosa.rsqrt"(%1594) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_88
Type: OpType.BroadcastType
Arguments: ['add_52', 'rsqrt_17']
Parents: ['add_52', 'rsqrt_17']
Children: ['mul_89']
--------------------MLIR OPS--------------------
%1596 = "tosa.mul"(%1584, %1595) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_89
Type: OpType.BroadcastType
Arguments: ['arg164_1', 'mul_88']
Parents: ['arg164_1', 'mul_88']
Children: ['view_179', 'view_181']
--------------------MLIR OPS--------------------
%1597 = "tosa.reshape"(%arg126) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1598 = "tosa.mul"(%1597, %1596) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_97
Type: OpType.ReshapeType
Arguments: ['arg165_1', [1, 0]]
Parents: ['arg165_1']
Children: ['mm_33']
--------------------MLIR OPS--------------------
%1599 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1600 = "tosa.transpose"(%arg127, %1599) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_179
Type: OpType.ReshapeType
Arguments: ['mul_89', [1, 1536]]
Parents: ['mul_89']
Children: ['mm_33']
--------------------MLIR OPS--------------------
%1601 = "tosa.reshape"(%1598) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_33
Type: OpType.ReduceType
Arguments: ['view_179', 'permute_97']
Parents: ['view_179', 'permute_97']
Children: ['view_180']
--------------------MLIR OPS--------------------
%1602 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1603 = "linalg.matmul"(%1601, %1600, %1602) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1604 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1605 = "arith.addf"(%arg400, %1604) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1605) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_180
Type: OpType.ReshapeType
Arguments: ['mm_33', [1, 1, 8960]]
Parents: ['mm_33']
Children: ['sigmoid_8', 'mul_90']
--------------------MLIR OPS--------------------
%1604 = "tosa.reshape"(%1603) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_8
Type: OpType.ElementwiseType
Arguments: ['view_180']
Parents: ['view_180']
Children: ['mul_90']
--------------------MLIR OPS--------------------
%1605 = "tosa.sigmoid"(%1604) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_90
Type: OpType.BroadcastType
Arguments: ['view_180', 'sigmoid_8']
Parents: ['view_180', 'sigmoid_8']
Children: ['mul_91']
--------------------MLIR OPS--------------------
%1606 = "tosa.mul"(%1604, %1605) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_98
Type: OpType.ReshapeType
Arguments: ['arg166_1', [1, 0]]
Parents: ['arg166_1']
Children: ['mm_34']
--------------------MLIR OPS--------------------
%1607 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1608 = "tosa.transpose"(%arg128, %1607) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_181
Type: OpType.ReshapeType
Arguments: ['mul_89', [1, 1536]]
Parents: ['mul_89']
Children: ['mm_34']
--------------------MLIR OPS--------------------
%1609 = "tosa.reshape"(%1598) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_34
Type: OpType.ReduceType
Arguments: ['view_181', 'permute_98']
Parents: ['view_181', 'permute_98']
Children: ['view_182']
--------------------MLIR OPS--------------------
%1610 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1611 = "linalg.matmul"(%1609, %1608, %1610) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1612 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1613 = "arith.addf"(%arg400, %1612) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1613) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_182
Type: OpType.ReshapeType
Arguments: ['mm_34', [1, 1, 8960]]
Parents: ['mm_34']
Children: ['mul_91']
--------------------MLIR OPS--------------------
%1612 = "tosa.reshape"(%1611) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_91
Type: OpType.BroadcastType
Arguments: ['mul_90', 'view_182']
Parents: ['mul_90', 'view_182']
Children: ['view_183']
--------------------MLIR OPS--------------------
%1613 = "tosa.mul"(%1606, %1612) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_99
Type: OpType.ReshapeType
Arguments: ['arg167_1', [1, 0]]
Parents: ['arg167_1']
Children: ['mm_35']
--------------------MLIR OPS--------------------
%1614 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1615 = "tosa.transpose"(%arg129, %1614) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_183
Type: OpType.ReshapeType
Arguments: ['mul_91', [1, 8960]]
Parents: ['mul_91']
Children: ['mm_35']
--------------------MLIR OPS--------------------
%1616 = "tosa.reshape"(%1613) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_35
Type: OpType.ReduceType
Arguments: ['view_183', 'permute_99']
Parents: ['view_183', 'permute_99']
Children: ['view_184']
--------------------MLIR OPS--------------------
%1617 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1618 = "linalg.matmul"(%1616, %1615, %1617) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1619 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1620 = "arith.addf"(%arg400, %1619) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1620) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_184
Type: OpType.ReshapeType
Arguments: ['mm_35', [1, 1, 1536]]
Parents: ['mm_35']
Children: ['add_54']
--------------------MLIR OPS--------------------
%1619 = "tosa.reshape"(%1618) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_54
Type: OpType.BroadcastType
Arguments: ['add_52', 'view_184']
Parents: ['add_52', 'view_184']
Children: ['pow_19', 'mul_92', 'add_58']
--------------------MLIR OPS--------------------
%1620 = "tosa.add"(%1584, %1619) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_19
Type: OpType.BroadcastType
Arguments: ['add_54', 2]
Parents: ['add_54']
Children: ['mean_18']
--------------------MLIR OPS--------------------
%1621 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1622 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1623 = "linalg.generic"(%1620, %1621) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1624 = "math.fpowi"(%arg398, %1622) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1624) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_18
Type: OpType.ReduceType
Arguments: ['pow_19', [-1], True]
Parents: ['pow_19']
Children: ['add_55']
--------------------MLIR OPS--------------------
%1624 = "tosa.reduce_sum"(%1623) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1625 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1626 = "tosa.reciprocal"(%1625) : (tensor<1xf32>) -> tensor<1xf32>
%1627 = "tosa.reshape"(%1626) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1628 = "tosa.mul"(%1627, %1624) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_55
Type: OpType.BroadcastType
Arguments: ['mean_18', 1e-06]
Parents: ['mean_18']
Children: ['rsqrt_18']
--------------------MLIR OPS--------------------
%1629 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1630 = "tosa.add"(%1628, %1629) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_18
Type: OpType.ElementwiseType
Arguments: ['add_55']
Parents: ['add_55']
Children: ['mul_92']
--------------------MLIR OPS--------------------
%1631 = "tosa.rsqrt"(%1630) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_92
Type: OpType.BroadcastType
Arguments: ['add_54', 'rsqrt_18']
Parents: ['add_54', 'rsqrt_18']
Children: ['mul_93']
--------------------MLIR OPS--------------------
%1632 = "tosa.mul"(%1620, %1631) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_93
Type: OpType.BroadcastType
Arguments: ['arg168_1', 'mul_92']
Parents: ['arg168_1', 'mul_92']
Children: ['view_185', 'view_188', 'view_191']
--------------------MLIR OPS--------------------
%1633 = "tosa.reshape"(%arg130) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1634 = "tosa.mul"(%1633, %1632) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_185
Type: OpType.ReshapeType
Arguments: ['mul_93', [1, 1536]]
Parents: ['mul_93']
Children: ['addmm_27']
--------------------MLIR OPS--------------------
%1635 = "tosa.reshape"(%1634) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_100
Type: OpType.ReshapeType
Arguments: ['arg169_1', [1, 0]]
Parents: ['arg169_1']
Children: ['addmm_27']
--------------------MLIR OPS--------------------
%1636 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1637 = "tosa.transpose"(%arg131, %1636) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_27
Type: OpType.ReduceType
Arguments: ['arg170_1', 'view_185', 'permute_100']
Parents: ['arg170_1', 'view_185', 'permute_100']
Children: ['view_186']
--------------------MLIR OPS--------------------
%1638 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1639 = "linalg.matmul"(%1635, %1637, %1638) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1642 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1643 = "arith.addf"(%arg400, %1642) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1643) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%1640 = "tosa.reshape"(%arg132) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%1641 = "tosa.add"(%1640, %1639) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_186
Type: OpType.ReshapeType
Arguments: ['addmm_27', [1, 1, 1536]]
Parents: ['addmm_27']
Children: ['view_187']
--------------------MLIR OPS--------------------
%1642 = "tosa.reshape"(%1641) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_187
Type: OpType.ReshapeType
Arguments: ['view_186', [1, 1, -1, 128]]
Parents: ['view_186']
Children: ['permute_101']
--------------------MLIR OPS--------------------
%1643 = "tosa.reshape"(%1642) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_101
Type: OpType.ReshapeType
Arguments: ['view_187', [0, 2, 1, 3]]
Parents: ['view_187']
Children: ['mul_94', 'slice_211', 'slice_212']
--------------------MLIR OPS--------------------
%1644 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1645 = "tosa.transpose"(%1643, %1644) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_188
Type: OpType.ReshapeType
Arguments: ['mul_93', [1, 1536]]
Parents: ['mul_93']
Children: ['addmm_28']
--------------------MLIR OPS--------------------
%1646 = "tosa.reshape"(%1634) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_102
Type: OpType.ReshapeType
Arguments: ['arg171_1', [1, 0]]
Parents: ['arg171_1']
Children: ['addmm_28']
--------------------MLIR OPS--------------------
%1647 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1648 = "tosa.transpose"(%arg133, %1647) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_28
Type: OpType.ReduceType
Arguments: ['arg172_1', 'view_188', 'permute_102']
Parents: ['arg172_1', 'view_188', 'permute_102']
Children: ['view_189']
--------------------MLIR OPS--------------------
%1649 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%1650 = "linalg.matmul"(%1646, %1648, %1649) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1653 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1654 = "arith.addf"(%arg400, %1653) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1654) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%1651 = "tosa.reshape"(%arg134) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%1652 = "tosa.add"(%1651, %1650) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_189
Type: OpType.ReshapeType
Arguments: ['addmm_28', [1, 1, 256]]
Parents: ['addmm_28']
Children: ['view_190']
--------------------MLIR OPS--------------------
%1653 = "tosa.reshape"(%1652) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_190
Type: OpType.ReshapeType
Arguments: ['view_189', [1, 1, -1, 128]]
Parents: ['view_189']
Children: ['permute_103']
--------------------MLIR OPS--------------------
%1654 = "tosa.reshape"(%1653) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_103
Type: OpType.ReshapeType
Arguments: ['view_190', [0, 2, 1, 3]]
Parents: ['view_190']
Children: ['mul_96', 'slice_213', 'slice_214']
--------------------MLIR OPS--------------------
%1655 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1656 = "tosa.transpose"(%1654, %1655) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_191
Type: OpType.ReshapeType
Arguments: ['mul_93', [1, 1536]]
Parents: ['mul_93']
Children: ['addmm_29']
--------------------MLIR OPS--------------------
%1657 = "tosa.reshape"(%1634) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_104
Type: OpType.ReshapeType
Arguments: ['arg173_1', [1, 0]]
Parents: ['arg173_1']
Children: ['addmm_29']
--------------------MLIR OPS--------------------
%1658 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1659 = "tosa.transpose"(%arg135, %1658) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_29
Type: OpType.ReduceType
Arguments: ['arg174_1', 'view_191', 'permute_104']
Parents: ['arg174_1', 'view_191', 'permute_104']
Children: ['view_192']
--------------------MLIR OPS--------------------
%1660 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%1661 = "linalg.matmul"(%1657, %1659, %1660) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1664 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1665 = "arith.addf"(%arg400, %1664) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1665) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%1662 = "tosa.reshape"(%arg136) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%1663 = "tosa.add"(%1662, %1661) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_192
Type: OpType.ReshapeType
Arguments: ['addmm_29', [1, 1, 256]]
Parents: ['addmm_29']
Children: ['view_193']
--------------------MLIR OPS--------------------
%1664 = "tosa.reshape"(%1663) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_193
Type: OpType.ReshapeType
Arguments: ['view_192', [1, 1, -1, 128]]
Parents: ['view_192']
Children: ['permute_105']
--------------------MLIR OPS--------------------
%1665 = "tosa.reshape"(%1664) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_105
Type: OpType.ReshapeType
Arguments: ['view_193', [0, 2, 1, 3]]
Parents: ['view_193']
Children: ['index_put_19']
--------------------MLIR OPS--------------------
%1666 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1667 = "tosa.transpose"(%1665, %1666) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_59
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_94', 'mul_96']
--------------------MLIR OPS--------------------
%1668 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_60
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_95', 'mul_97']
--------------------MLIR OPS--------------------
%1669 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_94
Type: OpType.BroadcastType
Arguments: ['permute_101', 'unsqueeze_59']
Parents: ['permute_101', 'unsqueeze_59']
Children: ['add_56']
--------------------MLIR OPS--------------------
%1670 = "tosa.mul"(%1645, %1668) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_211
Type: OpType.ReshapeType
Arguments: ['permute_101', 3, 0, 64]
Parents: ['permute_101']
Children: ['cat_18']
--------------------MLIR OPS--------------------
%1671 = "tensor.extract_slice"(%1645) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_212
Type: OpType.ReshapeType
Arguments: ['permute_101', 3, 64, 9223372036854775807]
Parents: ['permute_101']
Children: ['neg_18']
--------------------MLIR OPS--------------------
%1672 = "tensor.extract_slice"(%1645) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_18
Type: OpType.ElementwiseType
Arguments: ['slice_212']
Parents: ['slice_212']
Children: ['cat_18']
--------------------MLIR OPS--------------------
%1673 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%1674 = "linalg.negf"(%1672, %1673) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1675 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%1675) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_18
Type: OpType.ConcatType
Arguments: [[neg_18, slice_211], -1]
Parents: []
Children: ['mul_95']
--------------------MLIR OPS--------------------
%1675 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%1676 = "tensor.insert_slice"(%1674, %1675) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%1677 = "tensor.insert_slice"(%1671, %1676) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_95
Type: OpType.BroadcastType
Arguments: ['cat_18', 'unsqueeze_60']
Parents: ['cat_18', 'unsqueeze_60']
Children: ['add_56']
--------------------MLIR OPS--------------------
%1678 = "tosa.mul"(%1677, %1669) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_56
Type: OpType.BroadcastType
Arguments: ['mul_94', 'mul_95']
Parents: ['mul_94', 'mul_95']
Children: ['_scaled_dot_product_flash_attention_for_cpu_9']
--------------------MLIR OPS--------------------
%1679 = "tosa.add"(%1670, %1678) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_96
Type: OpType.BroadcastType
Arguments: ['permute_103', 'unsqueeze_59']
Parents: ['permute_103', 'unsqueeze_59']
Children: ['add_57']
--------------------MLIR OPS--------------------
%1680 = "tosa.mul"(%1656, %1668) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_213
Type: OpType.ReshapeType
Arguments: ['permute_103', 3, 0, 64]
Parents: ['permute_103']
Children: ['cat_19']
--------------------MLIR OPS--------------------
%1681 = "tensor.extract_slice"(%1656) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_214
Type: OpType.ReshapeType
Arguments: ['permute_103', 3, 64, 9223372036854775807]
Parents: ['permute_103']
Children: ['neg_19']
--------------------MLIR OPS--------------------
%1682 = "tensor.extract_slice"(%1656) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_19
Type: OpType.ElementwiseType
Arguments: ['slice_214']
Parents: ['slice_214']
Children: ['cat_19']
--------------------MLIR OPS--------------------
%1683 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%1684 = "linalg.negf"(%1682, %1683) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1685 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%1685) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_19
Type: OpType.ConcatType
Arguments: [[neg_19, slice_213], -1]
Parents: []
Children: ['mul_97']
--------------------MLIR OPS--------------------
%1685 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%1686 = "tensor.insert_slice"(%1684, %1685) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%1687 = "tensor.insert_slice"(%1681, %1686) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_97
Type: OpType.BroadcastType
Arguments: ['cat_19', 'unsqueeze_60']
Parents: ['cat_19', 'unsqueeze_60']
Children: ['add_57']
--------------------MLIR OPS--------------------
%1688 = "tosa.mul"(%1687, %1669) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_57
Type: OpType.BroadcastType
Arguments: ['mul_96', 'mul_97']
Parents: ['mul_96', 'mul_97']
Children: ['index_put_18']
--------------------MLIR OPS--------------------
%1689 = "tosa.add"(%1680, %1688) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_18
Type: OpType.ElementwiseType
Arguments: ['arg18_1', [None, None, arg58_1], 'add_57']
Parents: ['arg18_1', 'add_57']
Children: ['slice_219', 'output']
--------------------MLIR OPS--------------------
%1690 = "bufferization.to_memref"(%arg137) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%1691 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%1692 = "bufferization.to_memref"(%1689) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%1693 = "arith.constant"() <{value = 0 : index}> : () -> index
%1694 = "arith.constant"() <{value = 1 : index}> : () -> index
%1695 = "arith.constant"() <{value = 1 : index}> : () -> index
%1696 = "arith.constant"() <{value = 2 : index}> : () -> index
%1697 = "arith.constant"() <{value = 1 : index}> : () -> index
%1698 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%1693, %1695, %1694) ({
^bb0(%arg398: index):
  "scf.for"(%1693, %1696, %1694) ({
  ^bb0(%arg399: index):
    "scf.for"(%1693, %1697, %1694) ({
    ^bb0(%arg400: index):
      %1700 = "memref.load"(%1691, %arg400) : (memref<1xi64>, index) -> i64
      %1701 = "arith.index_cast"(%1700) : (i64) -> index
      "scf.for"(%1693, %1698, %1694) ({
      ^bb0(%arg401: index):
        %1702 = "memref.load"(%1692, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1702, %1690, %arg398, %arg399, %1701, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1699 = "bufferization.to_tensor"(%1690) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_19
Type: OpType.ElementwiseType
Arguments: ['arg19_1', [None, None, arg58_1], 'permute_105']
Parents: ['arg19_1', 'permute_105']
Children: ['slice_227', 'output']
--------------------MLIR OPS--------------------
%1700 = "bufferization.to_memref"(%arg138) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%1701 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%1702 = "bufferization.to_memref"(%1667) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%1703 = "arith.constant"() <{value = 0 : index}> : () -> index
%1704 = "arith.constant"() <{value = 1 : index}> : () -> index
%1705 = "arith.constant"() <{value = 1 : index}> : () -> index
%1706 = "arith.constant"() <{value = 2 : index}> : () -> index
%1707 = "arith.constant"() <{value = 1 : index}> : () -> index
%1708 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%1703, %1705, %1704) ({
^bb0(%arg398: index):
  "scf.for"(%1703, %1706, %1704) ({
  ^bb0(%arg399: index):
    "scf.for"(%1703, %1707, %1704) ({
    ^bb0(%arg400: index):
      %1710 = "memref.load"(%1701, %arg400) : (memref<1xi64>, index) -> i64
      %1711 = "arith.index_cast"(%1710) : (i64) -> index
      "scf.for"(%1703, %1708, %1704) ({
      ^bb0(%arg401: index):
        %1712 = "memref.load"(%1702, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1712, %1700, %arg398, %arg399, %1711, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1709 = "bufferization.to_tensor"(%1700) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_219
Type: OpType.ReshapeType
Arguments: ['index_put_18', 0, 0, 9223372036854775807]
Parents: ['index_put_18']
Children: ['slice_220']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_220
Type: OpType.ReshapeType
Arguments: ['slice_219', 1, 0, 9223372036854775807]
Parents: ['slice_219']
Children: ['unsqueeze_62']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_62
Type: OpType.ReshapeType
Arguments: ['slice_220', 2]
Parents: ['slice_220']
Children: ['slice_221']
--------------------MLIR OPS--------------------
%1710 = "tosa.reshape"(%1699) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_221
Type: OpType.ReshapeType
Arguments: ['unsqueeze_62', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_62']
Children: ['slice_222']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_222
Type: OpType.ReshapeType
Arguments: ['slice_221', 4, 0, 9223372036854775807]
Parents: ['slice_221']
Children: ['expand_43']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_43
Type: OpType.ReshapeType
Arguments: ['slice_222', [1, 2, 6, 1024, 128]]
Parents: ['slice_222']
Children: ['clone_20']
--------------------MLIR OPS--------------------
%1711 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1712 = "tosa.add"(%1710, %1711) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_20
Type: OpType.ReduceType
Arguments: ['expand_43']
Parents: ['expand_43']
Children: ['view_194']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_194
Type: OpType.ReshapeType
Arguments: ['clone_20', [1, 12, 1024, 128]]
Parents: ['clone_20']
Children: ['_scaled_dot_product_flash_attention_for_cpu_9']
--------------------MLIR OPS--------------------
%1713 = "tosa.reshape"(%1712) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_227
Type: OpType.ReshapeType
Arguments: ['index_put_19', 0, 0, 9223372036854775807]
Parents: ['index_put_19']
Children: ['slice_228']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_228
Type: OpType.ReshapeType
Arguments: ['slice_227', 1, 0, 9223372036854775807]
Parents: ['slice_227']
Children: ['unsqueeze_64']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_64
Type: OpType.ReshapeType
Arguments: ['slice_228', 2]
Parents: ['slice_228']
Children: ['slice_229']
--------------------MLIR OPS--------------------
%1714 = "tosa.reshape"(%1709) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_229
Type: OpType.ReshapeType
Arguments: ['unsqueeze_64', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_64']
Children: ['slice_230']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_230
Type: OpType.ReshapeType
Arguments: ['slice_229', 4, 0, 9223372036854775807]
Parents: ['slice_229']
Children: ['expand_45']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_45
Type: OpType.ReshapeType
Arguments: ['slice_230', [1, 2, 6, 1024, 128]]
Parents: ['slice_230']
Children: ['clone_21']
--------------------MLIR OPS--------------------
%1715 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1716 = "tosa.add"(%1714, %1715) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_21
Type: OpType.ReduceType
Arguments: ['expand_45']
Parents: ['expand_45']
Children: ['view_195']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_195
Type: OpType.ReshapeType
Arguments: ['clone_21', [1, 12, 1024, 128]]
Parents: ['clone_21']
Children: ['_scaled_dot_product_flash_attention_for_cpu_9']
--------------------MLIR OPS--------------------
%1717 = "tosa.reshape"(%1716) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_231
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_232']
--------------------MLIR OPS--------------------
%1718 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_232
Type: OpType.ReshapeType
Arguments: ['slice_231', 1, 0, 9223372036854775807]
Parents: ['slice_231']
Children: ['slice_233']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_233
Type: OpType.ReshapeType
Arguments: ['slice_232', 2, 0, 9223372036854775807]
Parents: ['slice_232']
Children: ['where_9']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_18
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_9']
--------------------MLIR OPS--------------------
%1719 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_19
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_9']
--------------------MLIR OPS--------------------
%1720 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_9
Type: OpType.ElementwiseType
Arguments: ['slice_233', 'scalar_tensor_19', 'scalar_tensor_18']
Parents: ['slice_233', 'scalar_tensor_19', 'scalar_tensor_18']
Children: ['_scaled_dot_product_flash_attention_for_cpu_9']
--------------------MLIR OPS--------------------
%1721 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%1722 = "tensor.splat"(%1720) : (f32) -> tensor<1x1x1x1024xf32>
%1723 = "tensor.splat"(%1719) : (f32) -> tensor<1x1x1x1024xf32>
%1724 = "linalg.generic"(%1718, %1722, %1723, %1721) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %1725 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%1725) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_9
Type: OpType.ElementwiseType
Arguments: ['add_56', 'view_194', 'view_195']
Parents: ['add_56', 'view_194', 'view_195']
Children: ['getitem_18']
--------------------MLIR OPS--------------------
%1725 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%1726 = "tensor.splat"(%1725) : (f32) -> tensor<1x1024xf32>
%1727 = "tosa.reshape"(%1724) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%1728 = "tosa.add"(%1726, %1727) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%1729 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1730 = "tosa.transpose"(%1713, %1729) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%1731 = "tosa.reshape"(%1679) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%1732 = "tosa.reshape"(%1730) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%1733 = "tosa.matmul"(%1731, %1732) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%1734 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%1735 = "tensor.splat"(%1734) : (f32) -> tensor<12x1x1024xf32>
%1736 = "tosa.mul"(%1733, %1735) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1737 = "tosa.reshape"(%1728) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%1738 = "tosa.add"(%1736, %1737) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%1739 = "tosa.reduce_max"(%1738) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1740 = "tosa.sub"(%1738, %1739) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1741 = "math.exp"(%1740) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1742 = "tosa.reduce_sum"(%1741) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1743 = "tosa.log"(%1742) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1744 = "tosa.add"(%1739, %1743) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1745 = "tosa.sub"(%1738, %1744) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1746 = "math.exp"(%1745) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1747 = "tosa.reshape"(%1744) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%1748 = "tosa.reshape"(%1717) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%1749 = "tosa.matmul"(%1746, %1748) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%1750 = "tosa.reshape"(%1749) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_18
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_9', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_9']
Children: ['permute_106']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_106
Type: OpType.ReshapeType
Arguments: ['getitem_18', [0, 2, 1, 3]]
Parents: ['getitem_18']
Children: ['view_196']
--------------------MLIR OPS--------------------
%1751 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1752 = "tosa.transpose"(%1750, %1751) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_196
Type: OpType.ReshapeType
Arguments: ['permute_106', [1, 1, -1]]
Parents: ['permute_106']
Children: ['view_197']
--------------------MLIR OPS--------------------
%1753 = "tosa.reshape"(%1752) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_107
Type: OpType.ReshapeType
Arguments: ['arg175_1', [1, 0]]
Parents: ['arg175_1']
Children: ['mm_36']
--------------------MLIR OPS--------------------
%1754 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1755 = "tosa.transpose"(%arg139, %1754) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_197
Type: OpType.ReshapeType
Arguments: ['view_196', [1, 1536]]
Parents: ['view_196']
Children: ['mm_36']
--------------------MLIR OPS--------------------
%1756 = "tosa.reshape"(%1753) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_36
Type: OpType.ReduceType
Arguments: ['view_197', 'permute_107']
Parents: ['view_197', 'permute_107']
Children: ['view_198']
--------------------MLIR OPS--------------------
%1757 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1758 = "linalg.matmul"(%1756, %1755, %1757) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1759 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1760 = "arith.addf"(%arg400, %1759) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1760) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_198
Type: OpType.ReshapeType
Arguments: ['mm_36', [1, 1, 1536]]
Parents: ['mm_36']
Children: ['add_58']
--------------------MLIR OPS--------------------
%1759 = "tosa.reshape"(%1758) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_58
Type: OpType.BroadcastType
Arguments: ['add_54', 'view_198']
Parents: ['add_54', 'view_198']
Children: ['pow_20', 'mul_98', 'add_60']
--------------------MLIR OPS--------------------
%1760 = "tosa.add"(%1620, %1759) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_20
Type: OpType.BroadcastType
Arguments: ['add_58', 2]
Parents: ['add_58']
Children: ['mean_19']
--------------------MLIR OPS--------------------
%1761 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1762 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1763 = "linalg.generic"(%1760, %1761) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1764 = "math.fpowi"(%arg398, %1762) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1764) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_19
Type: OpType.ReduceType
Arguments: ['pow_20', [-1], True]
Parents: ['pow_20']
Children: ['add_59']
--------------------MLIR OPS--------------------
%1764 = "tosa.reduce_sum"(%1763) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1765 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1766 = "tosa.reciprocal"(%1765) : (tensor<1xf32>) -> tensor<1xf32>
%1767 = "tosa.reshape"(%1766) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1768 = "tosa.mul"(%1767, %1764) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_59
Type: OpType.BroadcastType
Arguments: ['mean_19', 1e-06]
Parents: ['mean_19']
Children: ['rsqrt_19']
--------------------MLIR OPS--------------------
%1769 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1770 = "tosa.add"(%1768, %1769) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_19
Type: OpType.ElementwiseType
Arguments: ['add_59']
Parents: ['add_59']
Children: ['mul_98']
--------------------MLIR OPS--------------------
%1771 = "tosa.rsqrt"(%1770) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_98
Type: OpType.BroadcastType
Arguments: ['add_58', 'rsqrt_19']
Parents: ['add_58', 'rsqrt_19']
Children: ['mul_99']
--------------------MLIR OPS--------------------
%1772 = "tosa.mul"(%1760, %1771) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_99
Type: OpType.BroadcastType
Arguments: ['arg176_1', 'mul_98']
Parents: ['arg176_1', 'mul_98']
Children: ['view_199', 'view_201']
--------------------MLIR OPS--------------------
%1773 = "tosa.reshape"(%arg140) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1774 = "tosa.mul"(%1773, %1772) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_108
Type: OpType.ReshapeType
Arguments: ['arg177_1', [1, 0]]
Parents: ['arg177_1']
Children: ['mm_37']
--------------------MLIR OPS--------------------
%1775 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1776 = "tosa.transpose"(%arg141, %1775) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_199
Type: OpType.ReshapeType
Arguments: ['mul_99', [1, 1536]]
Parents: ['mul_99']
Children: ['mm_37']
--------------------MLIR OPS--------------------
%1777 = "tosa.reshape"(%1774) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_37
Type: OpType.ReduceType
Arguments: ['view_199', 'permute_108']
Parents: ['view_199', 'permute_108']
Children: ['view_200']
--------------------MLIR OPS--------------------
%1778 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1779 = "linalg.matmul"(%1777, %1776, %1778) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1780 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1781 = "arith.addf"(%arg400, %1780) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1781) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_200
Type: OpType.ReshapeType
Arguments: ['mm_37', [1, 1, 8960]]
Parents: ['mm_37']
Children: ['sigmoid_9', 'mul_100']
--------------------MLIR OPS--------------------
%1780 = "tosa.reshape"(%1779) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_9
Type: OpType.ElementwiseType
Arguments: ['view_200']
Parents: ['view_200']
Children: ['mul_100']
--------------------MLIR OPS--------------------
%1781 = "tosa.sigmoid"(%1780) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_100
Type: OpType.BroadcastType
Arguments: ['view_200', 'sigmoid_9']
Parents: ['view_200', 'sigmoid_9']
Children: ['mul_101']
--------------------MLIR OPS--------------------
%1782 = "tosa.mul"(%1780, %1781) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_109
Type: OpType.ReshapeType
Arguments: ['arg178_1', [1, 0]]
Parents: ['arg178_1']
Children: ['mm_38']
--------------------MLIR OPS--------------------
%1783 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1784 = "tosa.transpose"(%arg142, %1783) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_201
Type: OpType.ReshapeType
Arguments: ['mul_99', [1, 1536]]
Parents: ['mul_99']
Children: ['mm_38']
--------------------MLIR OPS--------------------
%1785 = "tosa.reshape"(%1774) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_38
Type: OpType.ReduceType
Arguments: ['view_201', 'permute_109']
Parents: ['view_201', 'permute_109']
Children: ['view_202']
--------------------MLIR OPS--------------------
%1786 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1787 = "linalg.matmul"(%1785, %1784, %1786) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1788 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1789 = "arith.addf"(%arg400, %1788) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1789) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_202
Type: OpType.ReshapeType
Arguments: ['mm_38', [1, 1, 8960]]
Parents: ['mm_38']
Children: ['mul_101']
--------------------MLIR OPS--------------------
%1788 = "tosa.reshape"(%1787) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_101
Type: OpType.BroadcastType
Arguments: ['mul_100', 'view_202']
Parents: ['mul_100', 'view_202']
Children: ['view_203']
--------------------MLIR OPS--------------------
%1789 = "tosa.mul"(%1782, %1788) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_110
Type: OpType.ReshapeType
Arguments: ['arg179_1', [1, 0]]
Parents: ['arg179_1']
Children: ['mm_39']
--------------------MLIR OPS--------------------
%1790 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1791 = "tosa.transpose"(%arg143, %1790) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_203
Type: OpType.ReshapeType
Arguments: ['mul_101', [1, 8960]]
Parents: ['mul_101']
Children: ['mm_39']
--------------------MLIR OPS--------------------
%1792 = "tosa.reshape"(%1789) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_39
Type: OpType.ReduceType
Arguments: ['view_203', 'permute_110']
Parents: ['view_203', 'permute_110']
Children: ['view_204']
--------------------MLIR OPS--------------------
%1793 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1794 = "linalg.matmul"(%1792, %1791, %1793) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1795 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1796 = "arith.addf"(%arg400, %1795) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1796) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_204
Type: OpType.ReshapeType
Arguments: ['mm_39', [1, 1, 1536]]
Parents: ['mm_39']
Children: ['add_60']
--------------------MLIR OPS--------------------
%1795 = "tosa.reshape"(%1794) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_60
Type: OpType.BroadcastType
Arguments: ['add_58', 'view_204']
Parents: ['add_58', 'view_204']
Children: ['pow_21', 'mul_102', 'add_64']
--------------------MLIR OPS--------------------
%1796 = "tosa.add"(%1760, %1795) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_21
Type: OpType.BroadcastType
Arguments: ['add_60', 2]
Parents: ['add_60']
Children: ['mean_20']
--------------------MLIR OPS--------------------
%1797 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1798 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1799 = "linalg.generic"(%1796, %1797) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1800 = "math.fpowi"(%arg398, %1798) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1800) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_20
Type: OpType.ReduceType
Arguments: ['pow_21', [-1], True]
Parents: ['pow_21']
Children: ['add_61']
--------------------MLIR OPS--------------------
%1800 = "tosa.reduce_sum"(%1799) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1801 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1802 = "tosa.reciprocal"(%1801) : (tensor<1xf32>) -> tensor<1xf32>
%1803 = "tosa.reshape"(%1802) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1804 = "tosa.mul"(%1803, %1800) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_61
Type: OpType.BroadcastType
Arguments: ['mean_20', 1e-06]
Parents: ['mean_20']
Children: ['rsqrt_20']
--------------------MLIR OPS--------------------
%1805 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1806 = "tosa.add"(%1804, %1805) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_20
Type: OpType.ElementwiseType
Arguments: ['add_61']
Parents: ['add_61']
Children: ['mul_102']
--------------------MLIR OPS--------------------
%1807 = "tosa.rsqrt"(%1806) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_102
Type: OpType.BroadcastType
Arguments: ['add_60', 'rsqrt_20']
Parents: ['add_60', 'rsqrt_20']
Children: ['mul_103']
--------------------MLIR OPS--------------------
%1808 = "tosa.mul"(%1796, %1807) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_103
Type: OpType.BroadcastType
Arguments: ['arg180_1', 'mul_102']
Parents: ['arg180_1', 'mul_102']
Children: ['view_205', 'view_208', 'view_211']
--------------------MLIR OPS--------------------
%1809 = "tosa.reshape"(%arg144) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1810 = "tosa.mul"(%1809, %1808) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_205
Type: OpType.ReshapeType
Arguments: ['mul_103', [1, 1536]]
Parents: ['mul_103']
Children: ['addmm_30']
--------------------MLIR OPS--------------------
%1811 = "tosa.reshape"(%1810) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_111
Type: OpType.ReshapeType
Arguments: ['arg181_1', [1, 0]]
Parents: ['arg181_1']
Children: ['addmm_30']
--------------------MLIR OPS--------------------
%1812 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1813 = "tosa.transpose"(%arg145, %1812) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_30
Type: OpType.ReduceType
Arguments: ['arg182_1', 'view_205', 'permute_111']
Parents: ['arg182_1', 'view_205', 'permute_111']
Children: ['view_206']
--------------------MLIR OPS--------------------
%1814 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1815 = "linalg.matmul"(%1811, %1813, %1814) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1818 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1819 = "arith.addf"(%arg400, %1818) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1819) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%1816 = "tosa.reshape"(%arg146) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%1817 = "tosa.add"(%1816, %1815) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_206
Type: OpType.ReshapeType
Arguments: ['addmm_30', [1, 1, 1536]]
Parents: ['addmm_30']
Children: ['view_207']
--------------------MLIR OPS--------------------
%1818 = "tosa.reshape"(%1817) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_207
Type: OpType.ReshapeType
Arguments: ['view_206', [1, 1, -1, 128]]
Parents: ['view_206']
Children: ['permute_112']
--------------------MLIR OPS--------------------
%1819 = "tosa.reshape"(%1818) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_112
Type: OpType.ReshapeType
Arguments: ['view_207', [0, 2, 1, 3]]
Parents: ['view_207']
Children: ['mul_104', 'slice_234', 'slice_235']
--------------------MLIR OPS--------------------
%1820 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1821 = "tosa.transpose"(%1819, %1820) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_208
Type: OpType.ReshapeType
Arguments: ['mul_103', [1, 1536]]
Parents: ['mul_103']
Children: ['addmm_31']
--------------------MLIR OPS--------------------
%1822 = "tosa.reshape"(%1810) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_113
Type: OpType.ReshapeType
Arguments: ['arg183_1', [1, 0]]
Parents: ['arg183_1']
Children: ['addmm_31']
--------------------MLIR OPS--------------------
%1823 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1824 = "tosa.transpose"(%arg147, %1823) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_31
Type: OpType.ReduceType
Arguments: ['arg184_1', 'view_208', 'permute_113']
Parents: ['arg184_1', 'view_208', 'permute_113']
Children: ['view_209']
--------------------MLIR OPS--------------------
%1825 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%1826 = "linalg.matmul"(%1822, %1824, %1825) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1829 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1830 = "arith.addf"(%arg400, %1829) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1830) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%1827 = "tosa.reshape"(%arg148) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%1828 = "tosa.add"(%1827, %1826) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_209
Type: OpType.ReshapeType
Arguments: ['addmm_31', [1, 1, 256]]
Parents: ['addmm_31']
Children: ['view_210']
--------------------MLIR OPS--------------------
%1829 = "tosa.reshape"(%1828) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_210
Type: OpType.ReshapeType
Arguments: ['view_209', [1, 1, -1, 128]]
Parents: ['view_209']
Children: ['permute_114']
--------------------MLIR OPS--------------------
%1830 = "tosa.reshape"(%1829) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_114
Type: OpType.ReshapeType
Arguments: ['view_210', [0, 2, 1, 3]]
Parents: ['view_210']
Children: ['mul_106', 'slice_236', 'slice_237']
--------------------MLIR OPS--------------------
%1831 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1832 = "tosa.transpose"(%1830, %1831) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_211
Type: OpType.ReshapeType
Arguments: ['mul_103', [1, 1536]]
Parents: ['mul_103']
Children: ['addmm_32']
--------------------MLIR OPS--------------------
%1833 = "tosa.reshape"(%1810) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_115
Type: OpType.ReshapeType
Arguments: ['arg185_1', [1, 0]]
Parents: ['arg185_1']
Children: ['addmm_32']
--------------------MLIR OPS--------------------
%1834 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1835 = "tosa.transpose"(%arg149, %1834) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_32
Type: OpType.ReduceType
Arguments: ['arg186_1', 'view_211', 'permute_115']
Parents: ['arg186_1', 'view_211', 'permute_115']
Children: ['view_212']
--------------------MLIR OPS--------------------
%1836 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%1837 = "linalg.matmul"(%1833, %1835, %1836) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1840 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1841 = "arith.addf"(%arg400, %1840) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1841) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%1838 = "tosa.reshape"(%arg150) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%1839 = "tosa.add"(%1838, %1837) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_212
Type: OpType.ReshapeType
Arguments: ['addmm_32', [1, 1, 256]]
Parents: ['addmm_32']
Children: ['view_213']
--------------------MLIR OPS--------------------
%1840 = "tosa.reshape"(%1839) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_213
Type: OpType.ReshapeType
Arguments: ['view_212', [1, 1, -1, 128]]
Parents: ['view_212']
Children: ['permute_116']
--------------------MLIR OPS--------------------
%1841 = "tosa.reshape"(%1840) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_116
Type: OpType.ReshapeType
Arguments: ['view_213', [0, 2, 1, 3]]
Parents: ['view_213']
Children: ['index_put_21']
--------------------MLIR OPS--------------------
%1842 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1843 = "tosa.transpose"(%1841, %1842) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_65
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_104', 'mul_106']
--------------------MLIR OPS--------------------
%1844 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_66
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_105', 'mul_107']
--------------------MLIR OPS--------------------
%1845 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_104
Type: OpType.BroadcastType
Arguments: ['permute_112', 'unsqueeze_65']
Parents: ['permute_112', 'unsqueeze_65']
Children: ['add_62']
--------------------MLIR OPS--------------------
%1846 = "tosa.mul"(%1821, %1844) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_234
Type: OpType.ReshapeType
Arguments: ['permute_112', 3, 0, 64]
Parents: ['permute_112']
Children: ['cat_20']
--------------------MLIR OPS--------------------
%1847 = "tensor.extract_slice"(%1821) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_235
Type: OpType.ReshapeType
Arguments: ['permute_112', 3, 64, 9223372036854775807]
Parents: ['permute_112']
Children: ['neg_20']
--------------------MLIR OPS--------------------
%1848 = "tensor.extract_slice"(%1821) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_20
Type: OpType.ElementwiseType
Arguments: ['slice_235']
Parents: ['slice_235']
Children: ['cat_20']
--------------------MLIR OPS--------------------
%1849 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%1850 = "linalg.negf"(%1848, %1849) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1851 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%1851) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_20
Type: OpType.ConcatType
Arguments: [[neg_20, slice_234], -1]
Parents: []
Children: ['mul_105']
--------------------MLIR OPS--------------------
%1851 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%1852 = "tensor.insert_slice"(%1850, %1851) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%1853 = "tensor.insert_slice"(%1847, %1852) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_105
Type: OpType.BroadcastType
Arguments: ['cat_20', 'unsqueeze_66']
Parents: ['cat_20', 'unsqueeze_66']
Children: ['add_62']
--------------------MLIR OPS--------------------
%1854 = "tosa.mul"(%1853, %1845) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_62
Type: OpType.BroadcastType
Arguments: ['mul_104', 'mul_105']
Parents: ['mul_104', 'mul_105']
Children: ['_scaled_dot_product_flash_attention_for_cpu_10']
--------------------MLIR OPS--------------------
%1855 = "tosa.add"(%1846, %1854) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_106
Type: OpType.BroadcastType
Arguments: ['permute_114', 'unsqueeze_65']
Parents: ['permute_114', 'unsqueeze_65']
Children: ['add_63']
--------------------MLIR OPS--------------------
%1856 = "tosa.mul"(%1832, %1844) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_236
Type: OpType.ReshapeType
Arguments: ['permute_114', 3, 0, 64]
Parents: ['permute_114']
Children: ['cat_21']
--------------------MLIR OPS--------------------
%1857 = "tensor.extract_slice"(%1832) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_237
Type: OpType.ReshapeType
Arguments: ['permute_114', 3, 64, 9223372036854775807]
Parents: ['permute_114']
Children: ['neg_21']
--------------------MLIR OPS--------------------
%1858 = "tensor.extract_slice"(%1832) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_21
Type: OpType.ElementwiseType
Arguments: ['slice_237']
Parents: ['slice_237']
Children: ['cat_21']
--------------------MLIR OPS--------------------
%1859 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%1860 = "linalg.negf"(%1858, %1859) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1861 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%1861) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_21
Type: OpType.ConcatType
Arguments: [[neg_21, slice_236], -1]
Parents: []
Children: ['mul_107']
--------------------MLIR OPS--------------------
%1861 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%1862 = "tensor.insert_slice"(%1860, %1861) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%1863 = "tensor.insert_slice"(%1857, %1862) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_107
Type: OpType.BroadcastType
Arguments: ['cat_21', 'unsqueeze_66']
Parents: ['cat_21', 'unsqueeze_66']
Children: ['add_63']
--------------------MLIR OPS--------------------
%1864 = "tosa.mul"(%1863, %1845) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_63
Type: OpType.BroadcastType
Arguments: ['mul_106', 'mul_107']
Parents: ['mul_106', 'mul_107']
Children: ['index_put_20']
--------------------MLIR OPS--------------------
%1865 = "tosa.add"(%1856, %1864) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_20
Type: OpType.ElementwiseType
Arguments: ['arg20_1', [None, None, arg58_1], 'add_63']
Parents: ['arg20_1', 'add_63']
Children: ['slice_242', 'output']
--------------------MLIR OPS--------------------
%1866 = "bufferization.to_memref"(%arg151) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%1867 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%1868 = "bufferization.to_memref"(%1865) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%1869 = "arith.constant"() <{value = 0 : index}> : () -> index
%1870 = "arith.constant"() <{value = 1 : index}> : () -> index
%1871 = "arith.constant"() <{value = 1 : index}> : () -> index
%1872 = "arith.constant"() <{value = 2 : index}> : () -> index
%1873 = "arith.constant"() <{value = 1 : index}> : () -> index
%1874 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%1869, %1871, %1870) ({
^bb0(%arg398: index):
  "scf.for"(%1869, %1872, %1870) ({
  ^bb0(%arg399: index):
    "scf.for"(%1869, %1873, %1870) ({
    ^bb0(%arg400: index):
      %1876 = "memref.load"(%1867, %arg400) : (memref<1xi64>, index) -> i64
      %1877 = "arith.index_cast"(%1876) : (i64) -> index
      "scf.for"(%1869, %1874, %1870) ({
      ^bb0(%arg401: index):
        %1878 = "memref.load"(%1868, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1878, %1866, %arg398, %arg399, %1877, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1875 = "bufferization.to_tensor"(%1866) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_21
Type: OpType.ElementwiseType
Arguments: ['arg21_1', [None, None, arg58_1], 'permute_116']
Parents: ['arg21_1', 'permute_116']
Children: ['slice_250', 'output']
--------------------MLIR OPS--------------------
%1876 = "bufferization.to_memref"(%arg152) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%1877 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%1878 = "bufferization.to_memref"(%1843) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%1879 = "arith.constant"() <{value = 0 : index}> : () -> index
%1880 = "arith.constant"() <{value = 1 : index}> : () -> index
%1881 = "arith.constant"() <{value = 1 : index}> : () -> index
%1882 = "arith.constant"() <{value = 2 : index}> : () -> index
%1883 = "arith.constant"() <{value = 1 : index}> : () -> index
%1884 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%1879, %1881, %1880) ({
^bb0(%arg398: index):
  "scf.for"(%1879, %1882, %1880) ({
  ^bb0(%arg399: index):
    "scf.for"(%1879, %1883, %1880) ({
    ^bb0(%arg400: index):
      %1886 = "memref.load"(%1877, %arg400) : (memref<1xi64>, index) -> i64
      %1887 = "arith.index_cast"(%1886) : (i64) -> index
      "scf.for"(%1879, %1884, %1880) ({
      ^bb0(%arg401: index):
        %1888 = "memref.load"(%1878, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%1888, %1876, %arg398, %arg399, %1887, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%1885 = "bufferization.to_tensor"(%1876) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_242
Type: OpType.ReshapeType
Arguments: ['index_put_20', 0, 0, 9223372036854775807]
Parents: ['index_put_20']
Children: ['slice_243']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_243
Type: OpType.ReshapeType
Arguments: ['slice_242', 1, 0, 9223372036854775807]
Parents: ['slice_242']
Children: ['unsqueeze_68']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_68
Type: OpType.ReshapeType
Arguments: ['slice_243', 2]
Parents: ['slice_243']
Children: ['slice_244']
--------------------MLIR OPS--------------------
%1886 = "tosa.reshape"(%1875) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_244
Type: OpType.ReshapeType
Arguments: ['unsqueeze_68', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_68']
Children: ['slice_245']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_245
Type: OpType.ReshapeType
Arguments: ['slice_244', 4, 0, 9223372036854775807]
Parents: ['slice_244']
Children: ['expand_47']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_47
Type: OpType.ReshapeType
Arguments: ['slice_245', [1, 2, 6, 1024, 128]]
Parents: ['slice_245']
Children: ['clone_22']
--------------------MLIR OPS--------------------
%1887 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1888 = "tosa.add"(%1886, %1887) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_22
Type: OpType.ReduceType
Arguments: ['expand_47']
Parents: ['expand_47']
Children: ['view_214']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_214
Type: OpType.ReshapeType
Arguments: ['clone_22', [1, 12, 1024, 128]]
Parents: ['clone_22']
Children: ['_scaled_dot_product_flash_attention_for_cpu_10']
--------------------MLIR OPS--------------------
%1889 = "tosa.reshape"(%1888) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_250
Type: OpType.ReshapeType
Arguments: ['index_put_21', 0, 0, 9223372036854775807]
Parents: ['index_put_21']
Children: ['slice_251']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_251
Type: OpType.ReshapeType
Arguments: ['slice_250', 1, 0, 9223372036854775807]
Parents: ['slice_250']
Children: ['unsqueeze_70']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_70
Type: OpType.ReshapeType
Arguments: ['slice_251', 2]
Parents: ['slice_251']
Children: ['slice_252']
--------------------MLIR OPS--------------------
%1890 = "tosa.reshape"(%1885) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_252
Type: OpType.ReshapeType
Arguments: ['unsqueeze_70', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_70']
Children: ['slice_253']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_253
Type: OpType.ReshapeType
Arguments: ['slice_252', 4, 0, 9223372036854775807]
Parents: ['slice_252']
Children: ['expand_49']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_49
Type: OpType.ReshapeType
Arguments: ['slice_253', [1, 2, 6, 1024, 128]]
Parents: ['slice_253']
Children: ['clone_23']
--------------------MLIR OPS--------------------
%1891 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%1892 = "tosa.add"(%1890, %1891) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_23
Type: OpType.ReduceType
Arguments: ['expand_49']
Parents: ['expand_49']
Children: ['view_215']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_215
Type: OpType.ReshapeType
Arguments: ['clone_23', [1, 12, 1024, 128]]
Parents: ['clone_23']
Children: ['_scaled_dot_product_flash_attention_for_cpu_10']
--------------------MLIR OPS--------------------
%1893 = "tosa.reshape"(%1892) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_254
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_255']
--------------------MLIR OPS--------------------
%1894 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_255
Type: OpType.ReshapeType
Arguments: ['slice_254', 1, 0, 9223372036854775807]
Parents: ['slice_254']
Children: ['slice_256']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_256
Type: OpType.ReshapeType
Arguments: ['slice_255', 2, 0, 9223372036854775807]
Parents: ['slice_255']
Children: ['where_10']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_20
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_10']
--------------------MLIR OPS--------------------
%1895 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_21
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_10']
--------------------MLIR OPS--------------------
%1896 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_10
Type: OpType.ElementwiseType
Arguments: ['slice_256', 'scalar_tensor_21', 'scalar_tensor_20']
Parents: ['slice_256', 'scalar_tensor_21', 'scalar_tensor_20']
Children: ['_scaled_dot_product_flash_attention_for_cpu_10']
--------------------MLIR OPS--------------------
%1897 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%1898 = "tensor.splat"(%1896) : (f32) -> tensor<1x1x1x1024xf32>
%1899 = "tensor.splat"(%1895) : (f32) -> tensor<1x1x1x1024xf32>
%1900 = "linalg.generic"(%1894, %1898, %1899, %1897) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %1901 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%1901) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_10
Type: OpType.ElementwiseType
Arguments: ['add_62', 'view_214', 'view_215']
Parents: ['add_62', 'view_214', 'view_215']
Children: ['getitem_20']
--------------------MLIR OPS--------------------
%1901 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%1902 = "tensor.splat"(%1901) : (f32) -> tensor<1x1024xf32>
%1903 = "tosa.reshape"(%1900) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%1904 = "tosa.add"(%1902, %1903) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%1905 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1906 = "tosa.transpose"(%1889, %1905) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%1907 = "tosa.reshape"(%1855) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%1908 = "tosa.reshape"(%1906) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%1909 = "tosa.matmul"(%1907, %1908) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%1910 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%1911 = "tensor.splat"(%1910) : (f32) -> tensor<12x1x1024xf32>
%1912 = "tosa.mul"(%1909, %1911) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1913 = "tosa.reshape"(%1904) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%1914 = "tosa.add"(%1912, %1913) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%1915 = "tosa.reduce_max"(%1914) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1916 = "tosa.sub"(%1914, %1915) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1917 = "math.exp"(%1916) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1918 = "tosa.reduce_sum"(%1917) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%1919 = "tosa.log"(%1918) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1920 = "tosa.add"(%1915, %1919) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%1921 = "tosa.sub"(%1914, %1920) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%1922 = "math.exp"(%1921) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%1923 = "tosa.reshape"(%1920) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%1924 = "tosa.reshape"(%1893) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%1925 = "tosa.matmul"(%1922, %1924) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%1926 = "tosa.reshape"(%1925) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_20
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_10', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_10']
Children: ['permute_117']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_117
Type: OpType.ReshapeType
Arguments: ['getitem_20', [0, 2, 1, 3]]
Parents: ['getitem_20']
Children: ['view_216']
--------------------MLIR OPS--------------------
%1927 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1928 = "tosa.transpose"(%1926, %1927) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_216
Type: OpType.ReshapeType
Arguments: ['permute_117', [1, 1, -1]]
Parents: ['permute_117']
Children: ['view_217']
--------------------MLIR OPS--------------------
%1929 = "tosa.reshape"(%1928) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_118
Type: OpType.ReshapeType
Arguments: ['arg187_1', [1, 0]]
Parents: ['arg187_1']
Children: ['mm_40']
--------------------MLIR OPS--------------------
%1930 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1931 = "tosa.transpose"(%arg153, %1930) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_217
Type: OpType.ReshapeType
Arguments: ['view_216', [1, 1536]]
Parents: ['view_216']
Children: ['mm_40']
--------------------MLIR OPS--------------------
%1932 = "tosa.reshape"(%1929) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_40
Type: OpType.ReduceType
Arguments: ['view_217', 'permute_118']
Parents: ['view_217', 'permute_118']
Children: ['view_218']
--------------------MLIR OPS--------------------
%1933 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1934 = "linalg.matmul"(%1932, %1931, %1933) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1935 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1936 = "arith.addf"(%arg400, %1935) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1936) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_218
Type: OpType.ReshapeType
Arguments: ['mm_40', [1, 1, 1536]]
Parents: ['mm_40']
Children: ['add_64']
--------------------MLIR OPS--------------------
%1935 = "tosa.reshape"(%1934) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_64
Type: OpType.BroadcastType
Arguments: ['add_60', 'view_218']
Parents: ['add_60', 'view_218']
Children: ['pow_22', 'mul_108', 'add_66']
--------------------MLIR OPS--------------------
%1936 = "tosa.add"(%1796, %1935) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_22
Type: OpType.BroadcastType
Arguments: ['add_64', 2]
Parents: ['add_64']
Children: ['mean_21']
--------------------MLIR OPS--------------------
%1937 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1938 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1939 = "linalg.generic"(%1936, %1937) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1940 = "math.fpowi"(%arg398, %1938) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1940) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_21
Type: OpType.ReduceType
Arguments: ['pow_22', [-1], True]
Parents: ['pow_22']
Children: ['add_65']
--------------------MLIR OPS--------------------
%1940 = "tosa.reduce_sum"(%1939) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1941 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1942 = "tosa.reciprocal"(%1941) : (tensor<1xf32>) -> tensor<1xf32>
%1943 = "tosa.reshape"(%1942) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1944 = "tosa.mul"(%1943, %1940) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_65
Type: OpType.BroadcastType
Arguments: ['mean_21', 1e-06]
Parents: ['mean_21']
Children: ['rsqrt_21']
--------------------MLIR OPS--------------------
%1945 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1946 = "tosa.add"(%1944, %1945) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_21
Type: OpType.ElementwiseType
Arguments: ['add_65']
Parents: ['add_65']
Children: ['mul_108']
--------------------MLIR OPS--------------------
%1947 = "tosa.rsqrt"(%1946) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_108
Type: OpType.BroadcastType
Arguments: ['add_64', 'rsqrt_21']
Parents: ['add_64', 'rsqrt_21']
Children: ['mul_109']
--------------------MLIR OPS--------------------
%1948 = "tosa.mul"(%1936, %1947) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_109
Type: OpType.BroadcastType
Arguments: ['arg188_1', 'mul_108']
Parents: ['arg188_1', 'mul_108']
Children: ['view_219', 'view_221']
--------------------MLIR OPS--------------------
%1949 = "tosa.reshape"(%arg154) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1950 = "tosa.mul"(%1949, %1948) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_119
Type: OpType.ReshapeType
Arguments: ['arg189_1', [1, 0]]
Parents: ['arg189_1']
Children: ['mm_41']
--------------------MLIR OPS--------------------
%1951 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1952 = "tosa.transpose"(%arg155, %1951) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_219
Type: OpType.ReshapeType
Arguments: ['mul_109', [1, 1536]]
Parents: ['mul_109']
Children: ['mm_41']
--------------------MLIR OPS--------------------
%1953 = "tosa.reshape"(%1950) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_41
Type: OpType.ReduceType
Arguments: ['view_219', 'permute_119']
Parents: ['view_219', 'permute_119']
Children: ['view_220']
--------------------MLIR OPS--------------------
%1954 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1955 = "linalg.matmul"(%1953, %1952, %1954) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1956 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1957 = "arith.addf"(%arg400, %1956) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1957) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_220
Type: OpType.ReshapeType
Arguments: ['mm_41', [1, 1, 8960]]
Parents: ['mm_41']
Children: ['sigmoid_10', 'mul_110']
--------------------MLIR OPS--------------------
%1956 = "tosa.reshape"(%1955) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_10
Type: OpType.ElementwiseType
Arguments: ['view_220']
Parents: ['view_220']
Children: ['mul_110']
--------------------MLIR OPS--------------------
%1957 = "tosa.sigmoid"(%1956) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_110
Type: OpType.BroadcastType
Arguments: ['view_220', 'sigmoid_10']
Parents: ['view_220', 'sigmoid_10']
Children: ['mul_111']
--------------------MLIR OPS--------------------
%1958 = "tosa.mul"(%1956, %1957) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_120
Type: OpType.ReshapeType
Arguments: ['arg190_1', [1, 0]]
Parents: ['arg190_1']
Children: ['mm_42']
--------------------MLIR OPS--------------------
%1959 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1960 = "tosa.transpose"(%arg156, %1959) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_221
Type: OpType.ReshapeType
Arguments: ['mul_109', [1, 1536]]
Parents: ['mul_109']
Children: ['mm_42']
--------------------MLIR OPS--------------------
%1961 = "tosa.reshape"(%1950) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_42
Type: OpType.ReduceType
Arguments: ['view_221', 'permute_120']
Parents: ['view_221', 'permute_120']
Children: ['view_222']
--------------------MLIR OPS--------------------
%1962 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%1963 = "linalg.matmul"(%1961, %1960, %1962) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1964 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1965 = "arith.addf"(%arg400, %1964) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1965) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_222
Type: OpType.ReshapeType
Arguments: ['mm_42', [1, 1, 8960]]
Parents: ['mm_42']
Children: ['mul_111']
--------------------MLIR OPS--------------------
%1964 = "tosa.reshape"(%1963) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_111
Type: OpType.BroadcastType
Arguments: ['mul_110', 'view_222']
Parents: ['mul_110', 'view_222']
Children: ['view_223']
--------------------MLIR OPS--------------------
%1965 = "tosa.mul"(%1958, %1964) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_121
Type: OpType.ReshapeType
Arguments: ['arg191_1', [1, 0]]
Parents: ['arg191_1']
Children: ['mm_43']
--------------------MLIR OPS--------------------
%1966 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1967 = "tosa.transpose"(%arg157, %1966) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_223
Type: OpType.ReshapeType
Arguments: ['mul_111', [1, 8960]]
Parents: ['mul_111']
Children: ['mm_43']
--------------------MLIR OPS--------------------
%1968 = "tosa.reshape"(%1965) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_43
Type: OpType.ReduceType
Arguments: ['view_223', 'permute_121']
Parents: ['view_223', 'permute_121']
Children: ['view_224']
--------------------MLIR OPS--------------------
%1969 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1970 = "linalg.matmul"(%1968, %1967, %1969) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1971 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1972 = "arith.addf"(%arg400, %1971) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1972) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_224
Type: OpType.ReshapeType
Arguments: ['mm_43', [1, 1, 1536]]
Parents: ['mm_43']
Children: ['add_66']
--------------------MLIR OPS--------------------
%1971 = "tosa.reshape"(%1970) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_66
Type: OpType.BroadcastType
Arguments: ['add_64', 'view_224']
Parents: ['add_64', 'view_224']
Children: ['pow_23', 'mul_112', 'add_70']
--------------------MLIR OPS--------------------
%1972 = "tosa.add"(%1936, %1971) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_23
Type: OpType.BroadcastType
Arguments: ['add_66', 2]
Parents: ['add_66']
Children: ['mean_22']
--------------------MLIR OPS--------------------
%1973 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%1974 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%1975 = "linalg.generic"(%1972, %1973) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %1976 = "math.fpowi"(%arg398, %1974) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%1976) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_22
Type: OpType.ReduceType
Arguments: ['pow_23', [-1], True]
Parents: ['pow_23']
Children: ['add_67']
--------------------MLIR OPS--------------------
%1976 = "tosa.reduce_sum"(%1975) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%1977 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%1978 = "tosa.reciprocal"(%1977) : (tensor<1xf32>) -> tensor<1xf32>
%1979 = "tosa.reshape"(%1978) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%1980 = "tosa.mul"(%1979, %1976) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_67
Type: OpType.BroadcastType
Arguments: ['mean_22', 1e-06]
Parents: ['mean_22']
Children: ['rsqrt_22']
--------------------MLIR OPS--------------------
%1981 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%1982 = "tosa.add"(%1980, %1981) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_22
Type: OpType.ElementwiseType
Arguments: ['add_67']
Parents: ['add_67']
Children: ['mul_112']
--------------------MLIR OPS--------------------
%1983 = "tosa.rsqrt"(%1982) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_112
Type: OpType.BroadcastType
Arguments: ['add_66', 'rsqrt_22']
Parents: ['add_66', 'rsqrt_22']
Children: ['mul_113']
--------------------MLIR OPS--------------------
%1984 = "tosa.mul"(%1972, %1983) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_113
Type: OpType.BroadcastType
Arguments: ['arg192_1', 'mul_112']
Parents: ['arg192_1', 'mul_112']
Children: ['view_225', 'view_228', 'view_231']
--------------------MLIR OPS--------------------
%1985 = "tosa.reshape"(%arg158) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%1986 = "tosa.mul"(%1985, %1984) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_225
Type: OpType.ReshapeType
Arguments: ['mul_113', [1, 1536]]
Parents: ['mul_113']
Children: ['addmm_33']
--------------------MLIR OPS--------------------
%1987 = "tosa.reshape"(%1986) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_122
Type: OpType.ReshapeType
Arguments: ['arg193_1', [1, 0]]
Parents: ['arg193_1']
Children: ['addmm_33']
--------------------MLIR OPS--------------------
%1988 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%1989 = "tosa.transpose"(%arg159, %1988) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_33
Type: OpType.ReduceType
Arguments: ['arg194_1', 'view_225', 'permute_122']
Parents: ['arg194_1', 'view_225', 'permute_122']
Children: ['view_226']
--------------------MLIR OPS--------------------
%1990 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%1991 = "linalg.matmul"(%1987, %1989, %1990) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %1994 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %1995 = "arith.addf"(%arg400, %1994) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%1995) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%1992 = "tosa.reshape"(%arg160) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%1993 = "tosa.add"(%1992, %1991) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_226
Type: OpType.ReshapeType
Arguments: ['addmm_33', [1, 1, 1536]]
Parents: ['addmm_33']
Children: ['view_227']
--------------------MLIR OPS--------------------
%1994 = "tosa.reshape"(%1993) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_227
Type: OpType.ReshapeType
Arguments: ['view_226', [1, 1, -1, 128]]
Parents: ['view_226']
Children: ['permute_123']
--------------------MLIR OPS--------------------
%1995 = "tosa.reshape"(%1994) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_123
Type: OpType.ReshapeType
Arguments: ['view_227', [0, 2, 1, 3]]
Parents: ['view_227']
Children: ['mul_114', 'slice_257', 'slice_258']
--------------------MLIR OPS--------------------
%1996 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%1997 = "tosa.transpose"(%1995, %1996) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_228
Type: OpType.ReshapeType
Arguments: ['mul_113', [1, 1536]]
Parents: ['mul_113']
Children: ['addmm_34']
--------------------MLIR OPS--------------------
%1998 = "tosa.reshape"(%1986) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_124
Type: OpType.ReshapeType
Arguments: ['arg195_1', [1, 0]]
Parents: ['arg195_1']
Children: ['addmm_34']
--------------------MLIR OPS--------------------
%1999 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2000 = "tosa.transpose"(%arg161, %1999) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_34
Type: OpType.ReduceType
Arguments: ['arg196_1', 'view_228', 'permute_124']
Parents: ['arg196_1', 'view_228', 'permute_124']
Children: ['view_229']
--------------------MLIR OPS--------------------
%2001 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2002 = "linalg.matmul"(%1998, %2000, %2001) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2005 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2006 = "arith.addf"(%arg400, %2005) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2006) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2003 = "tosa.reshape"(%arg162) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2004 = "tosa.add"(%2003, %2002) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_229
Type: OpType.ReshapeType
Arguments: ['addmm_34', [1, 1, 256]]
Parents: ['addmm_34']
Children: ['view_230']
--------------------MLIR OPS--------------------
%2005 = "tosa.reshape"(%2004) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_230
Type: OpType.ReshapeType
Arguments: ['view_229', [1, 1, -1, 128]]
Parents: ['view_229']
Children: ['permute_125']
--------------------MLIR OPS--------------------
%2006 = "tosa.reshape"(%2005) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_125
Type: OpType.ReshapeType
Arguments: ['view_230', [0, 2, 1, 3]]
Parents: ['view_230']
Children: ['mul_116', 'slice_259', 'slice_260']
--------------------MLIR OPS--------------------
%2007 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2008 = "tosa.transpose"(%2006, %2007) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_231
Type: OpType.ReshapeType
Arguments: ['mul_113', [1, 1536]]
Parents: ['mul_113']
Children: ['addmm_35']
--------------------MLIR OPS--------------------
%2009 = "tosa.reshape"(%1986) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_126
Type: OpType.ReshapeType
Arguments: ['arg197_1', [1, 0]]
Parents: ['arg197_1']
Children: ['addmm_35']
--------------------MLIR OPS--------------------
%2010 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2011 = "tosa.transpose"(%arg163, %2010) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_35
Type: OpType.ReduceType
Arguments: ['arg198_1', 'view_231', 'permute_126']
Parents: ['arg198_1', 'view_231', 'permute_126']
Children: ['view_232']
--------------------MLIR OPS--------------------
%2012 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2013 = "linalg.matmul"(%2009, %2011, %2012) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2016 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2017 = "arith.addf"(%arg400, %2016) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2017) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2014 = "tosa.reshape"(%arg164) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2015 = "tosa.add"(%2014, %2013) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_232
Type: OpType.ReshapeType
Arguments: ['addmm_35', [1, 1, 256]]
Parents: ['addmm_35']
Children: ['view_233']
--------------------MLIR OPS--------------------
%2016 = "tosa.reshape"(%2015) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_233
Type: OpType.ReshapeType
Arguments: ['view_232', [1, 1, -1, 128]]
Parents: ['view_232']
Children: ['permute_127']
--------------------MLIR OPS--------------------
%2017 = "tosa.reshape"(%2016) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_127
Type: OpType.ReshapeType
Arguments: ['view_233', [0, 2, 1, 3]]
Parents: ['view_233']
Children: ['index_put_23']
--------------------MLIR OPS--------------------
%2018 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2019 = "tosa.transpose"(%2017, %2018) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_71
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_114', 'mul_116']
--------------------MLIR OPS--------------------
%2020 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_72
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_115', 'mul_117']
--------------------MLIR OPS--------------------
%2021 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_114
Type: OpType.BroadcastType
Arguments: ['permute_123', 'unsqueeze_71']
Parents: ['permute_123', 'unsqueeze_71']
Children: ['add_68']
--------------------MLIR OPS--------------------
%2022 = "tosa.mul"(%1997, %2020) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_257
Type: OpType.ReshapeType
Arguments: ['permute_123', 3, 0, 64]
Parents: ['permute_123']
Children: ['cat_22']
--------------------MLIR OPS--------------------
%2023 = "tensor.extract_slice"(%1997) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_258
Type: OpType.ReshapeType
Arguments: ['permute_123', 3, 64, 9223372036854775807]
Parents: ['permute_123']
Children: ['neg_22']
--------------------MLIR OPS--------------------
%2024 = "tensor.extract_slice"(%1997) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_22
Type: OpType.ElementwiseType
Arguments: ['slice_258']
Parents: ['slice_258']
Children: ['cat_22']
--------------------MLIR OPS--------------------
%2025 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%2026 = "linalg.negf"(%2024, %2025) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2027 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2027) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_22
Type: OpType.ConcatType
Arguments: [[neg_22, slice_257], -1]
Parents: []
Children: ['mul_115']
--------------------MLIR OPS--------------------
%2027 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%2028 = "tensor.insert_slice"(%2026, %2027) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%2029 = "tensor.insert_slice"(%2023, %2028) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_115
Type: OpType.BroadcastType
Arguments: ['cat_22', 'unsqueeze_72']
Parents: ['cat_22', 'unsqueeze_72']
Children: ['add_68']
--------------------MLIR OPS--------------------
%2030 = "tosa.mul"(%2029, %2021) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_68
Type: OpType.BroadcastType
Arguments: ['mul_114', 'mul_115']
Parents: ['mul_114', 'mul_115']
Children: ['_scaled_dot_product_flash_attention_for_cpu_11']
--------------------MLIR OPS--------------------
%2031 = "tosa.add"(%2022, %2030) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_116
Type: OpType.BroadcastType
Arguments: ['permute_125', 'unsqueeze_71']
Parents: ['permute_125', 'unsqueeze_71']
Children: ['add_69']
--------------------MLIR OPS--------------------
%2032 = "tosa.mul"(%2008, %2020) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_259
Type: OpType.ReshapeType
Arguments: ['permute_125', 3, 0, 64]
Parents: ['permute_125']
Children: ['cat_23']
--------------------MLIR OPS--------------------
%2033 = "tensor.extract_slice"(%2008) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_260
Type: OpType.ReshapeType
Arguments: ['permute_125', 3, 64, 9223372036854775807]
Parents: ['permute_125']
Children: ['neg_23']
--------------------MLIR OPS--------------------
%2034 = "tensor.extract_slice"(%2008) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_23
Type: OpType.ElementwiseType
Arguments: ['slice_260']
Parents: ['slice_260']
Children: ['cat_23']
--------------------MLIR OPS--------------------
%2035 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%2036 = "linalg.negf"(%2034, %2035) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2037 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2037) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_23
Type: OpType.ConcatType
Arguments: [[neg_23, slice_259], -1]
Parents: []
Children: ['mul_117']
--------------------MLIR OPS--------------------
%2037 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%2038 = "tensor.insert_slice"(%2036, %2037) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%2039 = "tensor.insert_slice"(%2033, %2038) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_117
Type: OpType.BroadcastType
Arguments: ['cat_23', 'unsqueeze_72']
Parents: ['cat_23', 'unsqueeze_72']
Children: ['add_69']
--------------------MLIR OPS--------------------
%2040 = "tosa.mul"(%2039, %2021) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_69
Type: OpType.BroadcastType
Arguments: ['mul_116', 'mul_117']
Parents: ['mul_116', 'mul_117']
Children: ['index_put_22']
--------------------MLIR OPS--------------------
%2041 = "tosa.add"(%2032, %2040) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_22
Type: OpType.ElementwiseType
Arguments: ['arg22_1', [None, None, arg58_1], 'add_69']
Parents: ['arg22_1', 'add_69']
Children: ['slice_265', 'output']
--------------------MLIR OPS--------------------
%2042 = "bufferization.to_memref"(%arg165) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2043 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2044 = "bufferization.to_memref"(%2041) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2045 = "arith.constant"() <{value = 0 : index}> : () -> index
%2046 = "arith.constant"() <{value = 1 : index}> : () -> index
%2047 = "arith.constant"() <{value = 1 : index}> : () -> index
%2048 = "arith.constant"() <{value = 2 : index}> : () -> index
%2049 = "arith.constant"() <{value = 1 : index}> : () -> index
%2050 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2045, %2047, %2046) ({
^bb0(%arg398: index):
  "scf.for"(%2045, %2048, %2046) ({
  ^bb0(%arg399: index):
    "scf.for"(%2045, %2049, %2046) ({
    ^bb0(%arg400: index):
      %2052 = "memref.load"(%2043, %arg400) : (memref<1xi64>, index) -> i64
      %2053 = "arith.index_cast"(%2052) : (i64) -> index
      "scf.for"(%2045, %2050, %2046) ({
      ^bb0(%arg401: index):
        %2054 = "memref.load"(%2044, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2054, %2042, %arg398, %arg399, %2053, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2051 = "bufferization.to_tensor"(%2042) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_23
Type: OpType.ElementwiseType
Arguments: ['arg23_1', [None, None, arg58_1], 'permute_127']
Parents: ['arg23_1', 'permute_127']
Children: ['slice_273', 'output']
--------------------MLIR OPS--------------------
%2052 = "bufferization.to_memref"(%arg166) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2053 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2054 = "bufferization.to_memref"(%2019) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2055 = "arith.constant"() <{value = 0 : index}> : () -> index
%2056 = "arith.constant"() <{value = 1 : index}> : () -> index
%2057 = "arith.constant"() <{value = 1 : index}> : () -> index
%2058 = "arith.constant"() <{value = 2 : index}> : () -> index
%2059 = "arith.constant"() <{value = 1 : index}> : () -> index
%2060 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2055, %2057, %2056) ({
^bb0(%arg398: index):
  "scf.for"(%2055, %2058, %2056) ({
  ^bb0(%arg399: index):
    "scf.for"(%2055, %2059, %2056) ({
    ^bb0(%arg400: index):
      %2062 = "memref.load"(%2053, %arg400) : (memref<1xi64>, index) -> i64
      %2063 = "arith.index_cast"(%2062) : (i64) -> index
      "scf.for"(%2055, %2060, %2056) ({
      ^bb0(%arg401: index):
        %2064 = "memref.load"(%2054, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2064, %2052, %arg398, %arg399, %2063, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2061 = "bufferization.to_tensor"(%2052) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_265
Type: OpType.ReshapeType
Arguments: ['index_put_22', 0, 0, 9223372036854775807]
Parents: ['index_put_22']
Children: ['slice_266']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_266
Type: OpType.ReshapeType
Arguments: ['slice_265', 1, 0, 9223372036854775807]
Parents: ['slice_265']
Children: ['unsqueeze_74']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_74
Type: OpType.ReshapeType
Arguments: ['slice_266', 2]
Parents: ['slice_266']
Children: ['slice_267']
--------------------MLIR OPS--------------------
%2062 = "tosa.reshape"(%2051) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_267
Type: OpType.ReshapeType
Arguments: ['unsqueeze_74', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_74']
Children: ['slice_268']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_268
Type: OpType.ReshapeType
Arguments: ['slice_267', 4, 0, 9223372036854775807]
Parents: ['slice_267']
Children: ['expand_51']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_51
Type: OpType.ReshapeType
Arguments: ['slice_268', [1, 2, 6, 1024, 128]]
Parents: ['slice_268']
Children: ['clone_24']
--------------------MLIR OPS--------------------
%2063 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2064 = "tosa.add"(%2062, %2063) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_24
Type: OpType.ReduceType
Arguments: ['expand_51']
Parents: ['expand_51']
Children: ['view_234']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_234
Type: OpType.ReshapeType
Arguments: ['clone_24', [1, 12, 1024, 128]]
Parents: ['clone_24']
Children: ['_scaled_dot_product_flash_attention_for_cpu_11']
--------------------MLIR OPS--------------------
%2065 = "tosa.reshape"(%2064) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_273
Type: OpType.ReshapeType
Arguments: ['index_put_23', 0, 0, 9223372036854775807]
Parents: ['index_put_23']
Children: ['slice_274']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_274
Type: OpType.ReshapeType
Arguments: ['slice_273', 1, 0, 9223372036854775807]
Parents: ['slice_273']
Children: ['unsqueeze_76']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_76
Type: OpType.ReshapeType
Arguments: ['slice_274', 2]
Parents: ['slice_274']
Children: ['slice_275']
--------------------MLIR OPS--------------------
%2066 = "tosa.reshape"(%2061) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_275
Type: OpType.ReshapeType
Arguments: ['unsqueeze_76', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_76']
Children: ['slice_276']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_276
Type: OpType.ReshapeType
Arguments: ['slice_275', 4, 0, 9223372036854775807]
Parents: ['slice_275']
Children: ['expand_53']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_53
Type: OpType.ReshapeType
Arguments: ['slice_276', [1, 2, 6, 1024, 128]]
Parents: ['slice_276']
Children: ['clone_25']
--------------------MLIR OPS--------------------
%2067 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2068 = "tosa.add"(%2066, %2067) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_25
Type: OpType.ReduceType
Arguments: ['expand_53']
Parents: ['expand_53']
Children: ['view_235']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_235
Type: OpType.ReshapeType
Arguments: ['clone_25', [1, 12, 1024, 128]]
Parents: ['clone_25']
Children: ['_scaled_dot_product_flash_attention_for_cpu_11']
--------------------MLIR OPS--------------------
%2069 = "tosa.reshape"(%2068) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_277
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_278']
--------------------MLIR OPS--------------------
%2070 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_278
Type: OpType.ReshapeType
Arguments: ['slice_277', 1, 0, 9223372036854775807]
Parents: ['slice_277']
Children: ['slice_279']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_279
Type: OpType.ReshapeType
Arguments: ['slice_278', 2, 0, 9223372036854775807]
Parents: ['slice_278']
Children: ['where_11']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_22
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_11']
--------------------MLIR OPS--------------------
%2071 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_23
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_11']
--------------------MLIR OPS--------------------
%2072 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_11
Type: OpType.ElementwiseType
Arguments: ['slice_279', 'scalar_tensor_23', 'scalar_tensor_22']
Parents: ['slice_279', 'scalar_tensor_23', 'scalar_tensor_22']
Children: ['_scaled_dot_product_flash_attention_for_cpu_11']
--------------------MLIR OPS--------------------
%2073 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%2074 = "tensor.splat"(%2072) : (f32) -> tensor<1x1x1x1024xf32>
%2075 = "tensor.splat"(%2071) : (f32) -> tensor<1x1x1x1024xf32>
%2076 = "linalg.generic"(%2070, %2074, %2075, %2073) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %2077 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%2077) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_11
Type: OpType.ElementwiseType
Arguments: ['add_68', 'view_234', 'view_235']
Parents: ['add_68', 'view_234', 'view_235']
Children: ['getitem_22']
--------------------MLIR OPS--------------------
%2077 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%2078 = "tensor.splat"(%2077) : (f32) -> tensor<1x1024xf32>
%2079 = "tosa.reshape"(%2076) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%2080 = "tosa.add"(%2078, %2079) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%2081 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2082 = "tosa.transpose"(%2065, %2081) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%2083 = "tosa.reshape"(%2031) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%2084 = "tosa.reshape"(%2082) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%2085 = "tosa.matmul"(%2083, %2084) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%2086 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%2087 = "tensor.splat"(%2086) : (f32) -> tensor<12x1x1024xf32>
%2088 = "tosa.mul"(%2085, %2087) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2089 = "tosa.reshape"(%2080) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%2090 = "tosa.add"(%2088, %2089) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%2091 = "tosa.reduce_max"(%2090) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2092 = "tosa.sub"(%2090, %2091) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2093 = "math.exp"(%2092) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2094 = "tosa.reduce_sum"(%2093) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2095 = "tosa.log"(%2094) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2096 = "tosa.add"(%2091, %2095) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2097 = "tosa.sub"(%2090, %2096) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2098 = "math.exp"(%2097) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2099 = "tosa.reshape"(%2096) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%2100 = "tosa.reshape"(%2069) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%2101 = "tosa.matmul"(%2098, %2100) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%2102 = "tosa.reshape"(%2101) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_22
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_11', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_11']
Children: ['permute_128']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_128
Type: OpType.ReshapeType
Arguments: ['getitem_22', [0, 2, 1, 3]]
Parents: ['getitem_22']
Children: ['view_236']
--------------------MLIR OPS--------------------
%2103 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2104 = "tosa.transpose"(%2102, %2103) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_236
Type: OpType.ReshapeType
Arguments: ['permute_128', [1, 1, -1]]
Parents: ['permute_128']
Children: ['view_237']
--------------------MLIR OPS--------------------
%2105 = "tosa.reshape"(%2104) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_129
Type: OpType.ReshapeType
Arguments: ['arg199_1', [1, 0]]
Parents: ['arg199_1']
Children: ['mm_44']
--------------------MLIR OPS--------------------
%2106 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2107 = "tosa.transpose"(%arg167, %2106) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_237
Type: OpType.ReshapeType
Arguments: ['view_236', [1, 1536]]
Parents: ['view_236']
Children: ['mm_44']
--------------------MLIR OPS--------------------
%2108 = "tosa.reshape"(%2105) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_44
Type: OpType.ReduceType
Arguments: ['view_237', 'permute_129']
Parents: ['view_237', 'permute_129']
Children: ['view_238']
--------------------MLIR OPS--------------------
%2109 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2110 = "linalg.matmul"(%2108, %2107, %2109) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2111 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2112 = "arith.addf"(%arg400, %2111) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2112) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_238
Type: OpType.ReshapeType
Arguments: ['mm_44', [1, 1, 1536]]
Parents: ['mm_44']
Children: ['add_70']
--------------------MLIR OPS--------------------
%2111 = "tosa.reshape"(%2110) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_70
Type: OpType.BroadcastType
Arguments: ['add_66', 'view_238']
Parents: ['add_66', 'view_238']
Children: ['pow_24', 'mul_118', 'add_72']
--------------------MLIR OPS--------------------
%2112 = "tosa.add"(%1972, %2111) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_24
Type: OpType.BroadcastType
Arguments: ['add_70', 2]
Parents: ['add_70']
Children: ['mean_23']
--------------------MLIR OPS--------------------
%2113 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2114 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2115 = "linalg.generic"(%2112, %2113) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2116 = "math.fpowi"(%arg398, %2114) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2116) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_23
Type: OpType.ReduceType
Arguments: ['pow_24', [-1], True]
Parents: ['pow_24']
Children: ['add_71']
--------------------MLIR OPS--------------------
%2116 = "tosa.reduce_sum"(%2115) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2117 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2118 = "tosa.reciprocal"(%2117) : (tensor<1xf32>) -> tensor<1xf32>
%2119 = "tosa.reshape"(%2118) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%2120 = "tosa.mul"(%2119, %2116) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_71
Type: OpType.BroadcastType
Arguments: ['mean_23', 1e-06]
Parents: ['mean_23']
Children: ['rsqrt_23']
--------------------MLIR OPS--------------------
%2121 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%2122 = "tosa.add"(%2120, %2121) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_23
Type: OpType.ElementwiseType
Arguments: ['add_71']
Parents: ['add_71']
Children: ['mul_118']
--------------------MLIR OPS--------------------
%2123 = "tosa.rsqrt"(%2122) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_118
Type: OpType.BroadcastType
Arguments: ['add_70', 'rsqrt_23']
Parents: ['add_70', 'rsqrt_23']
Children: ['mul_119']
--------------------MLIR OPS--------------------
%2124 = "tosa.mul"(%2112, %2123) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_119
Type: OpType.BroadcastType
Arguments: ['arg200_1', 'mul_118']
Parents: ['arg200_1', 'mul_118']
Children: ['view_239', 'view_241']
--------------------MLIR OPS--------------------
%2125 = "tosa.reshape"(%arg168) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%2126 = "tosa.mul"(%2125, %2124) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_130
Type: OpType.ReshapeType
Arguments: ['arg201_1', [1, 0]]
Parents: ['arg201_1']
Children: ['mm_45']
--------------------MLIR OPS--------------------
%2127 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2128 = "tosa.transpose"(%arg169, %2127) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_239
Type: OpType.ReshapeType
Arguments: ['mul_119', [1, 1536]]
Parents: ['mul_119']
Children: ['mm_45']
--------------------MLIR OPS--------------------
%2129 = "tosa.reshape"(%2126) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_45
Type: OpType.ReduceType
Arguments: ['view_239', 'permute_130']
Parents: ['view_239', 'permute_130']
Children: ['view_240']
--------------------MLIR OPS--------------------
%2130 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%2131 = "linalg.matmul"(%2129, %2128, %2130) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2132 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2133 = "arith.addf"(%arg400, %2132) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2133) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_240
Type: OpType.ReshapeType
Arguments: ['mm_45', [1, 1, 8960]]
Parents: ['mm_45']
Children: ['sigmoid_11', 'mul_120']
--------------------MLIR OPS--------------------
%2132 = "tosa.reshape"(%2131) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_11
Type: OpType.ElementwiseType
Arguments: ['view_240']
Parents: ['view_240']
Children: ['mul_120']
--------------------MLIR OPS--------------------
%2133 = "tosa.sigmoid"(%2132) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_120
Type: OpType.BroadcastType
Arguments: ['view_240', 'sigmoid_11']
Parents: ['view_240', 'sigmoid_11']
Children: ['mul_121']
--------------------MLIR OPS--------------------
%2134 = "tosa.mul"(%2132, %2133) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_131
Type: OpType.ReshapeType
Arguments: ['arg202_1', [1, 0]]
Parents: ['arg202_1']
Children: ['mm_46']
--------------------MLIR OPS--------------------
%2135 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2136 = "tosa.transpose"(%arg170, %2135) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_241
Type: OpType.ReshapeType
Arguments: ['mul_119', [1, 1536]]
Parents: ['mul_119']
Children: ['mm_46']
--------------------MLIR OPS--------------------
%2137 = "tosa.reshape"(%2126) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_46
Type: OpType.ReduceType
Arguments: ['view_241', 'permute_131']
Parents: ['view_241', 'permute_131']
Children: ['view_242']
--------------------MLIR OPS--------------------
%2138 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%2139 = "linalg.matmul"(%2137, %2136, %2138) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2140 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2141 = "arith.addf"(%arg400, %2140) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2141) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_242
Type: OpType.ReshapeType
Arguments: ['mm_46', [1, 1, 8960]]
Parents: ['mm_46']
Children: ['mul_121']
--------------------MLIR OPS--------------------
%2140 = "tosa.reshape"(%2139) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_121
Type: OpType.BroadcastType
Arguments: ['mul_120', 'view_242']
Parents: ['mul_120', 'view_242']
Children: ['view_243']
--------------------MLIR OPS--------------------
%2141 = "tosa.mul"(%2134, %2140) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_132
Type: OpType.ReshapeType
Arguments: ['arg203_1', [1, 0]]
Parents: ['arg203_1']
Children: ['mm_47']
--------------------MLIR OPS--------------------
%2142 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2143 = "tosa.transpose"(%arg171, %2142) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_243
Type: OpType.ReshapeType
Arguments: ['mul_121', [1, 8960]]
Parents: ['mul_121']
Children: ['mm_47']
--------------------MLIR OPS--------------------
%2144 = "tosa.reshape"(%2141) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_47
Type: OpType.ReduceType
Arguments: ['view_243', 'permute_132']
Parents: ['view_243', 'permute_132']
Children: ['view_244']
--------------------MLIR OPS--------------------
%2145 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2146 = "linalg.matmul"(%2144, %2143, %2145) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2147 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2148 = "arith.addf"(%arg400, %2147) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2148) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_244
Type: OpType.ReshapeType
Arguments: ['mm_47', [1, 1, 1536]]
Parents: ['mm_47']
Children: ['add_72']
--------------------MLIR OPS--------------------
%2147 = "tosa.reshape"(%2146) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_72
Type: OpType.BroadcastType
Arguments: ['add_70', 'view_244']
Parents: ['add_70', 'view_244']
Children: ['pow_25', 'mul_122', 'add_76']
--------------------MLIR OPS--------------------
%2148 = "tosa.add"(%2112, %2147) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_25
Type: OpType.BroadcastType
Arguments: ['add_72', 2]
Parents: ['add_72']
Children: ['mean_24']
--------------------MLIR OPS--------------------
%2149 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2150 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2151 = "linalg.generic"(%2148, %2149) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2152 = "math.fpowi"(%arg398, %2150) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2152) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_24
Type: OpType.ReduceType
Arguments: ['pow_25', [-1], True]
Parents: ['pow_25']
Children: ['add_73']
--------------------MLIR OPS--------------------
%2152 = "tosa.reduce_sum"(%2151) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2153 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2154 = "tosa.reciprocal"(%2153) : (tensor<1xf32>) -> tensor<1xf32>
%2155 = "tosa.reshape"(%2154) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%2156 = "tosa.mul"(%2155, %2152) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_73
Type: OpType.BroadcastType
Arguments: ['mean_24', 1e-06]
Parents: ['mean_24']
Children: ['rsqrt_24']
--------------------MLIR OPS--------------------
%2157 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%2158 = "tosa.add"(%2156, %2157) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_24
Type: OpType.ElementwiseType
Arguments: ['add_73']
Parents: ['add_73']
Children: ['mul_122']
--------------------MLIR OPS--------------------
%2159 = "tosa.rsqrt"(%2158) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_122
Type: OpType.BroadcastType
Arguments: ['add_72', 'rsqrt_24']
Parents: ['add_72', 'rsqrt_24']
Children: ['mul_123']
--------------------MLIR OPS--------------------
%2160 = "tosa.mul"(%2148, %2159) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_123
Type: OpType.BroadcastType
Arguments: ['arg204_1', 'mul_122']
Parents: ['arg204_1', 'mul_122']
Children: ['view_245', 'view_248', 'view_251']
--------------------MLIR OPS--------------------
%2161 = "tosa.reshape"(%arg172) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%2162 = "tosa.mul"(%2161, %2160) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_245
Type: OpType.ReshapeType
Arguments: ['mul_123', [1, 1536]]
Parents: ['mul_123']
Children: ['addmm_36']
--------------------MLIR OPS--------------------
%2163 = "tosa.reshape"(%2162) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_133
Type: OpType.ReshapeType
Arguments: ['arg205_1', [1, 0]]
Parents: ['arg205_1']
Children: ['addmm_36']
--------------------MLIR OPS--------------------
%2164 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2165 = "tosa.transpose"(%arg173, %2164) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_36
Type: OpType.ReduceType
Arguments: ['arg206_1', 'view_245', 'permute_133']
Parents: ['arg206_1', 'view_245', 'permute_133']
Children: ['view_246']
--------------------MLIR OPS--------------------
%2166 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2167 = "linalg.matmul"(%2163, %2165, %2166) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2170 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2171 = "arith.addf"(%arg400, %2170) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2171) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%2168 = "tosa.reshape"(%arg174) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%2169 = "tosa.add"(%2168, %2167) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_246
Type: OpType.ReshapeType
Arguments: ['addmm_36', [1, 1, 1536]]
Parents: ['addmm_36']
Children: ['view_247']
--------------------MLIR OPS--------------------
%2170 = "tosa.reshape"(%2169) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_247
Type: OpType.ReshapeType
Arguments: ['view_246', [1, 1, -1, 128]]
Parents: ['view_246']
Children: ['permute_134']
--------------------MLIR OPS--------------------
%2171 = "tosa.reshape"(%2170) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_134
Type: OpType.ReshapeType
Arguments: ['view_247', [0, 2, 1, 3]]
Parents: ['view_247']
Children: ['mul_124', 'slice_280', 'slice_281']
--------------------MLIR OPS--------------------
%2172 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2173 = "tosa.transpose"(%2171, %2172) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_248
Type: OpType.ReshapeType
Arguments: ['mul_123', [1, 1536]]
Parents: ['mul_123']
Children: ['addmm_37']
--------------------MLIR OPS--------------------
%2174 = "tosa.reshape"(%2162) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_135
Type: OpType.ReshapeType
Arguments: ['arg207_1', [1, 0]]
Parents: ['arg207_1']
Children: ['addmm_37']
--------------------MLIR OPS--------------------
%2175 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2176 = "tosa.transpose"(%arg175, %2175) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_37
Type: OpType.ReduceType
Arguments: ['arg208_1', 'view_248', 'permute_135']
Parents: ['arg208_1', 'view_248', 'permute_135']
Children: ['view_249']
--------------------MLIR OPS--------------------
%2177 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2178 = "linalg.matmul"(%2174, %2176, %2177) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2181 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2182 = "arith.addf"(%arg400, %2181) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2182) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2179 = "tosa.reshape"(%arg176) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2180 = "tosa.add"(%2179, %2178) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_249
Type: OpType.ReshapeType
Arguments: ['addmm_37', [1, 1, 256]]
Parents: ['addmm_37']
Children: ['view_250']
--------------------MLIR OPS--------------------
%2181 = "tosa.reshape"(%2180) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_250
Type: OpType.ReshapeType
Arguments: ['view_249', [1, 1, -1, 128]]
Parents: ['view_249']
Children: ['permute_136']
--------------------MLIR OPS--------------------
%2182 = "tosa.reshape"(%2181) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_136
Type: OpType.ReshapeType
Arguments: ['view_250', [0, 2, 1, 3]]
Parents: ['view_250']
Children: ['mul_126', 'slice_282', 'slice_283']
--------------------MLIR OPS--------------------
%2183 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2184 = "tosa.transpose"(%2182, %2183) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_251
Type: OpType.ReshapeType
Arguments: ['mul_123', [1, 1536]]
Parents: ['mul_123']
Children: ['addmm_38']
--------------------MLIR OPS--------------------
%2185 = "tosa.reshape"(%2162) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_137
Type: OpType.ReshapeType
Arguments: ['arg209_1', [1, 0]]
Parents: ['arg209_1']
Children: ['addmm_38']
--------------------MLIR OPS--------------------
%2186 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2187 = "tosa.transpose"(%arg177, %2186) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_38
Type: OpType.ReduceType
Arguments: ['arg210_1', 'view_251', 'permute_137']
Parents: ['arg210_1', 'view_251', 'permute_137']
Children: ['view_252']
--------------------MLIR OPS--------------------
%2188 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2189 = "linalg.matmul"(%2185, %2187, %2188) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2192 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2193 = "arith.addf"(%arg400, %2192) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2193) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2190 = "tosa.reshape"(%arg178) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2191 = "tosa.add"(%2190, %2189) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_252
Type: OpType.ReshapeType
Arguments: ['addmm_38', [1, 1, 256]]
Parents: ['addmm_38']
Children: ['view_253']
--------------------MLIR OPS--------------------
%2192 = "tosa.reshape"(%2191) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_253
Type: OpType.ReshapeType
Arguments: ['view_252', [1, 1, -1, 128]]
Parents: ['view_252']
Children: ['permute_138']
--------------------MLIR OPS--------------------
%2193 = "tosa.reshape"(%2192) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_138
Type: OpType.ReshapeType
Arguments: ['view_253', [0, 2, 1, 3]]
Parents: ['view_253']
Children: ['index_put_25']
--------------------MLIR OPS--------------------
%2194 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2195 = "tosa.transpose"(%2193, %2194) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_77
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_124', 'mul_126']
--------------------MLIR OPS--------------------
%2196 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_78
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_125', 'mul_127']
--------------------MLIR OPS--------------------
%2197 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_124
Type: OpType.BroadcastType
Arguments: ['permute_134', 'unsqueeze_77']
Parents: ['permute_134', 'unsqueeze_77']
Children: ['add_74']
--------------------MLIR OPS--------------------
%2198 = "tosa.mul"(%2173, %2196) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_280
Type: OpType.ReshapeType
Arguments: ['permute_134', 3, 0, 64]
Parents: ['permute_134']
Children: ['cat_24']
--------------------MLIR OPS--------------------
%2199 = "tensor.extract_slice"(%2173) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_281
Type: OpType.ReshapeType
Arguments: ['permute_134', 3, 64, 9223372036854775807]
Parents: ['permute_134']
Children: ['neg_24']
--------------------MLIR OPS--------------------
%2200 = "tensor.extract_slice"(%2173) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_24
Type: OpType.ElementwiseType
Arguments: ['slice_281']
Parents: ['slice_281']
Children: ['cat_24']
--------------------MLIR OPS--------------------
%2201 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%2202 = "linalg.negf"(%2200, %2201) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2203 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2203) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_24
Type: OpType.ConcatType
Arguments: [[neg_24, slice_280], -1]
Parents: []
Children: ['mul_125']
--------------------MLIR OPS--------------------
%2203 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%2204 = "tensor.insert_slice"(%2202, %2203) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%2205 = "tensor.insert_slice"(%2199, %2204) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_125
Type: OpType.BroadcastType
Arguments: ['cat_24', 'unsqueeze_78']
Parents: ['cat_24', 'unsqueeze_78']
Children: ['add_74']
--------------------MLIR OPS--------------------
%2206 = "tosa.mul"(%2205, %2197) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_74
Type: OpType.BroadcastType
Arguments: ['mul_124', 'mul_125']
Parents: ['mul_124', 'mul_125']
Children: ['_scaled_dot_product_flash_attention_for_cpu_12']
--------------------MLIR OPS--------------------
%2207 = "tosa.add"(%2198, %2206) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_126
Type: OpType.BroadcastType
Arguments: ['permute_136', 'unsqueeze_77']
Parents: ['permute_136', 'unsqueeze_77']
Children: ['add_75']
--------------------MLIR OPS--------------------
%2208 = "tosa.mul"(%2184, %2196) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_282
Type: OpType.ReshapeType
Arguments: ['permute_136', 3, 0, 64]
Parents: ['permute_136']
Children: ['cat_25']
--------------------MLIR OPS--------------------
%2209 = "tensor.extract_slice"(%2184) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_283
Type: OpType.ReshapeType
Arguments: ['permute_136', 3, 64, 9223372036854775807]
Parents: ['permute_136']
Children: ['neg_25']
--------------------MLIR OPS--------------------
%2210 = "tensor.extract_slice"(%2184) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_25
Type: OpType.ElementwiseType
Arguments: ['slice_283']
Parents: ['slice_283']
Children: ['cat_25']
--------------------MLIR OPS--------------------
%2211 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%2212 = "linalg.negf"(%2210, %2211) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2213 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2213) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_25
Type: OpType.ConcatType
Arguments: [[neg_25, slice_282], -1]
Parents: []
Children: ['mul_127']
--------------------MLIR OPS--------------------
%2213 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%2214 = "tensor.insert_slice"(%2212, %2213) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%2215 = "tensor.insert_slice"(%2209, %2214) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_127
Type: OpType.BroadcastType
Arguments: ['cat_25', 'unsqueeze_78']
Parents: ['cat_25', 'unsqueeze_78']
Children: ['add_75']
--------------------MLIR OPS--------------------
%2216 = "tosa.mul"(%2215, %2197) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_75
Type: OpType.BroadcastType
Arguments: ['mul_126', 'mul_127']
Parents: ['mul_126', 'mul_127']
Children: ['index_put_24']
--------------------MLIR OPS--------------------
%2217 = "tosa.add"(%2208, %2216) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_24
Type: OpType.ElementwiseType
Arguments: ['arg24_1', [None, None, arg58_1], 'add_75']
Parents: ['arg24_1', 'add_75']
Children: ['slice_288', 'output']
--------------------MLIR OPS--------------------
%2218 = "bufferization.to_memref"(%arg179) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2219 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2220 = "bufferization.to_memref"(%2217) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2221 = "arith.constant"() <{value = 0 : index}> : () -> index
%2222 = "arith.constant"() <{value = 1 : index}> : () -> index
%2223 = "arith.constant"() <{value = 1 : index}> : () -> index
%2224 = "arith.constant"() <{value = 2 : index}> : () -> index
%2225 = "arith.constant"() <{value = 1 : index}> : () -> index
%2226 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2221, %2223, %2222) ({
^bb0(%arg398: index):
  "scf.for"(%2221, %2224, %2222) ({
  ^bb0(%arg399: index):
    "scf.for"(%2221, %2225, %2222) ({
    ^bb0(%arg400: index):
      %2228 = "memref.load"(%2219, %arg400) : (memref<1xi64>, index) -> i64
      %2229 = "arith.index_cast"(%2228) : (i64) -> index
      "scf.for"(%2221, %2226, %2222) ({
      ^bb0(%arg401: index):
        %2230 = "memref.load"(%2220, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2230, %2218, %arg398, %arg399, %2229, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2227 = "bufferization.to_tensor"(%2218) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_25
Type: OpType.ElementwiseType
Arguments: ['arg25_1', [None, None, arg58_1], 'permute_138']
Parents: ['arg25_1', 'permute_138']
Children: ['slice_296', 'output']
--------------------MLIR OPS--------------------
%2228 = "bufferization.to_memref"(%arg180) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2229 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2230 = "bufferization.to_memref"(%2195) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2231 = "arith.constant"() <{value = 0 : index}> : () -> index
%2232 = "arith.constant"() <{value = 1 : index}> : () -> index
%2233 = "arith.constant"() <{value = 1 : index}> : () -> index
%2234 = "arith.constant"() <{value = 2 : index}> : () -> index
%2235 = "arith.constant"() <{value = 1 : index}> : () -> index
%2236 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2231, %2233, %2232) ({
^bb0(%arg398: index):
  "scf.for"(%2231, %2234, %2232) ({
  ^bb0(%arg399: index):
    "scf.for"(%2231, %2235, %2232) ({
    ^bb0(%arg400: index):
      %2238 = "memref.load"(%2229, %arg400) : (memref<1xi64>, index) -> i64
      %2239 = "arith.index_cast"(%2238) : (i64) -> index
      "scf.for"(%2231, %2236, %2232) ({
      ^bb0(%arg401: index):
        %2240 = "memref.load"(%2230, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2240, %2228, %arg398, %arg399, %2239, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2237 = "bufferization.to_tensor"(%2228) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_288
Type: OpType.ReshapeType
Arguments: ['index_put_24', 0, 0, 9223372036854775807]
Parents: ['index_put_24']
Children: ['slice_289']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_289
Type: OpType.ReshapeType
Arguments: ['slice_288', 1, 0, 9223372036854775807]
Parents: ['slice_288']
Children: ['unsqueeze_80']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_80
Type: OpType.ReshapeType
Arguments: ['slice_289', 2]
Parents: ['slice_289']
Children: ['slice_290']
--------------------MLIR OPS--------------------
%2238 = "tosa.reshape"(%2227) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_290
Type: OpType.ReshapeType
Arguments: ['unsqueeze_80', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_80']
Children: ['slice_291']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_291
Type: OpType.ReshapeType
Arguments: ['slice_290', 4, 0, 9223372036854775807]
Parents: ['slice_290']
Children: ['expand_55']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_55
Type: OpType.ReshapeType
Arguments: ['slice_291', [1, 2, 6, 1024, 128]]
Parents: ['slice_291']
Children: ['clone_26']
--------------------MLIR OPS--------------------
%2239 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2240 = "tosa.add"(%2238, %2239) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_26
Type: OpType.ReduceType
Arguments: ['expand_55']
Parents: ['expand_55']
Children: ['view_254']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_254
Type: OpType.ReshapeType
Arguments: ['clone_26', [1, 12, 1024, 128]]
Parents: ['clone_26']
Children: ['_scaled_dot_product_flash_attention_for_cpu_12']
--------------------MLIR OPS--------------------
%2241 = "tosa.reshape"(%2240) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_296
Type: OpType.ReshapeType
Arguments: ['index_put_25', 0, 0, 9223372036854775807]
Parents: ['index_put_25']
Children: ['slice_297']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_297
Type: OpType.ReshapeType
Arguments: ['slice_296', 1, 0, 9223372036854775807]
Parents: ['slice_296']
Children: ['unsqueeze_82']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_82
Type: OpType.ReshapeType
Arguments: ['slice_297', 2]
Parents: ['slice_297']
Children: ['slice_298']
--------------------MLIR OPS--------------------
%2242 = "tosa.reshape"(%2237) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_298
Type: OpType.ReshapeType
Arguments: ['unsqueeze_82', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_82']
Children: ['slice_299']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_299
Type: OpType.ReshapeType
Arguments: ['slice_298', 4, 0, 9223372036854775807]
Parents: ['slice_298']
Children: ['expand_57']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_57
Type: OpType.ReshapeType
Arguments: ['slice_299', [1, 2, 6, 1024, 128]]
Parents: ['slice_299']
Children: ['clone_27']
--------------------MLIR OPS--------------------
%2243 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2244 = "tosa.add"(%2242, %2243) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_27
Type: OpType.ReduceType
Arguments: ['expand_57']
Parents: ['expand_57']
Children: ['view_255']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_255
Type: OpType.ReshapeType
Arguments: ['clone_27', [1, 12, 1024, 128]]
Parents: ['clone_27']
Children: ['_scaled_dot_product_flash_attention_for_cpu_12']
--------------------MLIR OPS--------------------
%2245 = "tosa.reshape"(%2244) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_300
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_301']
--------------------MLIR OPS--------------------
%2246 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_301
Type: OpType.ReshapeType
Arguments: ['slice_300', 1, 0, 9223372036854775807]
Parents: ['slice_300']
Children: ['slice_302']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_302
Type: OpType.ReshapeType
Arguments: ['slice_301', 2, 0, 9223372036854775807]
Parents: ['slice_301']
Children: ['where_12']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_24
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_12']
--------------------MLIR OPS--------------------
%2247 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_25
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_12']
--------------------MLIR OPS--------------------
%2248 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_12
Type: OpType.ElementwiseType
Arguments: ['slice_302', 'scalar_tensor_25', 'scalar_tensor_24']
Parents: ['slice_302', 'scalar_tensor_25', 'scalar_tensor_24']
Children: ['_scaled_dot_product_flash_attention_for_cpu_12']
--------------------MLIR OPS--------------------
%2249 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%2250 = "tensor.splat"(%2248) : (f32) -> tensor<1x1x1x1024xf32>
%2251 = "tensor.splat"(%2247) : (f32) -> tensor<1x1x1x1024xf32>
%2252 = "linalg.generic"(%2246, %2250, %2251, %2249) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %2253 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%2253) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_12
Type: OpType.ElementwiseType
Arguments: ['add_74', 'view_254', 'view_255']
Parents: ['add_74', 'view_254', 'view_255']
Children: ['getitem_24']
--------------------MLIR OPS--------------------
%2253 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%2254 = "tensor.splat"(%2253) : (f32) -> tensor<1x1024xf32>
%2255 = "tosa.reshape"(%2252) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%2256 = "tosa.add"(%2254, %2255) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%2257 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2258 = "tosa.transpose"(%2241, %2257) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%2259 = "tosa.reshape"(%2207) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%2260 = "tosa.reshape"(%2258) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%2261 = "tosa.matmul"(%2259, %2260) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%2262 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%2263 = "tensor.splat"(%2262) : (f32) -> tensor<12x1x1024xf32>
%2264 = "tosa.mul"(%2261, %2263) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2265 = "tosa.reshape"(%2256) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%2266 = "tosa.add"(%2264, %2265) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%2267 = "tosa.reduce_max"(%2266) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2268 = "tosa.sub"(%2266, %2267) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2269 = "math.exp"(%2268) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2270 = "tosa.reduce_sum"(%2269) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2271 = "tosa.log"(%2270) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2272 = "tosa.add"(%2267, %2271) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2273 = "tosa.sub"(%2266, %2272) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2274 = "math.exp"(%2273) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2275 = "tosa.reshape"(%2272) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%2276 = "tosa.reshape"(%2245) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%2277 = "tosa.matmul"(%2274, %2276) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%2278 = "tosa.reshape"(%2277) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_24
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_12', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_12']
Children: ['permute_139']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_139
Type: OpType.ReshapeType
Arguments: ['getitem_24', [0, 2, 1, 3]]
Parents: ['getitem_24']
Children: ['view_256']
--------------------MLIR OPS--------------------
%2279 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2280 = "tosa.transpose"(%2278, %2279) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_256
Type: OpType.ReshapeType
Arguments: ['permute_139', [1, 1, -1]]
Parents: ['permute_139']
Children: ['view_257']
--------------------MLIR OPS--------------------
%2281 = "tosa.reshape"(%2280) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_140
Type: OpType.ReshapeType
Arguments: ['arg211_1', [1, 0]]
Parents: ['arg211_1']
Children: ['mm_48']
--------------------MLIR OPS--------------------
%2282 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2283 = "tosa.transpose"(%arg181, %2282) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_257
Type: OpType.ReshapeType
Arguments: ['view_256', [1, 1536]]
Parents: ['view_256']
Children: ['mm_48']
--------------------MLIR OPS--------------------
%2284 = "tosa.reshape"(%2281) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_48
Type: OpType.ReduceType
Arguments: ['view_257', 'permute_140']
Parents: ['view_257', 'permute_140']
Children: ['view_258']
--------------------MLIR OPS--------------------
%2285 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2286 = "linalg.matmul"(%2284, %2283, %2285) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2287 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2288 = "arith.addf"(%arg400, %2287) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2288) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_258
Type: OpType.ReshapeType
Arguments: ['mm_48', [1, 1, 1536]]
Parents: ['mm_48']
Children: ['add_76']
--------------------MLIR OPS--------------------
%2287 = "tosa.reshape"(%2286) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_76
Type: OpType.BroadcastType
Arguments: ['add_72', 'view_258']
Parents: ['add_72', 'view_258']
Children: ['pow_26', 'mul_128', 'add_78']
--------------------MLIR OPS--------------------
%2288 = "tosa.add"(%2148, %2287) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_26
Type: OpType.BroadcastType
Arguments: ['add_76', 2]
Parents: ['add_76']
Children: ['mean_25']
--------------------MLIR OPS--------------------
%2289 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2290 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2291 = "linalg.generic"(%2288, %2289) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2292 = "math.fpowi"(%arg398, %2290) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2292) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_25
Type: OpType.ReduceType
Arguments: ['pow_26', [-1], True]
Parents: ['pow_26']
Children: ['add_77']
--------------------MLIR OPS--------------------
%2292 = "tosa.reduce_sum"(%2291) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2293 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2294 = "tosa.reciprocal"(%2293) : (tensor<1xf32>) -> tensor<1xf32>
%2295 = "tosa.reshape"(%2294) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%2296 = "tosa.mul"(%2295, %2292) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_77
Type: OpType.BroadcastType
Arguments: ['mean_25', 1e-06]
Parents: ['mean_25']
Children: ['rsqrt_25']
--------------------MLIR OPS--------------------
%2297 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%2298 = "tosa.add"(%2296, %2297) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_25
Type: OpType.ElementwiseType
Arguments: ['add_77']
Parents: ['add_77']
Children: ['mul_128']
--------------------MLIR OPS--------------------
%2299 = "tosa.rsqrt"(%2298) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_128
Type: OpType.BroadcastType
Arguments: ['add_76', 'rsqrt_25']
Parents: ['add_76', 'rsqrt_25']
Children: ['mul_129']
--------------------MLIR OPS--------------------
%2300 = "tosa.mul"(%2288, %2299) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_129
Type: OpType.BroadcastType
Arguments: ['arg212_1', 'mul_128']
Parents: ['arg212_1', 'mul_128']
Children: ['view_259', 'view_261']
--------------------MLIR OPS--------------------
%2301 = "tosa.reshape"(%arg182) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%2302 = "tosa.mul"(%2301, %2300) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_141
Type: OpType.ReshapeType
Arguments: ['arg213_1', [1, 0]]
Parents: ['arg213_1']
Children: ['mm_49']
--------------------MLIR OPS--------------------
%2303 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2304 = "tosa.transpose"(%arg183, %2303) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_259
Type: OpType.ReshapeType
Arguments: ['mul_129', [1, 1536]]
Parents: ['mul_129']
Children: ['mm_49']
--------------------MLIR OPS--------------------
%2305 = "tosa.reshape"(%2302) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_49
Type: OpType.ReduceType
Arguments: ['view_259', 'permute_141']
Parents: ['view_259', 'permute_141']
Children: ['view_260']
--------------------MLIR OPS--------------------
%2306 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%2307 = "linalg.matmul"(%2305, %2304, %2306) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2308 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2309 = "arith.addf"(%arg400, %2308) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2309) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_260
Type: OpType.ReshapeType
Arguments: ['mm_49', [1, 1, 8960]]
Parents: ['mm_49']
Children: ['sigmoid_12', 'mul_130']
--------------------MLIR OPS--------------------
%2308 = "tosa.reshape"(%2307) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_12
Type: OpType.ElementwiseType
Arguments: ['view_260']
Parents: ['view_260']
Children: ['mul_130']
--------------------MLIR OPS--------------------
%2309 = "tosa.sigmoid"(%2308) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_130
Type: OpType.BroadcastType
Arguments: ['view_260', 'sigmoid_12']
Parents: ['view_260', 'sigmoid_12']
Children: ['mul_131']
--------------------MLIR OPS--------------------
%2310 = "tosa.mul"(%2308, %2309) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_142
Type: OpType.ReshapeType
Arguments: ['arg214_1', [1, 0]]
Parents: ['arg214_1']
Children: ['mm_50']
--------------------MLIR OPS--------------------
%2311 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2312 = "tosa.transpose"(%arg184, %2311) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_261
Type: OpType.ReshapeType
Arguments: ['mul_129', [1, 1536]]
Parents: ['mul_129']
Children: ['mm_50']
--------------------MLIR OPS--------------------
%2313 = "tosa.reshape"(%2302) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_50
Type: OpType.ReduceType
Arguments: ['view_261', 'permute_142']
Parents: ['view_261', 'permute_142']
Children: ['view_262']
--------------------MLIR OPS--------------------
%2314 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%2315 = "linalg.matmul"(%2313, %2312, %2314) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2316 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2317 = "arith.addf"(%arg400, %2316) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2317) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_262
Type: OpType.ReshapeType
Arguments: ['mm_50', [1, 1, 8960]]
Parents: ['mm_50']
Children: ['mul_131']
--------------------MLIR OPS--------------------
%2316 = "tosa.reshape"(%2315) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_131
Type: OpType.BroadcastType
Arguments: ['mul_130', 'view_262']
Parents: ['mul_130', 'view_262']
Children: ['view_263']
--------------------MLIR OPS--------------------
%2317 = "tosa.mul"(%2310, %2316) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_143
Type: OpType.ReshapeType
Arguments: ['arg215_1', [1, 0]]
Parents: ['arg215_1']
Children: ['mm_51']
--------------------MLIR OPS--------------------
%2318 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2319 = "tosa.transpose"(%arg185, %2318) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_263
Type: OpType.ReshapeType
Arguments: ['mul_131', [1, 8960]]
Parents: ['mul_131']
Children: ['mm_51']
--------------------MLIR OPS--------------------
%2320 = "tosa.reshape"(%2317) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_51
Type: OpType.ReduceType
Arguments: ['view_263', 'permute_143']
Parents: ['view_263', 'permute_143']
Children: ['view_264']
--------------------MLIR OPS--------------------
%2321 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2322 = "linalg.matmul"(%2320, %2319, %2321) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2323 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2324 = "arith.addf"(%arg400, %2323) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2324) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_264
Type: OpType.ReshapeType
Arguments: ['mm_51', [1, 1, 1536]]
Parents: ['mm_51']
Children: ['add_78']
--------------------MLIR OPS--------------------
%2323 = "tosa.reshape"(%2322) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_78
Type: OpType.BroadcastType
Arguments: ['add_76', 'view_264']
Parents: ['add_76', 'view_264']
Children: ['pow_27', 'mul_132', 'add_82']
--------------------MLIR OPS--------------------
%2324 = "tosa.add"(%2288, %2323) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_27
Type: OpType.BroadcastType
Arguments: ['add_78', 2]
Parents: ['add_78']
Children: ['mean_26']
--------------------MLIR OPS--------------------
%2325 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2326 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2327 = "linalg.generic"(%2324, %2325) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2328 = "math.fpowi"(%arg398, %2326) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2328) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_26
Type: OpType.ReduceType
Arguments: ['pow_27', [-1], True]
Parents: ['pow_27']
Children: ['add_79']
--------------------MLIR OPS--------------------
%2328 = "tosa.reduce_sum"(%2327) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2329 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2330 = "tosa.reciprocal"(%2329) : (tensor<1xf32>) -> tensor<1xf32>
%2331 = "tosa.reshape"(%2330) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%2332 = "tosa.mul"(%2331, %2328) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_79
Type: OpType.BroadcastType
Arguments: ['mean_26', 1e-06]
Parents: ['mean_26']
Children: ['rsqrt_26']
--------------------MLIR OPS--------------------
%2333 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%2334 = "tosa.add"(%2332, %2333) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_26
Type: OpType.ElementwiseType
Arguments: ['add_79']
Parents: ['add_79']
Children: ['mul_132']
--------------------MLIR OPS--------------------
%2335 = "tosa.rsqrt"(%2334) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_132
Type: OpType.BroadcastType
Arguments: ['add_78', 'rsqrt_26']
Parents: ['add_78', 'rsqrt_26']
Children: ['mul_133']
--------------------MLIR OPS--------------------
%2336 = "tosa.mul"(%2324, %2335) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_133
Type: OpType.BroadcastType
Arguments: ['arg216_1', 'mul_132']
Parents: ['arg216_1', 'mul_132']
Children: ['view_265', 'view_268', 'view_271']
--------------------MLIR OPS--------------------
%2337 = "tosa.reshape"(%arg186) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%2338 = "tosa.mul"(%2337, %2336) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_265
Type: OpType.ReshapeType
Arguments: ['mul_133', [1, 1536]]
Parents: ['mul_133']
Children: ['addmm_39']
--------------------MLIR OPS--------------------
%2339 = "tosa.reshape"(%2338) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_144
Type: OpType.ReshapeType
Arguments: ['arg217_1', [1, 0]]
Parents: ['arg217_1']
Children: ['addmm_39']
--------------------MLIR OPS--------------------
%2340 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2341 = "tosa.transpose"(%arg187, %2340) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_39
Type: OpType.ReduceType
Arguments: ['arg218_1', 'view_265', 'permute_144']
Parents: ['arg218_1', 'view_265', 'permute_144']
Children: ['view_266']
--------------------MLIR OPS--------------------
%2342 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2343 = "linalg.matmul"(%2339, %2341, %2342) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2346 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2347 = "arith.addf"(%arg400, %2346) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2347) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%2344 = "tosa.reshape"(%arg188) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%2345 = "tosa.add"(%2344, %2343) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_266
Type: OpType.ReshapeType
Arguments: ['addmm_39', [1, 1, 1536]]
Parents: ['addmm_39']
Children: ['view_267']
--------------------MLIR OPS--------------------
%2346 = "tosa.reshape"(%2345) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_267
Type: OpType.ReshapeType
Arguments: ['view_266', [1, 1, -1, 128]]
Parents: ['view_266']
Children: ['permute_145']
--------------------MLIR OPS--------------------
%2347 = "tosa.reshape"(%2346) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_145
Type: OpType.ReshapeType
Arguments: ['view_267', [0, 2, 1, 3]]
Parents: ['view_267']
Children: ['mul_134', 'slice_303', 'slice_304']
--------------------MLIR OPS--------------------
%2348 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2349 = "tosa.transpose"(%2347, %2348) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_268
Type: OpType.ReshapeType
Arguments: ['mul_133', [1, 1536]]
Parents: ['mul_133']
Children: ['addmm_40']
--------------------MLIR OPS--------------------
%2350 = "tosa.reshape"(%2338) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_146
Type: OpType.ReshapeType
Arguments: ['arg219_1', [1, 0]]
Parents: ['arg219_1']
Children: ['addmm_40']
--------------------MLIR OPS--------------------
%2351 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2352 = "tosa.transpose"(%arg189, %2351) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_40
Type: OpType.ReduceType
Arguments: ['arg220_1', 'view_268', 'permute_146']
Parents: ['arg220_1', 'view_268', 'permute_146']
Children: ['view_269']
--------------------MLIR OPS--------------------
%2353 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2354 = "linalg.matmul"(%2350, %2352, %2353) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2357 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2358 = "arith.addf"(%arg400, %2357) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2358) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2355 = "tosa.reshape"(%arg190) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2356 = "tosa.add"(%2355, %2354) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_269
Type: OpType.ReshapeType
Arguments: ['addmm_40', [1, 1, 256]]
Parents: ['addmm_40']
Children: ['view_270']
--------------------MLIR OPS--------------------
%2357 = "tosa.reshape"(%2356) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_270
Type: OpType.ReshapeType
Arguments: ['view_269', [1, 1, -1, 128]]
Parents: ['view_269']
Children: ['permute_147']
--------------------MLIR OPS--------------------
%2358 = "tosa.reshape"(%2357) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_147
Type: OpType.ReshapeType
Arguments: ['view_270', [0, 2, 1, 3]]
Parents: ['view_270']
Children: ['mul_136', 'slice_305', 'slice_306']
--------------------MLIR OPS--------------------
%2359 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2360 = "tosa.transpose"(%2358, %2359) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_271
Type: OpType.ReshapeType
Arguments: ['mul_133', [1, 1536]]
Parents: ['mul_133']
Children: ['addmm_41']
--------------------MLIR OPS--------------------
%2361 = "tosa.reshape"(%2338) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_148
Type: OpType.ReshapeType
Arguments: ['arg221_1', [1, 0]]
Parents: ['arg221_1']
Children: ['addmm_41']
--------------------MLIR OPS--------------------
%2362 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2363 = "tosa.transpose"(%arg191, %2362) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_41
Type: OpType.ReduceType
Arguments: ['arg222_1', 'view_271', 'permute_148']
Parents: ['arg222_1', 'view_271', 'permute_148']
Children: ['view_272']
--------------------MLIR OPS--------------------
%2364 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2365 = "linalg.matmul"(%2361, %2363, %2364) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2368 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2369 = "arith.addf"(%arg400, %2368) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2369) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2366 = "tosa.reshape"(%arg192) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2367 = "tosa.add"(%2366, %2365) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_272
Type: OpType.ReshapeType
Arguments: ['addmm_41', [1, 1, 256]]
Parents: ['addmm_41']
Children: ['view_273']
--------------------MLIR OPS--------------------
%2368 = "tosa.reshape"(%2367) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_273
Type: OpType.ReshapeType
Arguments: ['view_272', [1, 1, -1, 128]]
Parents: ['view_272']
Children: ['permute_149']
--------------------MLIR OPS--------------------
%2369 = "tosa.reshape"(%2368) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_149
Type: OpType.ReshapeType
Arguments: ['view_273', [0, 2, 1, 3]]
Parents: ['view_273']
Children: ['index_put_27']
--------------------MLIR OPS--------------------
%2370 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2371 = "tosa.transpose"(%2369, %2370) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_83
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_134', 'mul_136']
--------------------MLIR OPS--------------------
%2372 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_84
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_135', 'mul_137']
--------------------MLIR OPS--------------------
%2373 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_134
Type: OpType.BroadcastType
Arguments: ['permute_145', 'unsqueeze_83']
Parents: ['permute_145', 'unsqueeze_83']
Children: ['add_80']
--------------------MLIR OPS--------------------
%2374 = "tosa.mul"(%2349, %2372) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_303
Type: OpType.ReshapeType
Arguments: ['permute_145', 3, 0, 64]
Parents: ['permute_145']
Children: ['cat_26']
--------------------MLIR OPS--------------------
%2375 = "tensor.extract_slice"(%2349) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_304
Type: OpType.ReshapeType
Arguments: ['permute_145', 3, 64, 9223372036854775807]
Parents: ['permute_145']
Children: ['neg_26']
--------------------MLIR OPS--------------------
%2376 = "tensor.extract_slice"(%2349) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_26
Type: OpType.ElementwiseType
Arguments: ['slice_304']
Parents: ['slice_304']
Children: ['cat_26']
--------------------MLIR OPS--------------------
%2377 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%2378 = "linalg.negf"(%2376, %2377) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2379 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2379) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_26
Type: OpType.ConcatType
Arguments: [[neg_26, slice_303], -1]
Parents: []
Children: ['mul_135']
--------------------MLIR OPS--------------------
%2379 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%2380 = "tensor.insert_slice"(%2378, %2379) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%2381 = "tensor.insert_slice"(%2375, %2380) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_135
Type: OpType.BroadcastType
Arguments: ['cat_26', 'unsqueeze_84']
Parents: ['cat_26', 'unsqueeze_84']
Children: ['add_80']
--------------------MLIR OPS--------------------
%2382 = "tosa.mul"(%2381, %2373) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_80
Type: OpType.BroadcastType
Arguments: ['mul_134', 'mul_135']
Parents: ['mul_134', 'mul_135']
Children: ['_scaled_dot_product_flash_attention_for_cpu_13']
--------------------MLIR OPS--------------------
%2383 = "tosa.add"(%2374, %2382) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_136
Type: OpType.BroadcastType
Arguments: ['permute_147', 'unsqueeze_83']
Parents: ['permute_147', 'unsqueeze_83']
Children: ['add_81']
--------------------MLIR OPS--------------------
%2384 = "tosa.mul"(%2360, %2372) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_305
Type: OpType.ReshapeType
Arguments: ['permute_147', 3, 0, 64]
Parents: ['permute_147']
Children: ['cat_27']
--------------------MLIR OPS--------------------
%2385 = "tensor.extract_slice"(%2360) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_306
Type: OpType.ReshapeType
Arguments: ['permute_147', 3, 64, 9223372036854775807]
Parents: ['permute_147']
Children: ['neg_27']
--------------------MLIR OPS--------------------
%2386 = "tensor.extract_slice"(%2360) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_27
Type: OpType.ElementwiseType
Arguments: ['slice_306']
Parents: ['slice_306']
Children: ['cat_27']
--------------------MLIR OPS--------------------
%2387 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%2388 = "linalg.negf"(%2386, %2387) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2389 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2389) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_27
Type: OpType.ConcatType
Arguments: [[neg_27, slice_305], -1]
Parents: []
Children: ['mul_137']
--------------------MLIR OPS--------------------
%2389 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%2390 = "tensor.insert_slice"(%2388, %2389) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%2391 = "tensor.insert_slice"(%2385, %2390) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_137
Type: OpType.BroadcastType
Arguments: ['cat_27', 'unsqueeze_84']
Parents: ['cat_27', 'unsqueeze_84']
Children: ['add_81']
--------------------MLIR OPS--------------------
%2392 = "tosa.mul"(%2391, %2373) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_81
Type: OpType.BroadcastType
Arguments: ['mul_136', 'mul_137']
Parents: ['mul_136', 'mul_137']
Children: ['index_put_26']
--------------------MLIR OPS--------------------
%2393 = "tosa.add"(%2384, %2392) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_26
Type: OpType.ElementwiseType
Arguments: ['arg26_1', [None, None, arg58_1], 'add_81']
Parents: ['arg26_1', 'add_81']
Children: ['slice_311', 'output']
--------------------MLIR OPS--------------------
%2394 = "bufferization.to_memref"(%arg193) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2395 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2396 = "bufferization.to_memref"(%2393) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2397 = "arith.constant"() <{value = 0 : index}> : () -> index
%2398 = "arith.constant"() <{value = 1 : index}> : () -> index
%2399 = "arith.constant"() <{value = 1 : index}> : () -> index
%2400 = "arith.constant"() <{value = 2 : index}> : () -> index
%2401 = "arith.constant"() <{value = 1 : index}> : () -> index
%2402 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2397, %2399, %2398) ({
^bb0(%arg398: index):
  "scf.for"(%2397, %2400, %2398) ({
  ^bb0(%arg399: index):
    "scf.for"(%2397, %2401, %2398) ({
    ^bb0(%arg400: index):
      %2404 = "memref.load"(%2395, %arg400) : (memref<1xi64>, index) -> i64
      %2405 = "arith.index_cast"(%2404) : (i64) -> index
      "scf.for"(%2397, %2402, %2398) ({
      ^bb0(%arg401: index):
        %2406 = "memref.load"(%2396, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2406, %2394, %arg398, %arg399, %2405, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2403 = "bufferization.to_tensor"(%2394) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_27
Type: OpType.ElementwiseType
Arguments: ['arg27_1', [None, None, arg58_1], 'permute_149']
Parents: ['arg27_1', 'permute_149']
Children: ['slice_319', 'output']
--------------------MLIR OPS--------------------
%2404 = "bufferization.to_memref"(%arg194) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2405 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2406 = "bufferization.to_memref"(%2371) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2407 = "arith.constant"() <{value = 0 : index}> : () -> index
%2408 = "arith.constant"() <{value = 1 : index}> : () -> index
%2409 = "arith.constant"() <{value = 1 : index}> : () -> index
%2410 = "arith.constant"() <{value = 2 : index}> : () -> index
%2411 = "arith.constant"() <{value = 1 : index}> : () -> index
%2412 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2407, %2409, %2408) ({
^bb0(%arg398: index):
  "scf.for"(%2407, %2410, %2408) ({
  ^bb0(%arg399: index):
    "scf.for"(%2407, %2411, %2408) ({
    ^bb0(%arg400: index):
      %2414 = "memref.load"(%2405, %arg400) : (memref<1xi64>, index) -> i64
      %2415 = "arith.index_cast"(%2414) : (i64) -> index
      "scf.for"(%2407, %2412, %2408) ({
      ^bb0(%arg401: index):
        %2416 = "memref.load"(%2406, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2416, %2404, %arg398, %arg399, %2415, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2413 = "bufferization.to_tensor"(%2404) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_311
Type: OpType.ReshapeType
Arguments: ['index_put_26', 0, 0, 9223372036854775807]
Parents: ['index_put_26']
Children: ['slice_312']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_312
Type: OpType.ReshapeType
Arguments: ['slice_311', 1, 0, 9223372036854775807]
Parents: ['slice_311']
Children: ['unsqueeze_86']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_86
Type: OpType.ReshapeType
Arguments: ['slice_312', 2]
Parents: ['slice_312']
Children: ['slice_313']
--------------------MLIR OPS--------------------
%2414 = "tosa.reshape"(%2403) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_313
Type: OpType.ReshapeType
Arguments: ['unsqueeze_86', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_86']
Children: ['slice_314']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_314
Type: OpType.ReshapeType
Arguments: ['slice_313', 4, 0, 9223372036854775807]
Parents: ['slice_313']
Children: ['expand_59']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_59
Type: OpType.ReshapeType
Arguments: ['slice_314', [1, 2, 6, 1024, 128]]
Parents: ['slice_314']
Children: ['clone_28']
--------------------MLIR OPS--------------------
%2415 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2416 = "tosa.add"(%2414, %2415) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_28
Type: OpType.ReduceType
Arguments: ['expand_59']
Parents: ['expand_59']
Children: ['view_274']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_274
Type: OpType.ReshapeType
Arguments: ['clone_28', [1, 12, 1024, 128]]
Parents: ['clone_28']
Children: ['_scaled_dot_product_flash_attention_for_cpu_13']
--------------------MLIR OPS--------------------
%2417 = "tosa.reshape"(%2416) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_319
Type: OpType.ReshapeType
Arguments: ['index_put_27', 0, 0, 9223372036854775807]
Parents: ['index_put_27']
Children: ['slice_320']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_320
Type: OpType.ReshapeType
Arguments: ['slice_319', 1, 0, 9223372036854775807]
Parents: ['slice_319']
Children: ['unsqueeze_88']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_88
Type: OpType.ReshapeType
Arguments: ['slice_320', 2]
Parents: ['slice_320']
Children: ['slice_321']
--------------------MLIR OPS--------------------
%2418 = "tosa.reshape"(%2413) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_321
Type: OpType.ReshapeType
Arguments: ['unsqueeze_88', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_88']
Children: ['slice_322']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_322
Type: OpType.ReshapeType
Arguments: ['slice_321', 4, 0, 9223372036854775807]
Parents: ['slice_321']
Children: ['expand_61']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_61
Type: OpType.ReshapeType
Arguments: ['slice_322', [1, 2, 6, 1024, 128]]
Parents: ['slice_322']
Children: ['clone_29']
--------------------MLIR OPS--------------------
%2419 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2420 = "tosa.add"(%2418, %2419) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_29
Type: OpType.ReduceType
Arguments: ['expand_61']
Parents: ['expand_61']
Children: ['view_275']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_275
Type: OpType.ReshapeType
Arguments: ['clone_29', [1, 12, 1024, 128]]
Parents: ['clone_29']
Children: ['_scaled_dot_product_flash_attention_for_cpu_13']
--------------------MLIR OPS--------------------
%2421 = "tosa.reshape"(%2420) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_323
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_324']
--------------------MLIR OPS--------------------
%2422 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_324
Type: OpType.ReshapeType
Arguments: ['slice_323', 1, 0, 9223372036854775807]
Parents: ['slice_323']
Children: ['slice_325']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_325
Type: OpType.ReshapeType
Arguments: ['slice_324', 2, 0, 9223372036854775807]
Parents: ['slice_324']
Children: ['where_13']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_26
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_13']
--------------------MLIR OPS--------------------
%2423 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_27
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_13']
--------------------MLIR OPS--------------------
%2424 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_13
Type: OpType.ElementwiseType
Arguments: ['slice_325', 'scalar_tensor_27', 'scalar_tensor_26']
Parents: ['slice_325', 'scalar_tensor_27', 'scalar_tensor_26']
Children: ['_scaled_dot_product_flash_attention_for_cpu_13']
--------------------MLIR OPS--------------------
%2425 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%2426 = "tensor.splat"(%2424) : (f32) -> tensor<1x1x1x1024xf32>
%2427 = "tensor.splat"(%2423) : (f32) -> tensor<1x1x1x1024xf32>
%2428 = "linalg.generic"(%2422, %2426, %2427, %2425) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %2429 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%2429) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_13
Type: OpType.ElementwiseType
Arguments: ['add_80', 'view_274', 'view_275']
Parents: ['add_80', 'view_274', 'view_275']
Children: ['getitem_26']
--------------------MLIR OPS--------------------
%2429 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%2430 = "tensor.splat"(%2429) : (f32) -> tensor<1x1024xf32>
%2431 = "tosa.reshape"(%2428) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%2432 = "tosa.add"(%2430, %2431) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%2433 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2434 = "tosa.transpose"(%2417, %2433) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%2435 = "tosa.reshape"(%2383) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%2436 = "tosa.reshape"(%2434) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%2437 = "tosa.matmul"(%2435, %2436) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%2438 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%2439 = "tensor.splat"(%2438) : (f32) -> tensor<12x1x1024xf32>
%2440 = "tosa.mul"(%2437, %2439) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2441 = "tosa.reshape"(%2432) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%2442 = "tosa.add"(%2440, %2441) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%2443 = "tosa.reduce_max"(%2442) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2444 = "tosa.sub"(%2442, %2443) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2445 = "math.exp"(%2444) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2446 = "tosa.reduce_sum"(%2445) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2447 = "tosa.log"(%2446) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2448 = "tosa.add"(%2443, %2447) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2449 = "tosa.sub"(%2442, %2448) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2450 = "math.exp"(%2449) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2451 = "tosa.reshape"(%2448) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%2452 = "tosa.reshape"(%2421) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%2453 = "tosa.matmul"(%2450, %2452) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%2454 = "tosa.reshape"(%2453) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_26
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_13', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_13']
Children: ['permute_150']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_150
Type: OpType.ReshapeType
Arguments: ['getitem_26', [0, 2, 1, 3]]
Parents: ['getitem_26']
Children: ['view_276']
--------------------MLIR OPS--------------------
%2455 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2456 = "tosa.transpose"(%2454, %2455) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_276
Type: OpType.ReshapeType
Arguments: ['permute_150', [1, 1, -1]]
Parents: ['permute_150']
Children: ['view_277']
--------------------MLIR OPS--------------------
%2457 = "tosa.reshape"(%2456) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_151
Type: OpType.ReshapeType
Arguments: ['arg223_1', [1, 0]]
Parents: ['arg223_1']
Children: ['mm_52']
--------------------MLIR OPS--------------------
%2458 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2459 = "tosa.transpose"(%arg195, %2458) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_277
Type: OpType.ReshapeType
Arguments: ['view_276', [1, 1536]]
Parents: ['view_276']
Children: ['mm_52']
--------------------MLIR OPS--------------------
%2460 = "tosa.reshape"(%2457) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_52
Type: OpType.ReduceType
Arguments: ['view_277', 'permute_151']
Parents: ['view_277', 'permute_151']
Children: ['view_278']
--------------------MLIR OPS--------------------
%2461 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2462 = "linalg.matmul"(%2460, %2459, %2461) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2463 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2464 = "arith.addf"(%arg400, %2463) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2464) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_278
Type: OpType.ReshapeType
Arguments: ['mm_52', [1, 1, 1536]]
Parents: ['mm_52']
Children: ['add_82']
--------------------MLIR OPS--------------------
%2463 = "tosa.reshape"(%2462) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_82
Type: OpType.BroadcastType
Arguments: ['add_78', 'view_278']
Parents: ['add_78', 'view_278']
Children: ['pow_28', 'mul_138', 'add_84']
--------------------MLIR OPS--------------------
%2464 = "tosa.add"(%2324, %2463) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_28
Type: OpType.BroadcastType
Arguments: ['add_82', 2]
Parents: ['add_82']
Children: ['mean_27']
--------------------MLIR OPS--------------------
%2465 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2466 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2467 = "linalg.generic"(%2464, %2465) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2468 = "math.fpowi"(%arg398, %2466) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2468) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_27
Type: OpType.ReduceType
Arguments: ['pow_28', [-1], True]
Parents: ['pow_28']
Children: ['add_83']
--------------------MLIR OPS--------------------
%2468 = "tosa.reduce_sum"(%2467) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2469 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2470 = "tosa.reciprocal"(%2469) : (tensor<1xf32>) -> tensor<1xf32>
%2471 = "tosa.reshape"(%2470) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%2472 = "tosa.mul"(%2471, %2468) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_83
Type: OpType.BroadcastType
Arguments: ['mean_27', 1e-06]
Parents: ['mean_27']
Children: ['rsqrt_27']
--------------------MLIR OPS--------------------
%2473 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%2474 = "tosa.add"(%2472, %2473) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_27
Type: OpType.ElementwiseType
Arguments: ['add_83']
Parents: ['add_83']
Children: ['mul_138']
--------------------MLIR OPS--------------------
%2475 = "tosa.rsqrt"(%2474) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_138
Type: OpType.BroadcastType
Arguments: ['add_82', 'rsqrt_27']
Parents: ['add_82', 'rsqrt_27']
Children: ['mul_139']
--------------------MLIR OPS--------------------
%2476 = "tosa.mul"(%2464, %2475) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_139
Type: OpType.BroadcastType
Arguments: ['arg224_1', 'mul_138']
Parents: ['arg224_1', 'mul_138']
Children: ['view_279', 'view_281']
--------------------MLIR OPS--------------------
%2477 = "tosa.reshape"(%arg196) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%2478 = "tosa.mul"(%2477, %2476) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_152
Type: OpType.ReshapeType
Arguments: ['arg225_1', [1, 0]]
Parents: ['arg225_1']
Children: ['mm_53']
--------------------MLIR OPS--------------------
%2479 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2480 = "tosa.transpose"(%arg197, %2479) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_279
Type: OpType.ReshapeType
Arguments: ['mul_139', [1, 1536]]
Parents: ['mul_139']
Children: ['mm_53']
--------------------MLIR OPS--------------------
%2481 = "tosa.reshape"(%2478) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_53
Type: OpType.ReduceType
Arguments: ['view_279', 'permute_152']
Parents: ['view_279', 'permute_152']
Children: ['view_280']
--------------------MLIR OPS--------------------
%2482 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%2483 = "linalg.matmul"(%2481, %2480, %2482) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2484 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2485 = "arith.addf"(%arg400, %2484) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2485) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_280
Type: OpType.ReshapeType
Arguments: ['mm_53', [1, 1, 8960]]
Parents: ['mm_53']
Children: ['sigmoid_13', 'mul_140']
--------------------MLIR OPS--------------------
%2484 = "tosa.reshape"(%2483) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_13
Type: OpType.ElementwiseType
Arguments: ['view_280']
Parents: ['view_280']
Children: ['mul_140']
--------------------MLIR OPS--------------------
%2485 = "tosa.sigmoid"(%2484) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_140
Type: OpType.BroadcastType
Arguments: ['view_280', 'sigmoid_13']
Parents: ['view_280', 'sigmoid_13']
Children: ['mul_141']
--------------------MLIR OPS--------------------
%2486 = "tosa.mul"(%2484, %2485) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_153
Type: OpType.ReshapeType
Arguments: ['arg226_1', [1, 0]]
Parents: ['arg226_1']
Children: ['mm_54']
--------------------MLIR OPS--------------------
%2487 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2488 = "tosa.transpose"(%arg198, %2487) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_281
Type: OpType.ReshapeType
Arguments: ['mul_139', [1, 1536]]
Parents: ['mul_139']
Children: ['mm_54']
--------------------MLIR OPS--------------------
%2489 = "tosa.reshape"(%2478) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_54
Type: OpType.ReduceType
Arguments: ['view_281', 'permute_153']
Parents: ['view_281', 'permute_153']
Children: ['view_282']
--------------------MLIR OPS--------------------
%2490 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%2491 = "linalg.matmul"(%2489, %2488, %2490) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2492 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2493 = "arith.addf"(%arg400, %2492) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2493) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_282
Type: OpType.ReshapeType
Arguments: ['mm_54', [1, 1, 8960]]
Parents: ['mm_54']
Children: ['mul_141']
--------------------MLIR OPS--------------------
%2492 = "tosa.reshape"(%2491) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_141
Type: OpType.BroadcastType
Arguments: ['mul_140', 'view_282']
Parents: ['mul_140', 'view_282']
Children: ['view_283']
--------------------MLIR OPS--------------------
%2493 = "tosa.mul"(%2486, %2492) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_154
Type: OpType.ReshapeType
Arguments: ['arg227_1', [1, 0]]
Parents: ['arg227_1']
Children: ['mm_55']
--------------------MLIR OPS--------------------
%2494 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2495 = "tosa.transpose"(%arg199, %2494) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_283
Type: OpType.ReshapeType
Arguments: ['mul_141', [1, 8960]]
Parents: ['mul_141']
Children: ['mm_55']
--------------------MLIR OPS--------------------
%2496 = "tosa.reshape"(%2493) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_55
Type: OpType.ReduceType
Arguments: ['view_283', 'permute_154']
Parents: ['view_283', 'permute_154']
Children: ['view_284']
--------------------MLIR OPS--------------------
%2497 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2498 = "linalg.matmul"(%2496, %2495, %2497) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2499 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2500 = "arith.addf"(%arg400, %2499) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2500) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_284
Type: OpType.ReshapeType
Arguments: ['mm_55', [1, 1, 1536]]
Parents: ['mm_55']
Children: ['add_84']
--------------------MLIR OPS--------------------
%2499 = "tosa.reshape"(%2498) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_84
Type: OpType.BroadcastType
Arguments: ['add_82', 'view_284']
Parents: ['add_82', 'view_284']
Children: ['pow_29', 'mul_142', 'add_88']
--------------------MLIR OPS--------------------
%2500 = "tosa.add"(%2464, %2499) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_29
Type: OpType.BroadcastType
Arguments: ['add_84', 2]
Parents: ['add_84']
Children: ['mean_28']
--------------------MLIR OPS--------------------
%2501 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2502 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2503 = "linalg.generic"(%2500, %2501) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2504 = "math.fpowi"(%arg398, %2502) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2504) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_28
Type: OpType.ReduceType
Arguments: ['pow_29', [-1], True]
Parents: ['pow_29']
Children: ['add_85']
--------------------MLIR OPS--------------------
%2504 = "tosa.reduce_sum"(%2503) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2505 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2506 = "tosa.reciprocal"(%2505) : (tensor<1xf32>) -> tensor<1xf32>
%2507 = "tosa.reshape"(%2506) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%2508 = "tosa.mul"(%2507, %2504) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_85
Type: OpType.BroadcastType
Arguments: ['mean_28', 1e-06]
Parents: ['mean_28']
Children: ['rsqrt_28']
--------------------MLIR OPS--------------------
%2509 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%2510 = "tosa.add"(%2508, %2509) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_28
Type: OpType.ElementwiseType
Arguments: ['add_85']
Parents: ['add_85']
Children: ['mul_142']
--------------------MLIR OPS--------------------
%2511 = "tosa.rsqrt"(%2510) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_142
Type: OpType.BroadcastType
Arguments: ['add_84', 'rsqrt_28']
Parents: ['add_84', 'rsqrt_28']
Children: ['mul_143']
--------------------MLIR OPS--------------------
%2512 = "tosa.mul"(%2500, %2511) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_143
Type: OpType.BroadcastType
Arguments: ['arg228_1', 'mul_142']
Parents: ['arg228_1', 'mul_142']
Children: ['view_285', 'view_288', 'view_291']
--------------------MLIR OPS--------------------
%2513 = "tosa.reshape"(%arg200) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%2514 = "tosa.mul"(%2513, %2512) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_285
Type: OpType.ReshapeType
Arguments: ['mul_143', [1, 1536]]
Parents: ['mul_143']
Children: ['addmm_42']
--------------------MLIR OPS--------------------
%2515 = "tosa.reshape"(%2514) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_155
Type: OpType.ReshapeType
Arguments: ['arg229_1', [1, 0]]
Parents: ['arg229_1']
Children: ['addmm_42']
--------------------MLIR OPS--------------------
%2516 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2517 = "tosa.transpose"(%arg201, %2516) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_42
Type: OpType.ReduceType
Arguments: ['arg230_1', 'view_285', 'permute_155']
Parents: ['arg230_1', 'view_285', 'permute_155']
Children: ['view_286']
--------------------MLIR OPS--------------------
%2518 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2519 = "linalg.matmul"(%2515, %2517, %2518) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2522 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2523 = "arith.addf"(%arg400, %2522) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2523) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%2520 = "tosa.reshape"(%arg202) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%2521 = "tosa.add"(%2520, %2519) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_286
Type: OpType.ReshapeType
Arguments: ['addmm_42', [1, 1, 1536]]
Parents: ['addmm_42']
Children: ['view_287']
--------------------MLIR OPS--------------------
%2522 = "tosa.reshape"(%2521) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_287
Type: OpType.ReshapeType
Arguments: ['view_286', [1, 1, -1, 128]]
Parents: ['view_286']
Children: ['permute_156']
--------------------MLIR OPS--------------------
%2523 = "tosa.reshape"(%2522) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_156
Type: OpType.ReshapeType
Arguments: ['view_287', [0, 2, 1, 3]]
Parents: ['view_287']
Children: ['mul_144', 'slice_326', 'slice_327']
--------------------MLIR OPS--------------------
%2524 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2525 = "tosa.transpose"(%2523, %2524) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_288
Type: OpType.ReshapeType
Arguments: ['mul_143', [1, 1536]]
Parents: ['mul_143']
Children: ['addmm_43']
--------------------MLIR OPS--------------------
%2526 = "tosa.reshape"(%2514) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_157
Type: OpType.ReshapeType
Arguments: ['arg231_1', [1, 0]]
Parents: ['arg231_1']
Children: ['addmm_43']
--------------------MLIR OPS--------------------
%2527 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2528 = "tosa.transpose"(%arg203, %2527) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_43
Type: OpType.ReduceType
Arguments: ['arg232_1', 'view_288', 'permute_157']
Parents: ['arg232_1', 'view_288', 'permute_157']
Children: ['view_289']
--------------------MLIR OPS--------------------
%2529 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2530 = "linalg.matmul"(%2526, %2528, %2529) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2533 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2534 = "arith.addf"(%arg400, %2533) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2534) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2531 = "tosa.reshape"(%arg204) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2532 = "tosa.add"(%2531, %2530) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_289
Type: OpType.ReshapeType
Arguments: ['addmm_43', [1, 1, 256]]
Parents: ['addmm_43']
Children: ['view_290']
--------------------MLIR OPS--------------------
%2533 = "tosa.reshape"(%2532) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_290
Type: OpType.ReshapeType
Arguments: ['view_289', [1, 1, -1, 128]]
Parents: ['view_289']
Children: ['permute_158']
--------------------MLIR OPS--------------------
%2534 = "tosa.reshape"(%2533) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_158
Type: OpType.ReshapeType
Arguments: ['view_290', [0, 2, 1, 3]]
Parents: ['view_290']
Children: ['mul_146', 'slice_328', 'slice_329']
--------------------MLIR OPS--------------------
%2535 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2536 = "tosa.transpose"(%2534, %2535) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_291
Type: OpType.ReshapeType
Arguments: ['mul_143', [1, 1536]]
Parents: ['mul_143']
Children: ['addmm_44']
--------------------MLIR OPS--------------------
%2537 = "tosa.reshape"(%2514) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_159
Type: OpType.ReshapeType
Arguments: ['arg233_1', [1, 0]]
Parents: ['arg233_1']
Children: ['addmm_44']
--------------------MLIR OPS--------------------
%2538 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2539 = "tosa.transpose"(%arg205, %2538) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_44
Type: OpType.ReduceType
Arguments: ['arg234_1', 'view_291', 'permute_159']
Parents: ['arg234_1', 'view_291', 'permute_159']
Children: ['view_292']
--------------------MLIR OPS--------------------
%2540 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2541 = "linalg.matmul"(%2537, %2539, %2540) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2544 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2545 = "arith.addf"(%arg400, %2544) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2545) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2542 = "tosa.reshape"(%arg206) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2543 = "tosa.add"(%2542, %2541) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_292
Type: OpType.ReshapeType
Arguments: ['addmm_44', [1, 1, 256]]
Parents: ['addmm_44']
Children: ['view_293']
--------------------MLIR OPS--------------------
%2544 = "tosa.reshape"(%2543) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_293
Type: OpType.ReshapeType
Arguments: ['view_292', [1, 1, -1, 128]]
Parents: ['view_292']
Children: ['permute_160']
--------------------MLIR OPS--------------------
%2545 = "tosa.reshape"(%2544) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_160
Type: OpType.ReshapeType
Arguments: ['view_293', [0, 2, 1, 3]]
Parents: ['view_293']
Children: ['index_put_29']
--------------------MLIR OPS--------------------
%2546 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2547 = "tosa.transpose"(%2545, %2546) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_89
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_144', 'mul_146']
--------------------MLIR OPS--------------------
%2548 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_90
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_145', 'mul_147']
--------------------MLIR OPS--------------------
%2549 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_144
Type: OpType.BroadcastType
Arguments: ['permute_156', 'unsqueeze_89']
Parents: ['permute_156', 'unsqueeze_89']
Children: ['add_86']
--------------------MLIR OPS--------------------
%2550 = "tosa.mul"(%2525, %2548) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_326
Type: OpType.ReshapeType
Arguments: ['permute_156', 3, 0, 64]
Parents: ['permute_156']
Children: ['cat_28']
--------------------MLIR OPS--------------------
%2551 = "tensor.extract_slice"(%2525) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_327
Type: OpType.ReshapeType
Arguments: ['permute_156', 3, 64, 9223372036854775807]
Parents: ['permute_156']
Children: ['neg_28']
--------------------MLIR OPS--------------------
%2552 = "tensor.extract_slice"(%2525) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_28
Type: OpType.ElementwiseType
Arguments: ['slice_327']
Parents: ['slice_327']
Children: ['cat_28']
--------------------MLIR OPS--------------------
%2553 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%2554 = "linalg.negf"(%2552, %2553) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2555 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2555) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_28
Type: OpType.ConcatType
Arguments: [[neg_28, slice_326], -1]
Parents: []
Children: ['mul_145']
--------------------MLIR OPS--------------------
%2555 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%2556 = "tensor.insert_slice"(%2554, %2555) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%2557 = "tensor.insert_slice"(%2551, %2556) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_145
Type: OpType.BroadcastType
Arguments: ['cat_28', 'unsqueeze_90']
Parents: ['cat_28', 'unsqueeze_90']
Children: ['add_86']
--------------------MLIR OPS--------------------
%2558 = "tosa.mul"(%2557, %2549) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_86
Type: OpType.BroadcastType
Arguments: ['mul_144', 'mul_145']
Parents: ['mul_144', 'mul_145']
Children: ['_scaled_dot_product_flash_attention_for_cpu_14']
--------------------MLIR OPS--------------------
%2559 = "tosa.add"(%2550, %2558) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_146
Type: OpType.BroadcastType
Arguments: ['permute_158', 'unsqueeze_89']
Parents: ['permute_158', 'unsqueeze_89']
Children: ['add_87']
--------------------MLIR OPS--------------------
%2560 = "tosa.mul"(%2536, %2548) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_328
Type: OpType.ReshapeType
Arguments: ['permute_158', 3, 0, 64]
Parents: ['permute_158']
Children: ['cat_29']
--------------------MLIR OPS--------------------
%2561 = "tensor.extract_slice"(%2536) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_329
Type: OpType.ReshapeType
Arguments: ['permute_158', 3, 64, 9223372036854775807]
Parents: ['permute_158']
Children: ['neg_29']
--------------------MLIR OPS--------------------
%2562 = "tensor.extract_slice"(%2536) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_29
Type: OpType.ElementwiseType
Arguments: ['slice_329']
Parents: ['slice_329']
Children: ['cat_29']
--------------------MLIR OPS--------------------
%2563 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%2564 = "linalg.negf"(%2562, %2563) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2565 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2565) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_29
Type: OpType.ConcatType
Arguments: [[neg_29, slice_328], -1]
Parents: []
Children: ['mul_147']
--------------------MLIR OPS--------------------
%2565 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%2566 = "tensor.insert_slice"(%2564, %2565) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%2567 = "tensor.insert_slice"(%2561, %2566) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_147
Type: OpType.BroadcastType
Arguments: ['cat_29', 'unsqueeze_90']
Parents: ['cat_29', 'unsqueeze_90']
Children: ['add_87']
--------------------MLIR OPS--------------------
%2568 = "tosa.mul"(%2567, %2549) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_87
Type: OpType.BroadcastType
Arguments: ['mul_146', 'mul_147']
Parents: ['mul_146', 'mul_147']
Children: ['index_put_28']
--------------------MLIR OPS--------------------
%2569 = "tosa.add"(%2560, %2568) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_28
Type: OpType.ElementwiseType
Arguments: ['arg28_1', [None, None, arg58_1], 'add_87']
Parents: ['arg28_1', 'add_87']
Children: ['slice_334', 'output']
--------------------MLIR OPS--------------------
%2570 = "bufferization.to_memref"(%arg207) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2571 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2572 = "bufferization.to_memref"(%2569) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2573 = "arith.constant"() <{value = 0 : index}> : () -> index
%2574 = "arith.constant"() <{value = 1 : index}> : () -> index
%2575 = "arith.constant"() <{value = 1 : index}> : () -> index
%2576 = "arith.constant"() <{value = 2 : index}> : () -> index
%2577 = "arith.constant"() <{value = 1 : index}> : () -> index
%2578 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2573, %2575, %2574) ({
^bb0(%arg398: index):
  "scf.for"(%2573, %2576, %2574) ({
  ^bb0(%arg399: index):
    "scf.for"(%2573, %2577, %2574) ({
    ^bb0(%arg400: index):
      %2580 = "memref.load"(%2571, %arg400) : (memref<1xi64>, index) -> i64
      %2581 = "arith.index_cast"(%2580) : (i64) -> index
      "scf.for"(%2573, %2578, %2574) ({
      ^bb0(%arg401: index):
        %2582 = "memref.load"(%2572, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2582, %2570, %arg398, %arg399, %2581, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2579 = "bufferization.to_tensor"(%2570) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_29
Type: OpType.ElementwiseType
Arguments: ['arg29_1', [None, None, arg58_1], 'permute_160']
Parents: ['arg29_1', 'permute_160']
Children: ['slice_342', 'output']
--------------------MLIR OPS--------------------
%2580 = "bufferization.to_memref"(%arg208) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2581 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2582 = "bufferization.to_memref"(%2547) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2583 = "arith.constant"() <{value = 0 : index}> : () -> index
%2584 = "arith.constant"() <{value = 1 : index}> : () -> index
%2585 = "arith.constant"() <{value = 1 : index}> : () -> index
%2586 = "arith.constant"() <{value = 2 : index}> : () -> index
%2587 = "arith.constant"() <{value = 1 : index}> : () -> index
%2588 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2583, %2585, %2584) ({
^bb0(%arg398: index):
  "scf.for"(%2583, %2586, %2584) ({
  ^bb0(%arg399: index):
    "scf.for"(%2583, %2587, %2584) ({
    ^bb0(%arg400: index):
      %2590 = "memref.load"(%2581, %arg400) : (memref<1xi64>, index) -> i64
      %2591 = "arith.index_cast"(%2590) : (i64) -> index
      "scf.for"(%2583, %2588, %2584) ({
      ^bb0(%arg401: index):
        %2592 = "memref.load"(%2582, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2592, %2580, %arg398, %arg399, %2591, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2589 = "bufferization.to_tensor"(%2580) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_334
Type: OpType.ReshapeType
Arguments: ['index_put_28', 0, 0, 9223372036854775807]
Parents: ['index_put_28']
Children: ['slice_335']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_335
Type: OpType.ReshapeType
Arguments: ['slice_334', 1, 0, 9223372036854775807]
Parents: ['slice_334']
Children: ['unsqueeze_92']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_92
Type: OpType.ReshapeType
Arguments: ['slice_335', 2]
Parents: ['slice_335']
Children: ['slice_336']
--------------------MLIR OPS--------------------
%2590 = "tosa.reshape"(%2579) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_336
Type: OpType.ReshapeType
Arguments: ['unsqueeze_92', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_92']
Children: ['slice_337']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_337
Type: OpType.ReshapeType
Arguments: ['slice_336', 4, 0, 9223372036854775807]
Parents: ['slice_336']
Children: ['expand_63']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_63
Type: OpType.ReshapeType
Arguments: ['slice_337', [1, 2, 6, 1024, 128]]
Parents: ['slice_337']
Children: ['clone_30']
--------------------MLIR OPS--------------------
%2591 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2592 = "tosa.add"(%2590, %2591) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_30
Type: OpType.ReduceType
Arguments: ['expand_63']
Parents: ['expand_63']
Children: ['view_294']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_294
Type: OpType.ReshapeType
Arguments: ['clone_30', [1, 12, 1024, 128]]
Parents: ['clone_30']
Children: ['_scaled_dot_product_flash_attention_for_cpu_14']
--------------------MLIR OPS--------------------
%2593 = "tosa.reshape"(%2592) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_342
Type: OpType.ReshapeType
Arguments: ['index_put_29', 0, 0, 9223372036854775807]
Parents: ['index_put_29']
Children: ['slice_343']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_343
Type: OpType.ReshapeType
Arguments: ['slice_342', 1, 0, 9223372036854775807]
Parents: ['slice_342']
Children: ['unsqueeze_94']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_94
Type: OpType.ReshapeType
Arguments: ['slice_343', 2]
Parents: ['slice_343']
Children: ['slice_344']
--------------------MLIR OPS--------------------
%2594 = "tosa.reshape"(%2589) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_344
Type: OpType.ReshapeType
Arguments: ['unsqueeze_94', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_94']
Children: ['slice_345']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_345
Type: OpType.ReshapeType
Arguments: ['slice_344', 4, 0, 9223372036854775807]
Parents: ['slice_344']
Children: ['expand_65']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_65
Type: OpType.ReshapeType
Arguments: ['slice_345', [1, 2, 6, 1024, 128]]
Parents: ['slice_345']
Children: ['clone_31']
--------------------MLIR OPS--------------------
%2595 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2596 = "tosa.add"(%2594, %2595) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_31
Type: OpType.ReduceType
Arguments: ['expand_65']
Parents: ['expand_65']
Children: ['view_295']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_295
Type: OpType.ReshapeType
Arguments: ['clone_31', [1, 12, 1024, 128]]
Parents: ['clone_31']
Children: ['_scaled_dot_product_flash_attention_for_cpu_14']
--------------------MLIR OPS--------------------
%2597 = "tosa.reshape"(%2596) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_346
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_347']
--------------------MLIR OPS--------------------
%2598 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_347
Type: OpType.ReshapeType
Arguments: ['slice_346', 1, 0, 9223372036854775807]
Parents: ['slice_346']
Children: ['slice_348']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_348
Type: OpType.ReshapeType
Arguments: ['slice_347', 2, 0, 9223372036854775807]
Parents: ['slice_347']
Children: ['where_14']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_28
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_14']
--------------------MLIR OPS--------------------
%2599 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_29
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_14']
--------------------MLIR OPS--------------------
%2600 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_14
Type: OpType.ElementwiseType
Arguments: ['slice_348', 'scalar_tensor_29', 'scalar_tensor_28']
Parents: ['slice_348', 'scalar_tensor_29', 'scalar_tensor_28']
Children: ['_scaled_dot_product_flash_attention_for_cpu_14']
--------------------MLIR OPS--------------------
%2601 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%2602 = "tensor.splat"(%2600) : (f32) -> tensor<1x1x1x1024xf32>
%2603 = "tensor.splat"(%2599) : (f32) -> tensor<1x1x1x1024xf32>
%2604 = "linalg.generic"(%2598, %2602, %2603, %2601) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %2605 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%2605) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_14
Type: OpType.ElementwiseType
Arguments: ['add_86', 'view_294', 'view_295']
Parents: ['add_86', 'view_294', 'view_295']
Children: ['getitem_28']
--------------------MLIR OPS--------------------
%2605 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%2606 = "tensor.splat"(%2605) : (f32) -> tensor<1x1024xf32>
%2607 = "tosa.reshape"(%2604) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%2608 = "tosa.add"(%2606, %2607) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%2609 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2610 = "tosa.transpose"(%2593, %2609) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%2611 = "tosa.reshape"(%2559) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%2612 = "tosa.reshape"(%2610) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%2613 = "tosa.matmul"(%2611, %2612) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%2614 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%2615 = "tensor.splat"(%2614) : (f32) -> tensor<12x1x1024xf32>
%2616 = "tosa.mul"(%2613, %2615) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2617 = "tosa.reshape"(%2608) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%2618 = "tosa.add"(%2616, %2617) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%2619 = "tosa.reduce_max"(%2618) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2620 = "tosa.sub"(%2618, %2619) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2621 = "math.exp"(%2620) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2622 = "tosa.reduce_sum"(%2621) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2623 = "tosa.log"(%2622) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2624 = "tosa.add"(%2619, %2623) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2625 = "tosa.sub"(%2618, %2624) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2626 = "math.exp"(%2625) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2627 = "tosa.reshape"(%2624) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%2628 = "tosa.reshape"(%2597) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%2629 = "tosa.matmul"(%2626, %2628) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%2630 = "tosa.reshape"(%2629) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_28
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_14', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_14']
Children: ['permute_161']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_161
Type: OpType.ReshapeType
Arguments: ['getitem_28', [0, 2, 1, 3]]
Parents: ['getitem_28']
Children: ['view_296']
--------------------MLIR OPS--------------------
%2631 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2632 = "tosa.transpose"(%2630, %2631) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_296
Type: OpType.ReshapeType
Arguments: ['permute_161', [1, 1, -1]]
Parents: ['permute_161']
Children: ['view_297']
--------------------MLIR OPS--------------------
%2633 = "tosa.reshape"(%2632) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_162
Type: OpType.ReshapeType
Arguments: ['arg235_1', [1, 0]]
Parents: ['arg235_1']
Children: ['mm_56']
--------------------MLIR OPS--------------------
%2634 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2635 = "tosa.transpose"(%arg209, %2634) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_297
Type: OpType.ReshapeType
Arguments: ['view_296', [1, 1536]]
Parents: ['view_296']
Children: ['mm_56']
--------------------MLIR OPS--------------------
%2636 = "tosa.reshape"(%2633) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_56
Type: OpType.ReduceType
Arguments: ['view_297', 'permute_162']
Parents: ['view_297', 'permute_162']
Children: ['view_298']
--------------------MLIR OPS--------------------
%2637 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2638 = "linalg.matmul"(%2636, %2635, %2637) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2639 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2640 = "arith.addf"(%arg400, %2639) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2640) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_298
Type: OpType.ReshapeType
Arguments: ['mm_56', [1, 1, 1536]]
Parents: ['mm_56']
Children: ['add_88']
--------------------MLIR OPS--------------------
%2639 = "tosa.reshape"(%2638) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_88
Type: OpType.BroadcastType
Arguments: ['add_84', 'view_298']
Parents: ['add_84', 'view_298']
Children: ['pow_30', 'mul_148', 'add_90']
--------------------MLIR OPS--------------------
%2640 = "tosa.add"(%2500, %2639) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_30
Type: OpType.BroadcastType
Arguments: ['add_88', 2]
Parents: ['add_88']
Children: ['mean_29']
--------------------MLIR OPS--------------------
%2641 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2642 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2643 = "linalg.generic"(%2640, %2641) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2644 = "math.fpowi"(%arg398, %2642) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2644) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_29
Type: OpType.ReduceType
Arguments: ['pow_30', [-1], True]
Parents: ['pow_30']
Children: ['add_89']
--------------------MLIR OPS--------------------
%2644 = "tosa.reduce_sum"(%2643) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2645 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2646 = "tosa.reciprocal"(%2645) : (tensor<1xf32>) -> tensor<1xf32>
%2647 = "tosa.reshape"(%2646) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%2648 = "tosa.mul"(%2647, %2644) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_89
Type: OpType.BroadcastType
Arguments: ['mean_29', 1e-06]
Parents: ['mean_29']
Children: ['rsqrt_29']
--------------------MLIR OPS--------------------
%2649 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%2650 = "tosa.add"(%2648, %2649) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_29
Type: OpType.ElementwiseType
Arguments: ['add_89']
Parents: ['add_89']
Children: ['mul_148']
--------------------MLIR OPS--------------------
%2651 = "tosa.rsqrt"(%2650) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_148
Type: OpType.BroadcastType
Arguments: ['add_88', 'rsqrt_29']
Parents: ['add_88', 'rsqrt_29']
Children: ['mul_149']
--------------------MLIR OPS--------------------
%2652 = "tosa.mul"(%2640, %2651) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_149
Type: OpType.BroadcastType
Arguments: ['arg236_1', 'mul_148']
Parents: ['arg236_1', 'mul_148']
Children: ['view_299', 'view_301']
--------------------MLIR OPS--------------------
%2653 = "tosa.reshape"(%arg210) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%2654 = "tosa.mul"(%2653, %2652) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_163
Type: OpType.ReshapeType
Arguments: ['arg237_1', [1, 0]]
Parents: ['arg237_1']
Children: ['mm_57']
--------------------MLIR OPS--------------------
%2655 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2656 = "tosa.transpose"(%arg211, %2655) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_299
Type: OpType.ReshapeType
Arguments: ['mul_149', [1, 1536]]
Parents: ['mul_149']
Children: ['mm_57']
--------------------MLIR OPS--------------------
%2657 = "tosa.reshape"(%2654) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_57
Type: OpType.ReduceType
Arguments: ['view_299', 'permute_163']
Parents: ['view_299', 'permute_163']
Children: ['view_300']
--------------------MLIR OPS--------------------
%2658 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%2659 = "linalg.matmul"(%2657, %2656, %2658) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2660 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2661 = "arith.addf"(%arg400, %2660) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2661) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_300
Type: OpType.ReshapeType
Arguments: ['mm_57', [1, 1, 8960]]
Parents: ['mm_57']
Children: ['sigmoid_14', 'mul_150']
--------------------MLIR OPS--------------------
%2660 = "tosa.reshape"(%2659) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_14
Type: OpType.ElementwiseType
Arguments: ['view_300']
Parents: ['view_300']
Children: ['mul_150']
--------------------MLIR OPS--------------------
%2661 = "tosa.sigmoid"(%2660) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_150
Type: OpType.BroadcastType
Arguments: ['view_300', 'sigmoid_14']
Parents: ['view_300', 'sigmoid_14']
Children: ['mul_151']
--------------------MLIR OPS--------------------
%2662 = "tosa.mul"(%2660, %2661) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_164
Type: OpType.ReshapeType
Arguments: ['arg238_1', [1, 0]]
Parents: ['arg238_1']
Children: ['mm_58']
--------------------MLIR OPS--------------------
%2663 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2664 = "tosa.transpose"(%arg212, %2663) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_301
Type: OpType.ReshapeType
Arguments: ['mul_149', [1, 1536]]
Parents: ['mul_149']
Children: ['mm_58']
--------------------MLIR OPS--------------------
%2665 = "tosa.reshape"(%2654) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_58
Type: OpType.ReduceType
Arguments: ['view_301', 'permute_164']
Parents: ['view_301', 'permute_164']
Children: ['view_302']
--------------------MLIR OPS--------------------
%2666 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%2667 = "linalg.matmul"(%2665, %2664, %2666) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2668 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2669 = "arith.addf"(%arg400, %2668) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2669) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_302
Type: OpType.ReshapeType
Arguments: ['mm_58', [1, 1, 8960]]
Parents: ['mm_58']
Children: ['mul_151']
--------------------MLIR OPS--------------------
%2668 = "tosa.reshape"(%2667) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_151
Type: OpType.BroadcastType
Arguments: ['mul_150', 'view_302']
Parents: ['mul_150', 'view_302']
Children: ['view_303']
--------------------MLIR OPS--------------------
%2669 = "tosa.mul"(%2662, %2668) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_165
Type: OpType.ReshapeType
Arguments: ['arg239_1', [1, 0]]
Parents: ['arg239_1']
Children: ['mm_59']
--------------------MLIR OPS--------------------
%2670 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2671 = "tosa.transpose"(%arg213, %2670) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_303
Type: OpType.ReshapeType
Arguments: ['mul_151', [1, 8960]]
Parents: ['mul_151']
Children: ['mm_59']
--------------------MLIR OPS--------------------
%2672 = "tosa.reshape"(%2669) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_59
Type: OpType.ReduceType
Arguments: ['view_303', 'permute_165']
Parents: ['view_303', 'permute_165']
Children: ['view_304']
--------------------MLIR OPS--------------------
%2673 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2674 = "linalg.matmul"(%2672, %2671, %2673) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2675 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2676 = "arith.addf"(%arg400, %2675) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2676) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_304
Type: OpType.ReshapeType
Arguments: ['mm_59', [1, 1, 1536]]
Parents: ['mm_59']
Children: ['add_90']
--------------------MLIR OPS--------------------
%2675 = "tosa.reshape"(%2674) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_90
Type: OpType.BroadcastType
Arguments: ['add_88', 'view_304']
Parents: ['add_88', 'view_304']
Children: ['pow_31', 'mul_152', 'add_94']
--------------------MLIR OPS--------------------
%2676 = "tosa.add"(%2640, %2675) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_31
Type: OpType.BroadcastType
Arguments: ['add_90', 2]
Parents: ['add_90']
Children: ['mean_30']
--------------------MLIR OPS--------------------
%2677 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2678 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2679 = "linalg.generic"(%2676, %2677) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2680 = "math.fpowi"(%arg398, %2678) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2680) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_30
Type: OpType.ReduceType
Arguments: ['pow_31', [-1], True]
Parents: ['pow_31']
Children: ['add_91']
--------------------MLIR OPS--------------------
%2680 = "tosa.reduce_sum"(%2679) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2681 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2682 = "tosa.reciprocal"(%2681) : (tensor<1xf32>) -> tensor<1xf32>
%2683 = "tosa.reshape"(%2682) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%2684 = "tosa.mul"(%2683, %2680) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_91
Type: OpType.BroadcastType
Arguments: ['mean_30', 1e-06]
Parents: ['mean_30']
Children: ['rsqrt_30']
--------------------MLIR OPS--------------------
%2685 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%2686 = "tosa.add"(%2684, %2685) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_30
Type: OpType.ElementwiseType
Arguments: ['add_91']
Parents: ['add_91']
Children: ['mul_152']
--------------------MLIR OPS--------------------
%2687 = "tosa.rsqrt"(%2686) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_152
Type: OpType.BroadcastType
Arguments: ['add_90', 'rsqrt_30']
Parents: ['add_90', 'rsqrt_30']
Children: ['mul_153']
--------------------MLIR OPS--------------------
%2688 = "tosa.mul"(%2676, %2687) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_153
Type: OpType.BroadcastType
Arguments: ['arg240_1', 'mul_152']
Parents: ['arg240_1', 'mul_152']
Children: ['view_305', 'view_308', 'view_311']
--------------------MLIR OPS--------------------
%2689 = "tosa.reshape"(%arg214) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%2690 = "tosa.mul"(%2689, %2688) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_305
Type: OpType.ReshapeType
Arguments: ['mul_153', [1, 1536]]
Parents: ['mul_153']
Children: ['addmm_45']
--------------------MLIR OPS--------------------
%2691 = "tosa.reshape"(%2690) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_166
Type: OpType.ReshapeType
Arguments: ['arg241_1', [1, 0]]
Parents: ['arg241_1']
Children: ['addmm_45']
--------------------MLIR OPS--------------------
%2692 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2693 = "tosa.transpose"(%arg215, %2692) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_45
Type: OpType.ReduceType
Arguments: ['arg242_1', 'view_305', 'permute_166']
Parents: ['arg242_1', 'view_305', 'permute_166']
Children: ['view_306']
--------------------MLIR OPS--------------------
%2694 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2695 = "linalg.matmul"(%2691, %2693, %2694) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2698 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2699 = "arith.addf"(%arg400, %2698) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2699) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%2696 = "tosa.reshape"(%arg216) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%2697 = "tosa.add"(%2696, %2695) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_306
Type: OpType.ReshapeType
Arguments: ['addmm_45', [1, 1, 1536]]
Parents: ['addmm_45']
Children: ['view_307']
--------------------MLIR OPS--------------------
%2698 = "tosa.reshape"(%2697) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_307
Type: OpType.ReshapeType
Arguments: ['view_306', [1, 1, -1, 128]]
Parents: ['view_306']
Children: ['permute_167']
--------------------MLIR OPS--------------------
%2699 = "tosa.reshape"(%2698) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_167
Type: OpType.ReshapeType
Arguments: ['view_307', [0, 2, 1, 3]]
Parents: ['view_307']
Children: ['mul_154', 'slice_349', 'slice_350']
--------------------MLIR OPS--------------------
%2700 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2701 = "tosa.transpose"(%2699, %2700) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_308
Type: OpType.ReshapeType
Arguments: ['mul_153', [1, 1536]]
Parents: ['mul_153']
Children: ['addmm_46']
--------------------MLIR OPS--------------------
%2702 = "tosa.reshape"(%2690) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_168
Type: OpType.ReshapeType
Arguments: ['arg243_1', [1, 0]]
Parents: ['arg243_1']
Children: ['addmm_46']
--------------------MLIR OPS--------------------
%2703 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2704 = "tosa.transpose"(%arg217, %2703) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_46
Type: OpType.ReduceType
Arguments: ['arg244_1', 'view_308', 'permute_168']
Parents: ['arg244_1', 'view_308', 'permute_168']
Children: ['view_309']
--------------------MLIR OPS--------------------
%2705 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2706 = "linalg.matmul"(%2702, %2704, %2705) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2709 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2710 = "arith.addf"(%arg400, %2709) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2710) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2707 = "tosa.reshape"(%arg218) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2708 = "tosa.add"(%2707, %2706) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_309
Type: OpType.ReshapeType
Arguments: ['addmm_46', [1, 1, 256]]
Parents: ['addmm_46']
Children: ['view_310']
--------------------MLIR OPS--------------------
%2709 = "tosa.reshape"(%2708) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_310
Type: OpType.ReshapeType
Arguments: ['view_309', [1, 1, -1, 128]]
Parents: ['view_309']
Children: ['permute_169']
--------------------MLIR OPS--------------------
%2710 = "tosa.reshape"(%2709) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_169
Type: OpType.ReshapeType
Arguments: ['view_310', [0, 2, 1, 3]]
Parents: ['view_310']
Children: ['mul_156', 'slice_351', 'slice_352']
--------------------MLIR OPS--------------------
%2711 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2712 = "tosa.transpose"(%2710, %2711) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_311
Type: OpType.ReshapeType
Arguments: ['mul_153', [1, 1536]]
Parents: ['mul_153']
Children: ['addmm_47']
--------------------MLIR OPS--------------------
%2713 = "tosa.reshape"(%2690) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_170
Type: OpType.ReshapeType
Arguments: ['arg245_1', [1, 0]]
Parents: ['arg245_1']
Children: ['addmm_47']
--------------------MLIR OPS--------------------
%2714 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2715 = "tosa.transpose"(%arg219, %2714) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_47
Type: OpType.ReduceType
Arguments: ['arg246_1', 'view_311', 'permute_170']
Parents: ['arg246_1', 'view_311', 'permute_170']
Children: ['view_312']
--------------------MLIR OPS--------------------
%2716 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2717 = "linalg.matmul"(%2713, %2715, %2716) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2720 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2721 = "arith.addf"(%arg400, %2720) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2721) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2718 = "tosa.reshape"(%arg220) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2719 = "tosa.add"(%2718, %2717) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_312
Type: OpType.ReshapeType
Arguments: ['addmm_47', [1, 1, 256]]
Parents: ['addmm_47']
Children: ['view_313']
--------------------MLIR OPS--------------------
%2720 = "tosa.reshape"(%2719) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_313
Type: OpType.ReshapeType
Arguments: ['view_312', [1, 1, -1, 128]]
Parents: ['view_312']
Children: ['permute_171']
--------------------MLIR OPS--------------------
%2721 = "tosa.reshape"(%2720) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_171
Type: OpType.ReshapeType
Arguments: ['view_313', [0, 2, 1, 3]]
Parents: ['view_313']
Children: ['index_put_31']
--------------------MLIR OPS--------------------
%2722 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2723 = "tosa.transpose"(%2721, %2722) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_95
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_154', 'mul_156']
--------------------MLIR OPS--------------------
%2724 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_96
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_155', 'mul_157']
--------------------MLIR OPS--------------------
%2725 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_154
Type: OpType.BroadcastType
Arguments: ['permute_167', 'unsqueeze_95']
Parents: ['permute_167', 'unsqueeze_95']
Children: ['add_92']
--------------------MLIR OPS--------------------
%2726 = "tosa.mul"(%2701, %2724) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_349
Type: OpType.ReshapeType
Arguments: ['permute_167', 3, 0, 64]
Parents: ['permute_167']
Children: ['cat_30']
--------------------MLIR OPS--------------------
%2727 = "tensor.extract_slice"(%2701) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_350
Type: OpType.ReshapeType
Arguments: ['permute_167', 3, 64, 9223372036854775807]
Parents: ['permute_167']
Children: ['neg_30']
--------------------MLIR OPS--------------------
%2728 = "tensor.extract_slice"(%2701) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_30
Type: OpType.ElementwiseType
Arguments: ['slice_350']
Parents: ['slice_350']
Children: ['cat_30']
--------------------MLIR OPS--------------------
%2729 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%2730 = "linalg.negf"(%2728, %2729) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2731 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2731) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_30
Type: OpType.ConcatType
Arguments: [[neg_30, slice_349], -1]
Parents: []
Children: ['mul_155']
--------------------MLIR OPS--------------------
%2731 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%2732 = "tensor.insert_slice"(%2730, %2731) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%2733 = "tensor.insert_slice"(%2727, %2732) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_155
Type: OpType.BroadcastType
Arguments: ['cat_30', 'unsqueeze_96']
Parents: ['cat_30', 'unsqueeze_96']
Children: ['add_92']
--------------------MLIR OPS--------------------
%2734 = "tosa.mul"(%2733, %2725) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_92
Type: OpType.BroadcastType
Arguments: ['mul_154', 'mul_155']
Parents: ['mul_154', 'mul_155']
Children: ['_scaled_dot_product_flash_attention_for_cpu_15']
--------------------MLIR OPS--------------------
%2735 = "tosa.add"(%2726, %2734) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_156
Type: OpType.BroadcastType
Arguments: ['permute_169', 'unsqueeze_95']
Parents: ['permute_169', 'unsqueeze_95']
Children: ['add_93']
--------------------MLIR OPS--------------------
%2736 = "tosa.mul"(%2712, %2724) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_351
Type: OpType.ReshapeType
Arguments: ['permute_169', 3, 0, 64]
Parents: ['permute_169']
Children: ['cat_31']
--------------------MLIR OPS--------------------
%2737 = "tensor.extract_slice"(%2712) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_352
Type: OpType.ReshapeType
Arguments: ['permute_169', 3, 64, 9223372036854775807]
Parents: ['permute_169']
Children: ['neg_31']
--------------------MLIR OPS--------------------
%2738 = "tensor.extract_slice"(%2712) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_31
Type: OpType.ElementwiseType
Arguments: ['slice_352']
Parents: ['slice_352']
Children: ['cat_31']
--------------------MLIR OPS--------------------
%2739 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%2740 = "linalg.negf"(%2738, %2739) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2741 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2741) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_31
Type: OpType.ConcatType
Arguments: [[neg_31, slice_351], -1]
Parents: []
Children: ['mul_157']
--------------------MLIR OPS--------------------
%2741 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%2742 = "tensor.insert_slice"(%2740, %2741) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%2743 = "tensor.insert_slice"(%2737, %2742) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_157
Type: OpType.BroadcastType
Arguments: ['cat_31', 'unsqueeze_96']
Parents: ['cat_31', 'unsqueeze_96']
Children: ['add_93']
--------------------MLIR OPS--------------------
%2744 = "tosa.mul"(%2743, %2725) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_93
Type: OpType.BroadcastType
Arguments: ['mul_156', 'mul_157']
Parents: ['mul_156', 'mul_157']
Children: ['index_put_30']
--------------------MLIR OPS--------------------
%2745 = "tosa.add"(%2736, %2744) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_30
Type: OpType.ElementwiseType
Arguments: ['arg30_1', [None, None, arg58_1], 'add_93']
Parents: ['arg30_1', 'add_93']
Children: ['slice_357', 'output']
--------------------MLIR OPS--------------------
%2746 = "bufferization.to_memref"(%arg221) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2747 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2748 = "bufferization.to_memref"(%2745) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2749 = "arith.constant"() <{value = 0 : index}> : () -> index
%2750 = "arith.constant"() <{value = 1 : index}> : () -> index
%2751 = "arith.constant"() <{value = 1 : index}> : () -> index
%2752 = "arith.constant"() <{value = 2 : index}> : () -> index
%2753 = "arith.constant"() <{value = 1 : index}> : () -> index
%2754 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2749, %2751, %2750) ({
^bb0(%arg398: index):
  "scf.for"(%2749, %2752, %2750) ({
  ^bb0(%arg399: index):
    "scf.for"(%2749, %2753, %2750) ({
    ^bb0(%arg400: index):
      %2756 = "memref.load"(%2747, %arg400) : (memref<1xi64>, index) -> i64
      %2757 = "arith.index_cast"(%2756) : (i64) -> index
      "scf.for"(%2749, %2754, %2750) ({
      ^bb0(%arg401: index):
        %2758 = "memref.load"(%2748, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2758, %2746, %arg398, %arg399, %2757, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2755 = "bufferization.to_tensor"(%2746) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_31
Type: OpType.ElementwiseType
Arguments: ['arg31_1', [None, None, arg58_1], 'permute_171']
Parents: ['arg31_1', 'permute_171']
Children: ['slice_365', 'output']
--------------------MLIR OPS--------------------
%2756 = "bufferization.to_memref"(%arg222) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2757 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2758 = "bufferization.to_memref"(%2723) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2759 = "arith.constant"() <{value = 0 : index}> : () -> index
%2760 = "arith.constant"() <{value = 1 : index}> : () -> index
%2761 = "arith.constant"() <{value = 1 : index}> : () -> index
%2762 = "arith.constant"() <{value = 2 : index}> : () -> index
%2763 = "arith.constant"() <{value = 1 : index}> : () -> index
%2764 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2759, %2761, %2760) ({
^bb0(%arg398: index):
  "scf.for"(%2759, %2762, %2760) ({
  ^bb0(%arg399: index):
    "scf.for"(%2759, %2763, %2760) ({
    ^bb0(%arg400: index):
      %2766 = "memref.load"(%2757, %arg400) : (memref<1xi64>, index) -> i64
      %2767 = "arith.index_cast"(%2766) : (i64) -> index
      "scf.for"(%2759, %2764, %2760) ({
      ^bb0(%arg401: index):
        %2768 = "memref.load"(%2758, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2768, %2756, %arg398, %arg399, %2767, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2765 = "bufferization.to_tensor"(%2756) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_357
Type: OpType.ReshapeType
Arguments: ['index_put_30', 0, 0, 9223372036854775807]
Parents: ['index_put_30']
Children: ['slice_358']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_358
Type: OpType.ReshapeType
Arguments: ['slice_357', 1, 0, 9223372036854775807]
Parents: ['slice_357']
Children: ['unsqueeze_98']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_98
Type: OpType.ReshapeType
Arguments: ['slice_358', 2]
Parents: ['slice_358']
Children: ['slice_359']
--------------------MLIR OPS--------------------
%2766 = "tosa.reshape"(%2755) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_359
Type: OpType.ReshapeType
Arguments: ['unsqueeze_98', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_98']
Children: ['slice_360']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_360
Type: OpType.ReshapeType
Arguments: ['slice_359', 4, 0, 9223372036854775807]
Parents: ['slice_359']
Children: ['expand_67']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_67
Type: OpType.ReshapeType
Arguments: ['slice_360', [1, 2, 6, 1024, 128]]
Parents: ['slice_360']
Children: ['clone_32']
--------------------MLIR OPS--------------------
%2767 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2768 = "tosa.add"(%2766, %2767) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_32
Type: OpType.ReduceType
Arguments: ['expand_67']
Parents: ['expand_67']
Children: ['view_314']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_314
Type: OpType.ReshapeType
Arguments: ['clone_32', [1, 12, 1024, 128]]
Parents: ['clone_32']
Children: ['_scaled_dot_product_flash_attention_for_cpu_15']
--------------------MLIR OPS--------------------
%2769 = "tosa.reshape"(%2768) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_365
Type: OpType.ReshapeType
Arguments: ['index_put_31', 0, 0, 9223372036854775807]
Parents: ['index_put_31']
Children: ['slice_366']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_366
Type: OpType.ReshapeType
Arguments: ['slice_365', 1, 0, 9223372036854775807]
Parents: ['slice_365']
Children: ['unsqueeze_100']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_100
Type: OpType.ReshapeType
Arguments: ['slice_366', 2]
Parents: ['slice_366']
Children: ['slice_367']
--------------------MLIR OPS--------------------
%2770 = "tosa.reshape"(%2765) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_367
Type: OpType.ReshapeType
Arguments: ['unsqueeze_100', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_100']
Children: ['slice_368']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_368
Type: OpType.ReshapeType
Arguments: ['slice_367', 4, 0, 9223372036854775807]
Parents: ['slice_367']
Children: ['expand_69']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_69
Type: OpType.ReshapeType
Arguments: ['slice_368', [1, 2, 6, 1024, 128]]
Parents: ['slice_368']
Children: ['clone_33']
--------------------MLIR OPS--------------------
%2771 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2772 = "tosa.add"(%2770, %2771) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_33
Type: OpType.ReduceType
Arguments: ['expand_69']
Parents: ['expand_69']
Children: ['view_315']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_315
Type: OpType.ReshapeType
Arguments: ['clone_33', [1, 12, 1024, 128]]
Parents: ['clone_33']
Children: ['_scaled_dot_product_flash_attention_for_cpu_15']
--------------------MLIR OPS--------------------
%2773 = "tosa.reshape"(%2772) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_369
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_370']
--------------------MLIR OPS--------------------
%2774 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_370
Type: OpType.ReshapeType
Arguments: ['slice_369', 1, 0, 9223372036854775807]
Parents: ['slice_369']
Children: ['slice_371']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_371
Type: OpType.ReshapeType
Arguments: ['slice_370', 2, 0, 9223372036854775807]
Parents: ['slice_370']
Children: ['where_15']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_30
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_15']
--------------------MLIR OPS--------------------
%2775 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_31
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_15']
--------------------MLIR OPS--------------------
%2776 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_15
Type: OpType.ElementwiseType
Arguments: ['slice_371', 'scalar_tensor_31', 'scalar_tensor_30']
Parents: ['slice_371', 'scalar_tensor_31', 'scalar_tensor_30']
Children: ['_scaled_dot_product_flash_attention_for_cpu_15']
--------------------MLIR OPS--------------------
%2777 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%2778 = "tensor.splat"(%2776) : (f32) -> tensor<1x1x1x1024xf32>
%2779 = "tensor.splat"(%2775) : (f32) -> tensor<1x1x1x1024xf32>
%2780 = "linalg.generic"(%2774, %2778, %2779, %2777) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %2781 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%2781) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_15
Type: OpType.ElementwiseType
Arguments: ['add_92', 'view_314', 'view_315']
Parents: ['add_92', 'view_314', 'view_315']
Children: ['getitem_30']
--------------------MLIR OPS--------------------
%2781 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%2782 = "tensor.splat"(%2781) : (f32) -> tensor<1x1024xf32>
%2783 = "tosa.reshape"(%2780) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%2784 = "tosa.add"(%2782, %2783) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%2785 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2786 = "tosa.transpose"(%2769, %2785) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%2787 = "tosa.reshape"(%2735) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%2788 = "tosa.reshape"(%2786) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%2789 = "tosa.matmul"(%2787, %2788) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%2790 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%2791 = "tensor.splat"(%2790) : (f32) -> tensor<12x1x1024xf32>
%2792 = "tosa.mul"(%2789, %2791) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2793 = "tosa.reshape"(%2784) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%2794 = "tosa.add"(%2792, %2793) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%2795 = "tosa.reduce_max"(%2794) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2796 = "tosa.sub"(%2794, %2795) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2797 = "math.exp"(%2796) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2798 = "tosa.reduce_sum"(%2797) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2799 = "tosa.log"(%2798) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2800 = "tosa.add"(%2795, %2799) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2801 = "tosa.sub"(%2794, %2800) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2802 = "math.exp"(%2801) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2803 = "tosa.reshape"(%2800) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%2804 = "tosa.reshape"(%2773) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%2805 = "tosa.matmul"(%2802, %2804) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%2806 = "tosa.reshape"(%2805) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_30
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_15', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_15']
Children: ['permute_172']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_172
Type: OpType.ReshapeType
Arguments: ['getitem_30', [0, 2, 1, 3]]
Parents: ['getitem_30']
Children: ['view_316']
--------------------MLIR OPS--------------------
%2807 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2808 = "tosa.transpose"(%2806, %2807) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_316
Type: OpType.ReshapeType
Arguments: ['permute_172', [1, 1, -1]]
Parents: ['permute_172']
Children: ['view_317']
--------------------MLIR OPS--------------------
%2809 = "tosa.reshape"(%2808) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_173
Type: OpType.ReshapeType
Arguments: ['arg247_1', [1, 0]]
Parents: ['arg247_1']
Children: ['mm_60']
--------------------MLIR OPS--------------------
%2810 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2811 = "tosa.transpose"(%arg223, %2810) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_317
Type: OpType.ReshapeType
Arguments: ['view_316', [1, 1536]]
Parents: ['view_316']
Children: ['mm_60']
--------------------MLIR OPS--------------------
%2812 = "tosa.reshape"(%2809) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_60
Type: OpType.ReduceType
Arguments: ['view_317', 'permute_173']
Parents: ['view_317', 'permute_173']
Children: ['view_318']
--------------------MLIR OPS--------------------
%2813 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2814 = "linalg.matmul"(%2812, %2811, %2813) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2815 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2816 = "arith.addf"(%arg400, %2815) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2816) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_318
Type: OpType.ReshapeType
Arguments: ['mm_60', [1, 1, 1536]]
Parents: ['mm_60']
Children: ['add_94']
--------------------MLIR OPS--------------------
%2815 = "tosa.reshape"(%2814) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_94
Type: OpType.BroadcastType
Arguments: ['add_90', 'view_318']
Parents: ['add_90', 'view_318']
Children: ['pow_32', 'mul_158', 'add_96']
--------------------MLIR OPS--------------------
%2816 = "tosa.add"(%2676, %2815) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_32
Type: OpType.BroadcastType
Arguments: ['add_94', 2]
Parents: ['add_94']
Children: ['mean_31']
--------------------MLIR OPS--------------------
%2817 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2818 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2819 = "linalg.generic"(%2816, %2817) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2820 = "math.fpowi"(%arg398, %2818) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2820) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_31
Type: OpType.ReduceType
Arguments: ['pow_32', [-1], True]
Parents: ['pow_32']
Children: ['add_95']
--------------------MLIR OPS--------------------
%2820 = "tosa.reduce_sum"(%2819) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2821 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2822 = "tosa.reciprocal"(%2821) : (tensor<1xf32>) -> tensor<1xf32>
%2823 = "tosa.reshape"(%2822) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%2824 = "tosa.mul"(%2823, %2820) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_95
Type: OpType.BroadcastType
Arguments: ['mean_31', 1e-06]
Parents: ['mean_31']
Children: ['rsqrt_31']
--------------------MLIR OPS--------------------
%2825 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%2826 = "tosa.add"(%2824, %2825) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_31
Type: OpType.ElementwiseType
Arguments: ['add_95']
Parents: ['add_95']
Children: ['mul_158']
--------------------MLIR OPS--------------------
%2827 = "tosa.rsqrt"(%2826) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_158
Type: OpType.BroadcastType
Arguments: ['add_94', 'rsqrt_31']
Parents: ['add_94', 'rsqrt_31']
Children: ['mul_159']
--------------------MLIR OPS--------------------
%2828 = "tosa.mul"(%2816, %2827) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_159
Type: OpType.BroadcastType
Arguments: ['arg248_1', 'mul_158']
Parents: ['arg248_1', 'mul_158']
Children: ['view_319', 'view_321']
--------------------MLIR OPS--------------------
%2829 = "tosa.reshape"(%arg224) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%2830 = "tosa.mul"(%2829, %2828) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_174
Type: OpType.ReshapeType
Arguments: ['arg249_1', [1, 0]]
Parents: ['arg249_1']
Children: ['mm_61']
--------------------MLIR OPS--------------------
%2831 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2832 = "tosa.transpose"(%arg225, %2831) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_319
Type: OpType.ReshapeType
Arguments: ['mul_159', [1, 1536]]
Parents: ['mul_159']
Children: ['mm_61']
--------------------MLIR OPS--------------------
%2833 = "tosa.reshape"(%2830) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_61
Type: OpType.ReduceType
Arguments: ['view_319', 'permute_174']
Parents: ['view_319', 'permute_174']
Children: ['view_320']
--------------------MLIR OPS--------------------
%2834 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%2835 = "linalg.matmul"(%2833, %2832, %2834) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2836 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2837 = "arith.addf"(%arg400, %2836) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2837) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_320
Type: OpType.ReshapeType
Arguments: ['mm_61', [1, 1, 8960]]
Parents: ['mm_61']
Children: ['sigmoid_15', 'mul_160']
--------------------MLIR OPS--------------------
%2836 = "tosa.reshape"(%2835) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: sigmoid_15
Type: OpType.ElementwiseType
Arguments: ['view_320']
Parents: ['view_320']
Children: ['mul_160']
--------------------MLIR OPS--------------------
%2837 = "tosa.sigmoid"(%2836) : (tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_160
Type: OpType.BroadcastType
Arguments: ['view_320', 'sigmoid_15']
Parents: ['view_320', 'sigmoid_15']
Children: ['mul_161']
--------------------MLIR OPS--------------------
%2838 = "tosa.mul"(%2836, %2837) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_175
Type: OpType.ReshapeType
Arguments: ['arg250_1', [1, 0]]
Parents: ['arg250_1']
Children: ['mm_62']
--------------------MLIR OPS--------------------
%2839 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2840 = "tosa.transpose"(%arg226, %2839) : (tensor<8960x1536xf32>, tensor<2xi32>) -> tensor<1536x8960xf32>

====================Graph Node====================
Node: view_321
Type: OpType.ReshapeType
Arguments: ['mul_159', [1, 1536]]
Parents: ['mul_159']
Children: ['mm_62']
--------------------MLIR OPS--------------------
%2841 = "tosa.reshape"(%2830) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_62
Type: OpType.ReduceType
Arguments: ['view_321', 'permute_175']
Parents: ['view_321', 'permute_175']
Children: ['view_322']
--------------------MLIR OPS--------------------
%2842 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x8960xf32>}> : () -> tensor<1x8960xf32>
%2843 = "linalg.matmul"(%2841, %2840, %2842) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2844 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2845 = "arith.addf"(%arg400, %2844) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2845) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x8960xf32>, tensor<1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: view_322
Type: OpType.ReshapeType
Arguments: ['mm_62', [1, 1, 8960]]
Parents: ['mm_62']
Children: ['mul_161']
--------------------MLIR OPS--------------------
%2844 = "tosa.reshape"(%2843) <{new_shape = array<i64: 1, 1, 8960>}> : (tensor<1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: mul_161
Type: OpType.BroadcastType
Arguments: ['mul_160', 'view_322']
Parents: ['mul_160', 'view_322']
Children: ['view_323']
--------------------MLIR OPS--------------------
%2845 = "tosa.mul"(%2838, %2844) : (tensor<1x1x8960xf32>, tensor<1x1x8960xf32>) -> tensor<1x1x8960xf32>

====================Graph Node====================
Node: permute_176
Type: OpType.ReshapeType
Arguments: ['arg251_1', [1, 0]]
Parents: ['arg251_1']
Children: ['mm_63']
--------------------MLIR OPS--------------------
%2846 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2847 = "tosa.transpose"(%arg227, %2846) : (tensor<1536x8960xf32>, tensor<2xi32>) -> tensor<8960x1536xf32>

====================Graph Node====================
Node: view_323
Type: OpType.ReshapeType
Arguments: ['mul_161', [1, 8960]]
Parents: ['mul_161']
Children: ['mm_63']
--------------------MLIR OPS--------------------
%2848 = "tosa.reshape"(%2845) <{new_shape = array<i64: 1, 8960>}> : (tensor<1x1x8960xf32>) -> tensor<1x8960xf32>

====================Graph Node====================
Node: mm_63
Type: OpType.ReduceType
Arguments: ['view_323', 'permute_176']
Parents: ['view_323', 'permute_176']
Children: ['view_324']
--------------------MLIR OPS--------------------
%2849 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2850 = "linalg.matmul"(%2848, %2847, %2849) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2851 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2852 = "arith.addf"(%arg400, %2851) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2852) : (f32) -> ()
}) : (tensor<1x8960xf32>, tensor<8960x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_324
Type: OpType.ReshapeType
Arguments: ['mm_63', [1, 1, 1536]]
Parents: ['mm_63']
Children: ['add_96']
--------------------MLIR OPS--------------------
%2851 = "tosa.reshape"(%2850) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_96
Type: OpType.BroadcastType
Arguments: ['add_94', 'view_324']
Parents: ['add_94', 'view_324']
Children: ['pow_33', 'mul_162', 'add_100']
--------------------MLIR OPS--------------------
%2852 = "tosa.add"(%2816, %2851) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_33
Type: OpType.BroadcastType
Arguments: ['add_96', 2]
Parents: ['add_96']
Children: ['mean_32']
--------------------MLIR OPS--------------------
%2853 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2854 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2855 = "linalg.generic"(%2852, %2853) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2856 = "math.fpowi"(%arg398, %2854) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2856) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_32
Type: OpType.ReduceType
Arguments: ['pow_33', [-1], True]
Parents: ['pow_33']
Children: ['add_97']
--------------------MLIR OPS--------------------
%2856 = "tosa.reduce_sum"(%2855) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2857 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2858 = "tosa.reciprocal"(%2857) : (tensor<1xf32>) -> tensor<1xf32>
%2859 = "tosa.reshape"(%2858) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%2860 = "tosa.mul"(%2859, %2856) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_97
Type: OpType.BroadcastType
Arguments: ['mean_32', 1e-06]
Parents: ['mean_32']
Children: ['rsqrt_32']
--------------------MLIR OPS--------------------
%2861 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%2862 = "tosa.add"(%2860, %2861) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_32
Type: OpType.ElementwiseType
Arguments: ['add_97']
Parents: ['add_97']
Children: ['mul_162']
--------------------MLIR OPS--------------------
%2863 = "tosa.rsqrt"(%2862) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_162
Type: OpType.BroadcastType
Arguments: ['add_96', 'rsqrt_32']
Parents: ['add_96', 'rsqrt_32']
Children: ['mul_163']
--------------------MLIR OPS--------------------
%2864 = "tosa.mul"(%2852, %2863) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_163
Type: OpType.BroadcastType
Arguments: ['arg252_1', 'mul_162']
Parents: ['arg252_1', 'mul_162']
Children: ['view_325', 'view_328', 'view_331']
--------------------MLIR OPS--------------------
%2865 = "tosa.reshape"(%arg228) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%2866 = "tosa.mul"(%2865, %2864) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_325
Type: OpType.ReshapeType
Arguments: ['mul_163', [1, 1536]]
Parents: ['mul_163']
Children: ['addmm_48']
--------------------MLIR OPS--------------------
%2867 = "tosa.reshape"(%2866) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_177
Type: OpType.ReshapeType
Arguments: ['arg253_1', [1, 0]]
Parents: ['arg253_1']
Children: ['addmm_48']
--------------------MLIR OPS--------------------
%2868 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2869 = "tosa.transpose"(%arg229, %2868) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: addmm_48
Type: OpType.ReduceType
Arguments: ['arg254_1', 'view_325', 'permute_177']
Parents: ['arg254_1', 'view_325', 'permute_177']
Children: ['view_326']
--------------------MLIR OPS--------------------
%2870 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2871 = "linalg.matmul"(%2867, %2869, %2870) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2874 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2875 = "arith.addf"(%arg400, %2874) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2875) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>
%2872 = "tosa.reshape"(%arg230) <{new_shape = array<i64: 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1536xf32>
%2873 = "tosa.add"(%2872, %2871) : (tensor<1x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_326
Type: OpType.ReshapeType
Arguments: ['addmm_48', [1, 1, 1536]]
Parents: ['addmm_48']
Children: ['view_327']
--------------------MLIR OPS--------------------
%2874 = "tosa.reshape"(%2873) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: view_327
Type: OpType.ReshapeType
Arguments: ['view_326', [1, 1, -1, 128]]
Parents: ['view_326']
Children: ['permute_178']
--------------------MLIR OPS--------------------
%2875 = "tosa.reshape"(%2874) <{new_shape = array<i64: 1, 1, 12, 128>}> : (tensor<1x1x1536xf32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: permute_178
Type: OpType.ReshapeType
Arguments: ['view_327', [0, 2, 1, 3]]
Parents: ['view_327']
Children: ['mul_164', 'slice_372', 'slice_373']
--------------------MLIR OPS--------------------
%2876 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2877 = "tosa.transpose"(%2875, %2876) : (tensor<1x1x12x128xf32>, tensor<4xi32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: view_328
Type: OpType.ReshapeType
Arguments: ['mul_163', [1, 1536]]
Parents: ['mul_163']
Children: ['addmm_49']
--------------------MLIR OPS--------------------
%2878 = "tosa.reshape"(%2866) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_179
Type: OpType.ReshapeType
Arguments: ['arg255_1', [1, 0]]
Parents: ['arg255_1']
Children: ['addmm_49']
--------------------MLIR OPS--------------------
%2879 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2880 = "tosa.transpose"(%arg231, %2879) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_49
Type: OpType.ReduceType
Arguments: ['arg256_1', 'view_328', 'permute_179']
Parents: ['arg256_1', 'view_328', 'permute_179']
Children: ['view_329']
--------------------MLIR OPS--------------------
%2881 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2882 = "linalg.matmul"(%2878, %2880, %2881) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2885 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2886 = "arith.addf"(%arg400, %2885) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2886) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2883 = "tosa.reshape"(%arg232) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2884 = "tosa.add"(%2883, %2882) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_329
Type: OpType.ReshapeType
Arguments: ['addmm_49', [1, 1, 256]]
Parents: ['addmm_49']
Children: ['view_330']
--------------------MLIR OPS--------------------
%2885 = "tosa.reshape"(%2884) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_330
Type: OpType.ReshapeType
Arguments: ['view_329', [1, 1, -1, 128]]
Parents: ['view_329']
Children: ['permute_180']
--------------------MLIR OPS--------------------
%2886 = "tosa.reshape"(%2885) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_180
Type: OpType.ReshapeType
Arguments: ['view_330', [0, 2, 1, 3]]
Parents: ['view_330']
Children: ['mul_166', 'slice_374', 'slice_375']
--------------------MLIR OPS--------------------
%2887 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2888 = "tosa.transpose"(%2886, %2887) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: view_331
Type: OpType.ReshapeType
Arguments: ['mul_163', [1, 1536]]
Parents: ['mul_163']
Children: ['addmm_50']
--------------------MLIR OPS--------------------
%2889 = "tosa.reshape"(%2866) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: permute_181
Type: OpType.ReshapeType
Arguments: ['arg257_1', [1, 0]]
Parents: ['arg257_1']
Children: ['addmm_50']
--------------------MLIR OPS--------------------
%2890 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2891 = "tosa.transpose"(%arg233, %2890) : (tensor<256x1536xf32>, tensor<2xi32>) -> tensor<1536x256xf32>

====================Graph Node====================
Node: addmm_50
Type: OpType.ReduceType
Arguments: ['arg258_1', 'view_331', 'permute_181']
Parents: ['arg258_1', 'view_331', 'permute_181']
Children: ['view_332']
--------------------MLIR OPS--------------------
%2892 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x256xf32>}> : () -> tensor<1x256xf32>
%2893 = "linalg.matmul"(%2889, %2891, %2892) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2896 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2897 = "arith.addf"(%arg400, %2896) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2897) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>
%2894 = "tosa.reshape"(%arg234) <{new_shape = array<i64: 1, 256>}> : (tensor<256xf32>) -> tensor<1x256xf32>
%2895 = "tosa.add"(%2894, %2893) : (tensor<1x256xf32>, tensor<1x256xf32>) -> tensor<1x256xf32>

====================Graph Node====================
Node: view_332
Type: OpType.ReshapeType
Arguments: ['addmm_50', [1, 1, 256]]
Parents: ['addmm_50']
Children: ['view_333']
--------------------MLIR OPS--------------------
%2896 = "tosa.reshape"(%2895) <{new_shape = array<i64: 1, 1, 256>}> : (tensor<1x256xf32>) -> tensor<1x1x256xf32>

====================Graph Node====================
Node: view_333
Type: OpType.ReshapeType
Arguments: ['view_332', [1, 1, -1, 128]]
Parents: ['view_332']
Children: ['permute_182']
--------------------MLIR OPS--------------------
%2897 = "tosa.reshape"(%2896) <{new_shape = array<i64: 1, 1, 2, 128>}> : (tensor<1x1x256xf32>) -> tensor<1x1x2x128xf32>

====================Graph Node====================
Node: permute_182
Type: OpType.ReshapeType
Arguments: ['view_333', [0, 2, 1, 3]]
Parents: ['view_333']
Children: ['index_put_33']
--------------------MLIR OPS--------------------
%2898 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2899 = "tosa.transpose"(%2897, %2898) : (tensor<1x1x2x128xf32>, tensor<4xi32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: unsqueeze_101
Type: OpType.ReshapeType
Arguments: ['mul', 1]
Parents: ['mul']
Children: ['mul_164', 'mul_166']
--------------------MLIR OPS--------------------
%2900 = "tosa.reshape"(%32) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: unsqueeze_102
Type: OpType.ReshapeType
Arguments: ['mul_1', 1]
Parents: ['mul_1']
Children: ['mul_165', 'mul_167']
--------------------MLIR OPS--------------------
%2901 = "tosa.reshape"(%36) <{new_shape = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x128xf32>) -> tensor<1x1x1x128xf32>

====================Graph Node====================
Node: mul_164
Type: OpType.BroadcastType
Arguments: ['permute_178', 'unsqueeze_101']
Parents: ['permute_178', 'unsqueeze_101']
Children: ['add_98']
--------------------MLIR OPS--------------------
%2902 = "tosa.mul"(%2877, %2900) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: slice_372
Type: OpType.ReshapeType
Arguments: ['permute_178', 3, 0, 64]
Parents: ['permute_178']
Children: ['cat_32']
--------------------MLIR OPS--------------------
%2903 = "tensor.extract_slice"(%2877) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: slice_373
Type: OpType.ReshapeType
Arguments: ['permute_178', 3, 64, 9223372036854775807]
Parents: ['permute_178']
Children: ['neg_32']
--------------------MLIR OPS--------------------
%2904 = "tensor.extract_slice"(%2877) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: neg_32
Type: OpType.ElementwiseType
Arguments: ['slice_373']
Parents: ['slice_373']
Children: ['cat_32']
--------------------MLIR OPS--------------------
%2905 = "tensor.empty"() : () -> tensor<1x12x1x64xf32>
%2906 = "linalg.negf"(%2904, %2905) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2907 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2907) : (f32) -> ()
}) : (tensor<1x12x1x64xf32>, tensor<1x12x1x64xf32>) -> tensor<1x12x1x64xf32>

====================Graph Node====================
Node: cat_32
Type: OpType.ConcatType
Arguments: [[neg_32, slice_372], -1]
Parents: []
Children: ['mul_165']
--------------------MLIR OPS--------------------
%2907 = "tensor.empty"() : () -> tensor<1x12x1x128xf32>
%2908 = "tensor.insert_slice"(%2906, %2907) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
%2909 = "tensor.insert_slice"(%2903, %2908) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 12, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x1x64xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_165
Type: OpType.BroadcastType
Arguments: ['cat_32', 'unsqueeze_102']
Parents: ['cat_32', 'unsqueeze_102']
Children: ['add_98']
--------------------MLIR OPS--------------------
%2910 = "tosa.mul"(%2909, %2901) : (tensor<1x12x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: add_98
Type: OpType.BroadcastType
Arguments: ['mul_164', 'mul_165']
Parents: ['mul_164', 'mul_165']
Children: ['_scaled_dot_product_flash_attention_for_cpu_16']
--------------------MLIR OPS--------------------
%2911 = "tosa.add"(%2902, %2910) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: mul_166
Type: OpType.BroadcastType
Arguments: ['permute_180', 'unsqueeze_101']
Parents: ['permute_180', 'unsqueeze_101']
Children: ['add_99']
--------------------MLIR OPS--------------------
%2912 = "tosa.mul"(%2888, %2900) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: slice_374
Type: OpType.ReshapeType
Arguments: ['permute_180', 3, 0, 64]
Parents: ['permute_180']
Children: ['cat_33']
--------------------MLIR OPS--------------------
%2913 = "tensor.extract_slice"(%2888) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: slice_375
Type: OpType.ReshapeType
Arguments: ['permute_180', 3, 64, 9223372036854775807]
Parents: ['permute_180']
Children: ['neg_33']
--------------------MLIR OPS--------------------
%2914 = "tensor.extract_slice"(%2888) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x128xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: neg_33
Type: OpType.ElementwiseType
Arguments: ['slice_375']
Parents: ['slice_375']
Children: ['cat_33']
--------------------MLIR OPS--------------------
%2915 = "tensor.empty"() : () -> tensor<1x2x1x64xf32>
%2916 = "linalg.negf"(%2914, %2915) <{operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2917 = "arith.negf"(%arg398) <{fastmath = #arith.fastmath<none>}> : (f32) -> f32
  "linalg.yield"(%2917) : (f32) -> ()
}) : (tensor<1x2x1x64xf32>, tensor<1x2x1x64xf32>) -> tensor<1x2x1x64xf32>

====================Graph Node====================
Node: cat_33
Type: OpType.ConcatType
Arguments: [[neg_33, slice_374], -1]
Parents: []
Children: ['mul_167']
--------------------MLIR OPS--------------------
%2917 = "tensor.empty"() : () -> tensor<1x2x1x128xf32>
%2918 = "tensor.insert_slice"(%2916, %2917) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>
%2919 = "tensor.insert_slice"(%2913, %2918) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 64>, static_sizes = array<i64: 1, 2, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x2x1x64xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: mul_167
Type: OpType.BroadcastType
Arguments: ['cat_33', 'unsqueeze_102']
Parents: ['cat_33', 'unsqueeze_102']
Children: ['add_99']
--------------------MLIR OPS--------------------
%2920 = "tosa.mul"(%2919, %2901) : (tensor<1x2x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: add_99
Type: OpType.BroadcastType
Arguments: ['mul_166', 'mul_167']
Parents: ['mul_166', 'mul_167']
Children: ['index_put_32']
--------------------MLIR OPS--------------------
%2921 = "tosa.add"(%2912, %2920) : (tensor<1x2x1x128xf32>, tensor<1x2x1x128xf32>) -> tensor<1x2x1x128xf32>

====================Graph Node====================
Node: index_put_32
Type: OpType.ElementwiseType
Arguments: ['arg32_1', [None, None, arg58_1], 'add_99']
Parents: ['arg32_1', 'add_99']
Children: ['slice_380', 'output']
--------------------MLIR OPS--------------------
%2922 = "bufferization.to_memref"(%arg235) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2923 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2924 = "bufferization.to_memref"(%2921) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2925 = "arith.constant"() <{value = 0 : index}> : () -> index
%2926 = "arith.constant"() <{value = 1 : index}> : () -> index
%2927 = "arith.constant"() <{value = 1 : index}> : () -> index
%2928 = "arith.constant"() <{value = 2 : index}> : () -> index
%2929 = "arith.constant"() <{value = 1 : index}> : () -> index
%2930 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2925, %2927, %2926) ({
^bb0(%arg398: index):
  "scf.for"(%2925, %2928, %2926) ({
  ^bb0(%arg399: index):
    "scf.for"(%2925, %2929, %2926) ({
    ^bb0(%arg400: index):
      %2932 = "memref.load"(%2923, %arg400) : (memref<1xi64>, index) -> i64
      %2933 = "arith.index_cast"(%2932) : (i64) -> index
      "scf.for"(%2925, %2930, %2926) ({
      ^bb0(%arg401: index):
        %2934 = "memref.load"(%2924, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2934, %2922, %arg398, %arg399, %2933, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2931 = "bufferization.to_tensor"(%2922) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: index_put_33
Type: OpType.ElementwiseType
Arguments: ['arg33_1', [None, None, arg58_1], 'permute_182']
Parents: ['arg33_1', 'permute_182']
Children: ['slice_388', 'output']
--------------------MLIR OPS--------------------
%2932 = "bufferization.to_memref"(%arg236) : (tensor<1x2x1024x128xf32>) -> memref<1x2x1024x128xf32>
%2933 = "bufferization.to_memref"(%arg2) : (tensor<1xi64>) -> memref<1xi64>
%2934 = "bufferization.to_memref"(%2899) : (tensor<1x2x1x128xf32>) -> memref<1x2x1x128xf32>
%2935 = "arith.constant"() <{value = 0 : index}> : () -> index
%2936 = "arith.constant"() <{value = 1 : index}> : () -> index
%2937 = "arith.constant"() <{value = 1 : index}> : () -> index
%2938 = "arith.constant"() <{value = 2 : index}> : () -> index
%2939 = "arith.constant"() <{value = 1 : index}> : () -> index
%2940 = "arith.constant"() <{value = 128 : index}> : () -> index
"scf.for"(%2935, %2937, %2936) ({
^bb0(%arg398: index):
  "scf.for"(%2935, %2938, %2936) ({
  ^bb0(%arg399: index):
    "scf.for"(%2935, %2939, %2936) ({
    ^bb0(%arg400: index):
      %2942 = "memref.load"(%2933, %arg400) : (memref<1xi64>, index) -> i64
      %2943 = "arith.index_cast"(%2942) : (i64) -> index
      "scf.for"(%2935, %2940, %2936) ({
      ^bb0(%arg401: index):
        %2944 = "memref.load"(%2934, %arg398, %arg399, %arg400, %arg401) : (memref<1x2x1x128xf32>, index, index, index, index) -> f32
        "memref.store"(%2944, %2932, %arg398, %arg399, %2943, %arg401) : (f32, memref<1x2x1024x128xf32>, index, index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    "scf.yield"() : () -> ()
  }) : (index, index, index) -> ()
  "scf.yield"() : () -> ()
}) : (index, index, index) -> ()
%2941 = "bufferization.to_tensor"(%2932) <{restrict}> : (memref<1x2x1024x128xf32>) -> tensor<1x2x1024x128xf32>

====================Graph Node====================
Node: slice_380
Type: OpType.ReshapeType
Arguments: ['index_put_32', 0, 0, 9223372036854775807]
Parents: ['index_put_32']
Children: ['slice_381']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_381
Type: OpType.ReshapeType
Arguments: ['slice_380', 1, 0, 9223372036854775807]
Parents: ['slice_380']
Children: ['unsqueeze_104']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_104
Type: OpType.ReshapeType
Arguments: ['slice_381', 2]
Parents: ['slice_381']
Children: ['slice_382']
--------------------MLIR OPS--------------------
%2942 = "tosa.reshape"(%2931) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_382
Type: OpType.ReshapeType
Arguments: ['unsqueeze_104', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_104']
Children: ['slice_383']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_383
Type: OpType.ReshapeType
Arguments: ['slice_382', 4, 0, 9223372036854775807]
Parents: ['slice_382']
Children: ['expand_71']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_71
Type: OpType.ReshapeType
Arguments: ['slice_383', [1, 2, 6, 1024, 128]]
Parents: ['slice_383']
Children: ['clone_34']
--------------------MLIR OPS--------------------
%2943 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2944 = "tosa.add"(%2942, %2943) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_34
Type: OpType.ReduceType
Arguments: ['expand_71']
Parents: ['expand_71']
Children: ['view_334']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_334
Type: OpType.ReshapeType
Arguments: ['clone_34', [1, 12, 1024, 128]]
Parents: ['clone_34']
Children: ['_scaled_dot_product_flash_attention_for_cpu_16']
--------------------MLIR OPS--------------------
%2945 = "tosa.reshape"(%2944) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_388
Type: OpType.ReshapeType
Arguments: ['index_put_33', 0, 0, 9223372036854775807]
Parents: ['index_put_33']
Children: ['slice_389']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_389
Type: OpType.ReshapeType
Arguments: ['slice_388', 1, 0, 9223372036854775807]
Parents: ['slice_388']
Children: ['unsqueeze_106']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: unsqueeze_106
Type: OpType.ReshapeType
Arguments: ['slice_389', 2]
Parents: ['slice_389']
Children: ['slice_390']
--------------------MLIR OPS--------------------
%2946 = "tosa.reshape"(%2941) <{new_shape = array<i64: 1, 2, 1, 1024, 128>}> : (tensor<1x2x1024x128xf32>) -> tensor<1x2x1x1024x128xf32>

====================Graph Node====================
Node: slice_390
Type: OpType.ReshapeType
Arguments: ['unsqueeze_106', 3, 0, 9223372036854775807]
Parents: ['unsqueeze_106']
Children: ['slice_391']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_391
Type: OpType.ReshapeType
Arguments: ['slice_390', 4, 0, 9223372036854775807]
Parents: ['slice_390']
Children: ['expand_73']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: expand_73
Type: OpType.ReshapeType
Arguments: ['slice_391', [1, 2, 6, 1024, 128]]
Parents: ['slice_391']
Children: ['clone_35']
--------------------MLIR OPS--------------------
%2947 = "tosa.const"() <{value = dense<0.000000e+00> : tensor<1x2x6x1024x128xf32>}> : () -> tensor<1x2x6x1024x128xf32>
%2948 = "tosa.add"(%2946, %2947) : (tensor<1x2x1x1024x128xf32>, tensor<1x2x6x1024x128xf32>) -> tensor<1x2x6x1024x128xf32>

====================Graph Node====================
Node: clone_35
Type: OpType.ReduceType
Arguments: ['expand_73']
Parents: ['expand_73']
Children: ['view_335']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: view_335
Type: OpType.ReshapeType
Arguments: ['clone_35', [1, 12, 1024, 128]]
Parents: ['clone_35']
Children: ['_scaled_dot_product_flash_attention_for_cpu_16']
--------------------MLIR OPS--------------------
%2949 = "tosa.reshape"(%2948) <{new_shape = array<i64: 1, 12, 1024, 128>}> : (tensor<1x2x6x1024x128xf32>) -> tensor<1x12x1024x128xf32>

====================Graph Node====================
Node: slice_392
Type: OpType.ReshapeType
Arguments: ['expand_1', 0, 0, 9223372036854775807]
Parents: ['expand_1']
Children: ['slice_393']
--------------------MLIR OPS--------------------
%2950 = "tosa.reshape"(%17) <{new_shape = array<i64: 1, 1, 1, 1024>}> : (tensor<1x1024xi1>) -> tensor<1x1x1x1024xi1>

====================Graph Node====================
Node: slice_393
Type: OpType.ReshapeType
Arguments: ['slice_392', 1, 0, 9223372036854775807]
Parents: ['slice_392']
Children: ['slice_394']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: slice_394
Type: OpType.ReshapeType
Arguments: ['slice_393', 2, 0, 9223372036854775807]
Parents: ['slice_393']
Children: ['where_16']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: scalar_tensor_32
Type: OpType.PlaceholderType
Arguments: [-inf]
Parents: []
Children: ['where_16']
--------------------MLIR OPS--------------------
%2951 = "arith.constant"() <{value = 0xFF800000 : f32}> : () -> f32

====================Graph Node====================
Node: scalar_tensor_33
Type: OpType.PlaceholderType
Arguments: [0.0]
Parents: []
Children: ['where_16']
--------------------MLIR OPS--------------------
%2952 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32

====================Graph Node====================
Node: where_16
Type: OpType.ElementwiseType
Arguments: ['slice_394', 'scalar_tensor_33', 'scalar_tensor_32']
Parents: ['slice_394', 'scalar_tensor_33', 'scalar_tensor_32']
Children: ['_scaled_dot_product_flash_attention_for_cpu_16']
--------------------MLIR OPS--------------------
%2953 = "tensor.empty"() : () -> tensor<1x1x1x1024xf32>
%2954 = "tensor.splat"(%2952) : (f32) -> tensor<1x1x1x1024xf32>
%2955 = "tensor.splat"(%2951) : (f32) -> tensor<1x1x1x1024xf32>
%2956 = "linalg.generic"(%2950, %2954, %2955, %2953) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 3, 1>}> ({
^bb0(%arg398: i1, %arg399: f32, %arg400: f32, %arg401: f32):
  %2957 = "arith.select"(%arg398, %arg399, %arg400) : (i1, f32, f32) -> f32
  "linalg.yield"(%2957) : (f32) -> ()
}) : (tensor<1x1x1x1024xi1>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>, tensor<1x1x1x1024xf32>) -> tensor<1x1x1x1024xf32>

====================Graph Node====================
Node: _scaled_dot_product_flash_attention_for_cpu_16
Type: OpType.ElementwiseType
Arguments: ['add_98', 'view_334', 'view_335']
Parents: ['add_98', 'view_334', 'view_335']
Children: ['getitem_32']
--------------------MLIR OPS--------------------
%2957 = "arith.constant"() <{value = 0.000000e+00 : f32}> : () -> f32
%2958 = "tensor.splat"(%2957) : (f32) -> tensor<1x1024xf32>
%2959 = "tosa.reshape"(%2956) <{new_shape = array<i64: 1, 1024>}> : (tensor<1x1x1x1024xf32>) -> tensor<1x1024xf32>
%2960 = "tosa.add"(%2958, %2959) : (tensor<1x1024xf32>, tensor<1x1024xf32>) -> tensor<1x1024xf32>
%2961 = "tosa.const"() <{value = dense<[0, 1, 3, 2]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2962 = "tosa.transpose"(%2945, %2961) : (tensor<1x12x1024x128xf32>, tensor<4xi32>) -> tensor<1x12x128x1024xf32>
%2963 = "tosa.reshape"(%2911) <{new_shape = array<i64: 12, 1, 128>}> : (tensor<1x12x1x128xf32>) -> tensor<12x1x128xf32>
%2964 = "tosa.reshape"(%2962) <{new_shape = array<i64: 12, 128, 1024>}> : (tensor<1x12x128x1024xf32>) -> tensor<12x128x1024xf32>
%2965 = "tosa.matmul"(%2963, %2964) : (tensor<12x1x128xf32>, tensor<12x128x1024xf32>) -> tensor<12x1x1024xf32>
%2966 = "arith.constant"() <{value = 0.0883883461 : f32}> : () -> f32
%2967 = "tensor.splat"(%2966) : (f32) -> tensor<12x1x1024xf32>
%2968 = "tosa.mul"(%2965, %2967) : (tensor<12x1x1024xf32>, tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2969 = "tosa.reshape"(%2960) <{new_shape = array<i64: 1, 1, 1024>}> : (tensor<1x1024xf32>) -> tensor<1x1x1024xf32>
%2970 = "tosa.add"(%2968, %2969) : (tensor<12x1x1024xf32>, tensor<1x1x1024xf32>) -> tensor<12x1x1024xf32>
%2971 = "tosa.reduce_max"(%2970) <{axis = 2 : i32, nan_mode = "PROPAGATE"}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2972 = "tosa.sub"(%2970, %2971) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2973 = "math.exp"(%2972) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2974 = "tosa.reduce_sum"(%2973) <{axis = 2 : i32}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1xf32>
%2975 = "tosa.log"(%2974) : (tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2976 = "tosa.add"(%2971, %2975) : (tensor<12x1x1xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1xf32>
%2977 = "tosa.sub"(%2970, %2976) : (tensor<12x1x1024xf32>, tensor<12x1x1xf32>) -> tensor<12x1x1024xf32>
%2978 = "math.exp"(%2977) <{fastmath = #arith.fastmath<none>}> : (tensor<12x1x1024xf32>) -> tensor<12x1x1024xf32>
%2979 = "tosa.reshape"(%2976) <{new_shape = array<i64: 1, 12, 1>}> : (tensor<12x1x1xf32>) -> tensor<1x12x1xf32>
%2980 = "tosa.reshape"(%2949) <{new_shape = array<i64: 12, 1024, 128>}> : (tensor<1x12x1024x128xf32>) -> tensor<12x1024x128xf32>
%2981 = "tosa.matmul"(%2978, %2980) : (tensor<12x1x1024xf32>, tensor<12x1024x128xf32>) -> tensor<12x1x128xf32>
%2982 = "tosa.reshape"(%2981) <{new_shape = array<i64: 1, 12, 1, 128>}> : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>

====================Graph Node====================
Node: getitem_32
Type: OpType.GetItemType
Arguments: ['_scaled_dot_product_flash_attention_for_cpu_16', 0]
Parents: ['_scaled_dot_product_flash_attention_for_cpu_16']
Children: ['permute_183']
--------------------MLIR OPS--------------------

====================Graph Node====================
Node: permute_183
Type: OpType.ReshapeType
Arguments: ['getitem_32', [0, 2, 1, 3]]
Parents: ['getitem_32']
Children: ['view_336']
--------------------MLIR OPS--------------------
%2983 = "tosa.const"() <{value = dense<[0, 2, 1, 3]> : tensor<4xi32>}> : () -> tensor<4xi32>
%2984 = "tosa.transpose"(%2982, %2983) : (tensor<1x12x1x128xf32>, tensor<4xi32>) -> tensor<1x1x12x128xf32>

====================Graph Node====================
Node: view_336
Type: OpType.ReshapeType
Arguments: ['permute_183', [1, 1, -1]]
Parents: ['permute_183']
Children: ['view_337']
--------------------MLIR OPS--------------------
%2985 = "tosa.reshape"(%2984) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1x12x128xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_184
Type: OpType.ReshapeType
Arguments: ['arg259_1', [1, 0]]
Parents: ['arg259_1']
Children: ['mm_64']
--------------------MLIR OPS--------------------
%2986 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
%2987 = "tosa.transpose"(%arg237, %2986) : (tensor<1536x1536xf32>, tensor<2xi32>) -> tensor<1536x1536xf32>

====================Graph Node====================
Node: view_337
Type: OpType.ReshapeType
Arguments: ['view_336', [1, 1536]]
Parents: ['view_336']
Children: ['mm_64']
--------------------MLIR OPS--------------------
%2988 = "tosa.reshape"(%2985) <{new_shape = array<i64: 1, 1536>}> : (tensor<1x1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: mm_64
Type: OpType.ReduceType
Arguments: ['view_337', 'permute_184']
Parents: ['view_337', 'permute_184']
Children: ['view_338']
--------------------MLIR OPS--------------------
%2989 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1x1536xf32>}> : () -> tensor<1x1536xf32>
%2990 = "linalg.matmul"(%2988, %2987, %2989) <{cast = #linalg.type_fn<cast_signed>, indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], operandSegmentSizes = array<i32: 2, 1>}> ({
^bb0(%arg398: f32, %arg399: f32, %arg400: f32):
  %2991 = "arith.mulf"(%arg398, %arg399) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  %2992 = "arith.addf"(%arg400, %2991) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
  "linalg.yield"(%2992) : (f32) -> ()
}) : (tensor<1x1536xf32>, tensor<1536x1536xf32>, tensor<1x1536xf32>) -> tensor<1x1536xf32>

====================Graph Node====================
Node: view_338
Type: OpType.ReshapeType
Arguments: ['mm_64', [1, 1, 1536]]
Parents: ['mm_64']
Children: ['add_100']
--------------------MLIR OPS--------------------
%2991 = "tosa.reshape"(%2990) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: add_100
Type: OpType.BroadcastType
Arguments: ['add_96', 'view_338']
Parents: ['add_96', 'view_338']
Children: ['pow_34', 'mul_168', 'add_102']
--------------------MLIR OPS--------------------
%2992 = "tosa.add"(%2852, %2991) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: pow_34
Type: OpType.BroadcastType
Arguments: ['add_100', 2]
Parents: ['add_100']
Children: ['mean_33']
--------------------MLIR OPS--------------------
%2993 = "tensor.empty"() : () -> tensor<1x1x1536xf32>
%2994 = "arith.constant"() <{value = 2 : i32}> : () -> i32
%2995 = "linalg.generic"(%2992, %2993) <{indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d0, d1, d2)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 1, 1>}> ({
^bb0(%arg398: f32, %arg399: f32):
  %2996 = "math.fpowi"(%arg398, %2994) <{fastmath = #arith.fastmath<none>}> : (f32, i32) -> f32
  "linalg.yield"(%2996) : (f32) -> ()
}) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mean_33
Type: OpType.ReduceType
Arguments: ['pow_34', [-1], True]
Parents: ['pow_34']
Children: ['add_101']
--------------------MLIR OPS--------------------
%2996 = "tosa.reduce_sum"(%2995) <{axis = 2 : i32}> : (tensor<1x1x1536xf32>) -> tensor<1x1x1xf32>
%2997 = "tosa.const"() <{value = dense<1.536000e+03> : tensor<1xf32>}> : () -> tensor<1xf32>
%2998 = "tosa.reciprocal"(%2997) : (tensor<1xf32>) -> tensor<1xf32>
%2999 = "tosa.reshape"(%2998) <{new_shape = array<i64: 1, 1, 1>}> : (tensor<1xf32>) -> tensor<1x1x1xf32>
%3000 = "tosa.mul"(%2999, %2996) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: add_101
Type: OpType.BroadcastType
Arguments: ['mean_33', 1e-06]
Parents: ['mean_33']
Children: ['rsqrt_33']
--------------------MLIR OPS--------------------
%3001 = "tosa.const"() <{value = dense<9.99999997E-7> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32>
%3002 = "tosa.add"(%3000, %3001) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: rsqrt_33
Type: OpType.ElementwiseType
Arguments: ['add_101']
Parents: ['add_101']
Children: ['mul_168']
--------------------MLIR OPS--------------------
%3003 = "tosa.rsqrt"(%3002) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32>

====================Graph Node====================
Node: mul_168
Type: OpType.BroadcastType
Arguments: ['add_100', 'rsqrt_33']
Parents: ['add_100', 'rsqrt_33']
Children: ['mul_169']
--------------------MLIR OPS--------------------
%3004 = "tosa.mul"(%2992, %3003) : (tensor<1x1x1536xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: mul_169
Type: OpType.BroadcastType
Arguments: ['arg260_1', 'mul_168']
Parents: ['arg260_1', 'mul_168']
Children: ['view_339', 'view_341']
--------------------MLIR OPS--------------------
%3005 = "tosa.reshape"(%arg238) <{new_shape = array<i64: 1, 1, 1536>}> : (tensor<1536xf32>) -> tensor<1x1x1536xf32>
%3006 = "tosa.mul"(%3005, %3004) : (tensor<1x1x1536xf32>, tensor<1x1x1536xf32>) -> tensor<1x1x1536xf32>

====================Graph Node====================
Node: permute_185
Type: OpType.ReshapeType
Arguments: ['arg261_1', [1, 0]]
Parents: ['arg261_1']
Children: ['mm_65']
--------------------MLIR OPS--------------------
%3007 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>